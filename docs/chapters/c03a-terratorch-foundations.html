<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.56">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Week 3a: TerraTorch Foundations</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<link href="../site_libs/quarto-contrib/fontawesome6-1.2.0/all.min.css" rel="stylesheet">
<link href="../site_libs/quarto-contrib/fontawesome6-1.2.0/latex-fontsize.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">GEOG 288KC</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../index.html"> 
<span class="menu-text">ğŸ  home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../Syllabus.html"> 
<span class="menu-text">ğŸ“‹ syllabus</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-weekly-sessions" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">ğŸ’» weekly sessions</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-weekly-sessions">    
        <li>
    <a class="dropdown-item" href="../chapters/c01-geospatial-data-foundations.html">
 <span class="dropdown-text">Week 1 - ğŸš€ Core Tools and Data Access</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../chapters/c02-spatial-temporal-attention-mechanisms.html">
 <span class="dropdown-text">Week 2 - âš¡ Rapid Remote Sensing Preprocessing</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../chapters/c03a-terratorch-foundations.html">
 <span class="dropdown-text">Week 3a - ğŸŒ TerraTorch Foundations</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../chapters/c03-complete-gfm-architecture.html">
 <span class="dropdown-text">Week 3b - ğŸ¤– Machine Learning on Remote Sensing</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../chapters/c04-pretraining-implementation.html">
 <span class="dropdown-text">Week 4 - ğŸ—ï¸ Foundation Models in Practice</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../chapters/c05-training-loop-optimization.html">
 <span class="dropdown-text">Week 5 - ğŸ”§ Fine-Tuning &amp; Transfer Learning</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../chapters/c06-model-evaluation-analysis.html">
 <span class="dropdown-text">Week 6 - â° Spatiotemporal Modeling &amp; Projects</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-cheatsheets" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">ğŸ‘€ cheatsheets</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-cheatsheets">    
        <li>
    <a class="dropdown-item" href="../cheatsheets.html">
 <span class="dropdown-text">ğŸ“‹ All Cheatsheets</span></a>
  </li>  
        <li><hr class="dropdown-divider"></li>
        <li class="dropdown-header">âš¡ Quick Starts</li>
        <li>
    <a class="dropdown-item" href="../extras/cheatsheets/week01_imports.html">
 <span class="dropdown-text">Week 01: Import Guide</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-explainers" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">ğŸ§© explainers</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-explainers">    
        <li class="dropdown-header">1ï¸âƒ£ Week 1</li>
        <li>
    <a class="dropdown-item" href="../extras/ai-ml-dl-fm-hierarchy.html">
 <span class="dropdown-text">ğŸ¤– AI/ML/DL/FM Hierarchy</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../extras/geospatial-foundation-model-predictions-standalone.html">
 <span class="dropdown-text">ğŸ¯ GFM Predictions (Standalone)</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../extras/geospatial-prediction-hierarchy.html">
 <span class="dropdown-text">âœ… Geospatial Task/Prediction Types</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../extras/neural_networks_explainer.html">
 <span class="dropdown-text">ğŸ§  Neural Networks: Neurons to Transformers</span></a>
  </li>  
        <li class="dropdown-header">2ï¸âƒ£ Week 2</li>
        <li>
    <a class="dropdown-item" href="../chapters/c00a-foundation_model_architectures.html">
 <span class="dropdown-text">ğŸ—ï¸ Foundation Model Architectures</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../chapters/c00b-introduction-to-deeplearning-architecture.html">
 <span class="dropdown-text">ğŸ“ Introduction to Deep Learning Architecture</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-extras" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">ğŸ“– extras</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-extras">    
        <li class="dropdown-header">ğŸ¯ Practical Examples</li>
        <li>
    <a class="dropdown-item" href="../extras/examples/normalization_comparison.html">
 <span class="dropdown-text">Normalization Comparison</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../extras/examples/resnet.html">
 <span class="dropdown-text">ResNet Implementation</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../extras/examples/segmentation_finetuning.html">
 <span class="dropdown-text">Segmentation Fine-Tuning</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../extras/examples/text_encoder.html">
 <span class="dropdown-text">Text Encoder</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../extras/examples/tiling-and-patches.html">
 <span class="dropdown-text">Tiling and Patches</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../extras/examples/terratorch_workflows.html">
 <span class="dropdown-text">TerraTorch Workflows</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../extras/resources/course_resources.html">
 <span class="dropdown-text">ğŸ“š Reference Materials</span></a>
  </li>  
        <li class="dropdown-header">ğŸ“ Project Templates</li>
        <li>
    <a class="dropdown-item" href="../extras/projects/project-proposal-template.html">
 <span class="dropdown-text">Project Proposal Template</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../extras/projects/mvp-template.html">
 <span class="dropdown-text">Project Results Template</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/gfms-from-scratch/gfms-from-scratch.github.io" target="_blank"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-page-left">
      <div class="quarto-title-block"><div><h1 class="title">Week 3a: TerraTorch Foundations</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
            <p class="subtitle lead">Traditional PyTorch approach with TorchGeo and TerraTorch</p>
                      </div>
  </div>
    
  
  <div class="quarto-title-meta column-page-left">

      
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#part-1-the-torchgeoterratorch-ecosystem" id="toc-part-1-the-torchgeoterratorch-ecosystem" class="nav-link" data-scroll-target="#part-1-the-torchgeoterratorch-ecosystem">Part 1: The TorchGeo/TerraTorch Ecosystem</a>
  <ul class="collapse">
  <li><a href="#the-library-stack" id="toc-the-library-stack" class="nav-link" data-scroll-target="#the-library-stack">The Library Stack</a></li>
  <li><a href="#the-eurosat-benchmark" id="toc-the-eurosat-benchmark" class="nav-link" data-scroll-target="#the-eurosat-benchmark">The EuroSAT Benchmark</a></li>
  <li><a href="#setup-and-installation" id="toc-setup-and-installation" class="nav-link" data-scroll-target="#setup-and-installation">Setup and Installation</a></li>
  </ul></li>
  <li><a href="#part-2-classification-with-eurosat" id="toc-part-2-classification-with-eurosat" class="nav-link" data-scroll-target="#part-2-classification-with-eurosat">Part 2: Classification with EuroSAT</a>
  <ul class="collapse">
  <li><a href="#step-1-load-the-dataset" id="toc-step-1-load-the-dataset" class="nav-link" data-scroll-target="#step-1-load-the-dataset">Step 1: Load the Dataset</a></li>
  <li><a href="#step-2-explore-the-data" id="toc-step-2-explore-the-data" class="nav-link" data-scroll-target="#step-2-explore-the-data">Step 2: Explore the Data</a></li>
  <li><a href="#step-3-create-data-transforms" id="toc-step-3-create-data-transforms" class="nav-link" data-scroll-target="#step-3-create-data-transforms">Step 3: Create Data Transforms</a></li>
  <li><a href="#step-4-create-dataloaders" id="toc-step-4-create-dataloaders" class="nav-link" data-scroll-target="#step-4-create-dataloaders">Step 4: Create DataLoaders</a></li>
  <li><a href="#step-5-build-the-model" id="toc-step-5-build-the-model" class="nav-link" data-scroll-target="#step-5-build-the-model">Step 5: Build the Model</a></li>
  </ul></li>
  <li><a href="#part-3-zero-shot-inference---baseline-performance" id="toc-part-3-zero-shot-inference---baseline-performance" class="nav-link" data-scroll-target="#part-3-zero-shot-inference---baseline-performance">Part 3: Zero-Shot Inference - Baseline Performance</a>
  <ul class="collapse">
  <li><a href="#understanding-zero-shot-inference" id="toc-understanding-zero-shot-inference" class="nav-link" data-scroll-target="#understanding-zero-shot-inference">Understanding Zero-Shot Inference</a></li>
  <li><a href="#step-6-zero-shot-evaluation" id="toc-step-6-zero-shot-evaluation" class="nav-link" data-scroll-target="#step-6-zero-shot-evaluation">Step 6: Zero-Shot Evaluation</a></li>
  <li><a href="#step-7-visualize-zero-shot-predictions" id="toc-step-7-visualize-zero-shot-predictions" class="nav-link" data-scroll-target="#step-7-visualize-zero-shot-predictions">Step 7: Visualize Zero-Shot Predictions</a></li>
  </ul></li>
  <li><a href="#part-4-few-shot-learning---learning-from-limited-data" id="toc-part-4-few-shot-learning---learning-from-limited-data" class="nav-link" data-scroll-target="#part-4-few-shot-learning---learning-from-limited-data">Part 4: Few-Shot Learning - Learning from Limited Data</a>
  <ul class="collapse">
  <li><a href="#helper-create-few-shot-datasets" id="toc-helper-create-few-shot-datasets" class="nav-link" data-scroll-target="#helper-create-few-shot-datasets">Helper: Create Few-Shot Datasets</a></li>
  <li><a href="#step-6a-prototype-networks---no-training-required" id="toc-step-6a-prototype-networks---no-training-required" class="nav-link" data-scroll-target="#step-6a-prototype-networks---no-training-required">Step 6a: Prototype Networks - No Training Required</a></li>
  <li><a href="#step-6b-linear-probing---fast-adaptation" id="toc-step-6b-linear-probing---fast-adaptation" class="nav-link" data-scroll-target="#step-6b-linear-probing---fast-adaptation">Step 6b: Linear Probing - Fast Adaptation</a></li>
  </ul></li>
  <li><a href="#part-5-full-fine-tuning---maximum-performance" id="toc-part-5-full-fine-tuning---maximum-performance" class="nav-link" data-scroll-target="#part-5-full-fine-tuning---maximum-performance">Part 5: Full Fine-Tuning - Maximum Performance</a>
  <ul class="collapse">
  <li><a href="#step-8-define-loss-function" id="toc-step-8-define-loss-function" class="nav-link" data-scroll-target="#step-8-define-loss-function">Step 8: Define Loss Function</a></li>
  <li><a href="#step-7-define-optimizer" id="toc-step-7-define-optimizer" class="nav-link" data-scroll-target="#step-7-define-optimizer">Step 7: Define Optimizer</a></li>
  <li><a href="#step-6-define-training-loop" id="toc-step-6-define-training-loop" class="nav-link" data-scroll-target="#step-6-define-training-loop">Step 6: Define Training Loop</a></li>
  <li><a href="#step-7-develop-a-training-loop-the-model" id="toc-step-7-develop-a-training-loop-the-model" class="nav-link" data-scroll-target="#step-7-develop-a-training-loop-the-model">Step 7: Develop a Training Loop the Model</a></li>
  <li><a href="#step-8-train-the-model" id="toc-step-8-train-the-model" class="nav-link" data-scroll-target="#step-8-train-the-model">Step 8: Train the Model</a></li>
  <li><a href="#step-9-visualize-training-progress" id="toc-step-9-visualize-training-progress" class="nav-link" data-scroll-target="#step-9-visualize-training-progress">Step 9: Visualize Training Progress</a></li>
  <li><a href="#step-10-evaluate-on-test-set" id="toc-step-10-evaluate-on-test-set" class="nav-link" data-scroll-target="#step-10-evaluate-on-test-set">Step 10: Evaluate on Test Set</a></li>
  <li><a href="#step-11-visualize-predictions" id="toc-step-11-visualize-predictions" class="nav-link" data-scroll-target="#step-11-visualize-predictions">Step 11: Visualize Predictions</a></li>
  </ul></li>
  <li><a href="#key-takeaways" id="toc-key-takeaways" class="nav-link" data-scroll-target="#key-takeaways">Key Takeaways</a>
  <ul class="collapse">
  <li><a href="#what-you-learned" id="toc-what-you-learned" class="nav-link" data-scroll-target="#what-you-learned">What You Learned</a></li>
  <li><a href="#next-steps" id="toc-next-steps" class="nav-link" data-scroll-target="#next-steps">Next Steps</a></li>
  </ul></li>
  <li><a href="#resources" id="toc-resources" class="nav-link" data-scroll-target="#resources">Resources</a>
  <ul class="collapse">
  <li><a href="#documentation" id="toc-documentation" class="nav-link" data-scroll-target="#documentation">Documentation</a></li>
  <li><a href="#datasets" id="toc-datasets" class="nav-link" data-scroll-target="#datasets">Datasets</a></li>
  <li><a href="#models" id="toc-models" class="nav-link" data-scroll-target="#models">Models</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block column-page-left" id="quarto-document-content">





<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>This session introduces foundation model workflows using TorchGeo and TerraTorch. Youâ€™ll learn to work with benchmark datasets, build production-ready models, and understand the fundamentals of geospatial deep learning with explicit PyTorch training loops.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Learning Objectives
</div>
</div>
<div class="callout-body-container callout-body">
<p>By the end of this session, you will be able to:</p>
<ol type="1">
<li>Load benchmark datasets using TorchGeo</li>
<li>Build foundation models using TerraTorchâ€™s EncoderDecoderFactory</li>
<li>Evaluate zero-shot performance and understand transfer learning</li>
<li>Implement few-shot learning with prototype networks</li>
<li>Use linear probing for efficient model adaptation</li>
<li>Train models using explicit PyTorch loops</li>
<li>Compare data efficiency across different training regimes</li>
</ol>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Why This Approach?
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Traditional PyTorch training loops (see every step)</li>
<li>Manual metric calculation (understand the math)</li>
<li>Explicit device management (visible <code>.to(device)</code>)</li>
<li>Debuggable workflows (inspect intermediate values)</li>
</ul>
</div>
</div>
</section>
<section id="part-1-the-torchgeoterratorch-ecosystem" class="level2">
<h2 class="anchored" data-anchor-id="part-1-the-torchgeoterratorch-ecosystem">Part 1: The TorchGeo/TerraTorch Ecosystem</h2>
<section id="the-library-stack" class="level3">
<h3 class="anchored" data-anchor-id="the-library-stack">The Library Stack</h3>
<pre><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Your Project Code                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   TerraTorch (Model Factory)        â”‚ â† Foundation models
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   TorchGeo (Dataset Handling)       â”‚ â† Geospatial data
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   PyTorch (Deep Learning)           â”‚ â† Core framework
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜</code></pre>
<p><strong>TorchGeo</strong> provides:</p>
<ul>
<li>Benchmark datasets (EuroSAT, BigEarthNet, etc.)</li>
<li>Geospatial data transforms</li>
<li>Samplers for efficient loading</li>
<li>Plotting and visualization utilities</li>
</ul>
<p><strong>TerraTorch</strong> provides:</p>
<ul>
<li>Pre-trained foundation models (Prithvi, SatMAE, etc.)</li>
<li>Model factory for easy configuration</li>
<li>Encoder-decoder architectures</li>
<li>Task-specific heads</li>
</ul>
</section>
<section id="the-eurosat-benchmark" class="level3">
<h3 class="anchored" data-anchor-id="the-eurosat-benchmark">The EuroSAT Benchmark</h3>
<p>EuroSAT is a land use classification dataset based on Sentinel-2 imagery.</p>
<p><strong>Dataset Statistics:</strong></p>
<ul>
<li><strong>Total images:</strong> ~27,000</li>
<li><strong>Image size:</strong> 64Ã—64 pixels</li>
<li><strong>Bands:</strong> 13 (all Sentinel-2 bands)</li>
<li><strong>Resolution:</strong> 10m, 20m, 60m (resampled to uniform grid)</li>
<li><strong>Classes:</strong> 10 land use categories (original dataset)</li>
</ul>
<p><strong>Note:</strong> The TorchGeo version may have 9 classes. The code dynamically adapts to the actual number of classes in <code>train_dataset.classes</code>.</p>
<p><strong>Typical Land Use Classes:</strong></p>
<ol type="1">
<li>AnnualCrop</li>
<li>Forest</li>
<li>HerbaceousVegetation</li>
<li>Highway</li>
<li>Industrial</li>
<li>Pasture</li>
<li>PermanentCrop</li>
<li>Residential</li>
<li>River (may be merged with SeaLake in some versions)</li>
</ol>
<p><strong>Published Benchmarks:</strong></p>
<ul>
<li>ResNet-50: ~98% accuracy</li>
<li>VGG-16: ~97% accuracy</li>
<li>AlexNet: ~94% accuracy</li>
</ul>
<p><strong>Citation:</strong></p>
<blockquote class="blockquote">
<p>Helber, P., Bischke, B., Dengel, A., &amp; Borth, D. (2019). EuroSAT: A novel dataset and deep learning benchmark for land use and land cover classification. <em>IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing</em>, 12(7), 2217-2226.</p>
</blockquote>
</section>
<section id="setup-and-installation" class="level3">
<h3 class="anchored" data-anchor-id="setup-and-installation">Setup and Installation</h3>
<div id="a9f78b30" class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> DataLoader</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pathlib <span class="im">import</span> Path</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> logging</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>logger <span class="op">=</span> logging.getLogger(<span class="va">__name__</span>)</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Set logging level to INFO</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>logger.setLevel(logging.INFO)</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Clear any existing handlers to prevent duplication</span></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>logger.handlers.clear()</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Add handler for Jupyter notebook output</span></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>handler <span class="op">=</span> logging.StreamHandler()</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>handler.setLevel(logging.INFO)</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>formatter <span class="op">=</span> logging.Formatter(<span class="st">'</span><span class="sc">%(message)s</span><span class="st">'</span>)</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>handler.setFormatter(formatter)</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>logger.addHandler(handler)</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Prevent messages from propagating to root logger</span></span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>logger.propagate <span class="op">=</span> <span class="va">False</span></span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Set random seeds for reproducibility</span></span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">42</span>)</span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Device selection</span></span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> torch.cuda.is_available():</span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a>    device <span class="op">=</span> torch.device(<span class="st">'cuda'</span>)</span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a>    logger.info(<span class="ss">f"Using CUDA GPU: </span><span class="sc">{</span>torch<span class="sc">.</span>cuda<span class="sc">.</span>get_device_name(<span class="dv">0</span>)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a><span class="cf">elif</span> torch.backends.mps.is_available():</span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a>    device <span class="op">=</span> torch.device(<span class="st">'mps'</span>)</span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a>    logger.info(<span class="st">"Using Apple Silicon MPS"</span>)</span>
<span id="cb2-37"><a href="#cb2-37" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb2-38"><a href="#cb2-38" aria-hidden="true" tabindex="-1"></a>    device <span class="op">=</span> torch.device(<span class="st">'cpu'</span>)</span>
<span id="cb2-39"><a href="#cb2-39" aria-hidden="true" tabindex="-1"></a>    logger.info(<span class="st">"Using CPU (training will be slower)"</span>)</span>
<span id="cb2-40"><a href="#cb2-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-41"><a href="#cb2-41" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"PyTorch version: </span><span class="sc">{</span>torch<span class="sc">.</span>__version__<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="part-2-classification-with-eurosat" class="level2">
<h2 class="anchored" data-anchor-id="part-2-classification-with-eurosat">Part 2: Classification with EuroSAT</h2>
<section id="step-1-load-the-dataset" class="level3">
<h3 class="anchored" data-anchor-id="step-1-load-the-dataset">Step 1: Load the Dataset</h3>
<p>TorchGeo makes loading benchmark datasets simple and standardized.</p>
<div id="859ae1d3" class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchgeo.datasets <span class="im">import</span> EuroSAT</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Define data directory</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>data_dir <span class="op">=</span> Path(<span class="st">"data"</span>)</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>data_dir.mkdir(exist_ok<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Load EuroSAT dataset with all bands</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="co"># First time will download ~90MB dataset</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="st">"Loading EuroSAT dataset..."</span>)</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>train_dataset <span class="op">=</span> EuroSAT(</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>    root<span class="op">=</span><span class="bu">str</span>(data_dir),</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>    split<span class="op">=</span><span class="st">"train"</span>,</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>    download<span class="op">=</span><span class="va">True</span></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>val_dataset <span class="op">=</span> EuroSAT(</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>    root<span class="op">=</span><span class="bu">str</span>(data_dir),</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>    split<span class="op">=</span><span class="st">"val"</span>,</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>    download<span class="op">=</span><span class="va">True</span></span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>test_dataset <span class="op">=</span> EuroSAT(</span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>    root<span class="op">=</span><span class="bu">str</span>(data_dir),</span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>    split<span class="op">=</span><span class="st">"test"</span>,</span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a>    download<span class="op">=</span><span class="va">True</span></span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Training samples: </span><span class="sc">{</span><span class="bu">len</span>(train_dataset)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Validation samples: </span><span class="sc">{</span><span class="bu">len</span>(val_dataset)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Test samples: </span><span class="sc">{</span><span class="bu">len</span>(test_dataset)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Number of classes: </span><span class="sc">{</span><span class="bu">len</span>(train_dataset.classes)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Classes: </span><span class="sc">{</span>train_dataset<span class="sc">.</span>classes<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Understanding the Dataset Object
</div>
</div>
<div class="callout-body-container callout-body">
<p>The <code>train_dataset</code> is a PyTorch <code>Dataset</code> object with:</p>
<ul>
<li><code>__len__()</code> - Returns number of samples</li>
<li><code>__getitem__(idx)</code> - Returns (image, label) tuple</li>
<li><code>.classes</code> - List of class names</li>
<li><code>.split</code> - Current split (train/val/test)</li>
</ul>
<p>This standardization means the same code works for any TorchGeo dataset.</p>
</div>
</div>
</section>
<section id="step-2-explore-the-data" class="level3">
<h3 class="anchored" data-anchor-id="step-2-explore-the-data">Step 2: Explore the Data</h3>
<p>Letâ€™s visualize samples from each class to understand what weâ€™re working with.</p>
<div id="563efe5a" class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get one sample from each class efficiently using random sampling</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>samples_per_class <span class="op">=</span> {}</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>num_classes <span class="op">=</span> <span class="bu">len</span>(train_dataset.classes)</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>dataset_size <span class="op">=</span> <span class="bu">len</span>(train_dataset)</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Random sampling is much faster than sequential scan</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Sample more indices than classes to ensure we find all classes quickly</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>random_indices <span class="op">=</span> random.sample(<span class="bu">range</span>(dataset_size), <span class="bu">min</span>(dataset_size, num_classes <span class="op">*</span> <span class="dv">10</span>))</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Sampling representative images (one per class)..."</span>)</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> idx <span class="kw">in</span> random_indices:</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>    sample <span class="op">=</span> train_dataset[idx]</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>    image <span class="op">=</span> sample[<span class="st">"image"</span>]</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>    label <span class="op">=</span> sample[<span class="st">"label"</span>]</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>    class_idx <span class="op">=</span> <span class="bu">int</span>(label) <span class="cf">if</span> <span class="bu">hasattr</span>(label, <span class="st">"item"</span>) <span class="cf">else</span> label</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> class_idx <span class="kw">not</span> <span class="kw">in</span> samples_per_class:</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>        samples_per_class[class_idx] <span class="op">=</span> image</span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Stop once we have all classes</span></span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">set</span>(samples_per_class.keys()) <span class="op">==</span> <span class="bu">set</span>(<span class="bu">range</span>(num_classes)):</span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>        logger.info(<span class="ss">f"Found all </span><span class="sc">{</span>num_classes<span class="sc">}</span><span class="ss"> classes in </span><span class="sc">{</span><span class="bu">len</span>(samples_per_class)<span class="sc">}</span><span class="ss"> samples"</span>)</span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>        <span class="cf">break</span></span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Create RGB composite for visualization</span></span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a><span class="co"># EuroSAT bands: [B01, B02, B03, B04, B05, B06, B07, B08, B8A, B09, B10, B11, B12]</span></span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a><span class="co"># RGB = B04 (Red), B03 (Green), B02 (Blue) = indices [3, 2, 1]</span></span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Dynamic grid based on actual number of classes found</span></span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a>n_samples <span class="op">=</span> <span class="bu">len</span>(samples_per_class)</span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a>n_cols <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a>n_rows <span class="op">=</span> <span class="bu">int</span>(np.ceil(n_samples <span class="op">/</span> n_cols))</span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(n_rows, n_cols, figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">3</span><span class="op">*</span>n_rows))</span>
<span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a>axes <span class="op">=</span> axes.ravel()</span>
<span id="cb4-38"><a href="#cb4-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-39"><a href="#cb4-39" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> idx, (label, image) <span class="kw">in</span> <span class="bu">enumerate</span>(samples_per_class.items()):</span>
<span id="cb4-40"><a href="#cb4-40" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Extract RGB bands</span></span>
<span id="cb4-41"><a href="#cb4-41" aria-hidden="true" tabindex="-1"></a>    rgb <span class="op">=</span> image[[<span class="dv">3</span>, <span class="dv">2</span>, <span class="dv">1</span>], :, :].numpy()  <span class="co"># Red, Green, Blue</span></span>
<span id="cb4-42"><a href="#cb4-42" aria-hidden="true" tabindex="-1"></a>    rgb <span class="op">=</span> np.transpose(rgb, (<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">0</span>))  <span class="co"># (H, W, C)</span></span>
<span id="cb4-43"><a href="#cb4-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-44"><a href="#cb4-44" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Normalize for display (using percentile stretch)</span></span>
<span id="cb4-45"><a href="#cb4-45" aria-hidden="true" tabindex="-1"></a>    p2, p98 <span class="op">=</span> np.percentile(rgb, (<span class="dv">2</span>, <span class="dv">98</span>))</span>
<span id="cb4-46"><a href="#cb4-46" aria-hidden="true" tabindex="-1"></a>    rgb_norm <span class="op">=</span> np.clip((rgb <span class="op">-</span> p2) <span class="op">/</span> (p98 <span class="op">-</span> p2), <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb4-47"><a href="#cb4-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-48"><a href="#cb4-48" aria-hidden="true" tabindex="-1"></a>    axes[idx].imshow(rgb_norm)</span>
<span id="cb4-49"><a href="#cb4-49" aria-hidden="true" tabindex="-1"></a>    axes[idx].set_title(train_dataset.classes[label])</span>
<span id="cb4-50"><a href="#cb4-50" aria-hidden="true" tabindex="-1"></a>    axes[idx].axis(<span class="st">'off'</span>)</span>
<span id="cb4-51"><a href="#cb4-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-52"><a href="#cb4-52" aria-hidden="true" tabindex="-1"></a><span class="co"># Hide any unused subplots</span></span>
<span id="cb4-53"><a href="#cb4-53" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> idx <span class="kw">in</span> <span class="bu">range</span>(n_samples, <span class="bu">len</span>(axes)):</span>
<span id="cb4-54"><a href="#cb4-54" aria-hidden="true" tabindex="-1"></a>    axes[idx].axis(<span class="st">'off'</span>)</span>
<span id="cb4-55"><a href="#cb4-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-56"><a href="#cb4-56" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb4-57"><a href="#cb4-57" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb4-58"><a href="#cb4-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-59"><a href="#cb4-59" aria-hidden="true" tabindex="-1"></a><span class="co"># Print band information and data range</span></span>
<span id="cb4-60"><a href="#cb4-60" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Image shape: </span><span class="sc">{</span>image<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb4-61"><a href="#cb4-61" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Bands: 13 Sentinel-2 bands"</span>)</span>
<span id="cb4-62"><a href="#cb4-62" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Spatial size: 64Ã—64 pixels"</span>)</span>
<span id="cb4-63"><a href="#cb4-63" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f""</span>)</span>
<span id="cb4-64"><a href="#cb4-64" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Raw EuroSAT data range:"</span>)</span>
<span id="cb4-65"><a href="#cb4-65" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"  Min value: </span><span class="sc">{</span>image<span class="sc">.</span><span class="bu">min</span>()<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb4-66"><a href="#cb4-66" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"  Max value: </span><span class="sc">{</span>image<span class="sc">.</span><span class="bu">max</span>()<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb4-67"><a href="#cb4-67" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"  Mean value: </span><span class="sc">{</span>image<span class="sc">.</span>mean()<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb4-68"><a href="#cb4-68" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f""</span>)</span>
<span id="cb4-69"><a href="#cb4-69" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"This confirms EuroSAT is NOT pre-normalized!"</span>)</span>
<span id="cb4-70"><a href="#cb4-70" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Typical Sentinel-2 range: 0-10000 (surface reflectance Ã— 10000)"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Band Selection Strategy
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Challenge:</strong> Prithvi expects 6 bands, EuroSAT has 13 bands.</p>
<p><strong>Solution:</strong> Select the 6 bands Prithvi was trained on:</p>
<ul>
<li>B02 (Blue) - 10m</li>
<li>B03 (Green) - 10m</li>
<li>B04 (Red) - 10m</li>
<li>B08 (NIR) - 10m</li>
<li>B11 (SWIR1) - 20m</li>
<li>B12 (SWIR2) - 20m</li>
</ul>
<p>EuroSAT indices: [1, 2, 3, 7, 11, 12]</p>
</div>
</div>
</section>
<section id="step-3-create-data-transforms" class="level3">
<h3 class="anchored" data-anchor-id="step-3-create-data-transforms">Step 3: Create Data Transforms</h3>
<p>We need to select the correct bands and normalize the data for Prithvi.</p>
<p><strong>Critical Understanding:</strong></p>
<ul>
<li><strong>EuroSAT raw data</strong>: Sentinel-2 surface reflectance values (typically 0-10000+)</li>
<li><strong>Prithvi expects</strong>: Normalized values in range [0, 1]</li>
<li><strong>Why this matters</strong>: Without normalization, the model gets completely out-of-distribution inputs</li>
<li><strong>Result without normalization</strong>: Zero-shot accuracy ~10% (random guessing)</li>
</ul>
<div id="2ffca559" class="cell" data-tangle="geogfm/training/eurosat_utils.py">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> select_prithvi_bands(sample):</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Select the 6 bands Prithvi was trained on from EuroSAT's 13 bands.</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="co">    ----------</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a><span class="co">    sample : dict</span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a><span class="co">        TorchGeo sample with 'image' and 'label' keys</span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns</span></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a><span class="co">    -------</span></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a><span class="co">    dict</span></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a><span class="co">        Sample with 6-band image</span></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># EuroSAT band order: [B01, B02, B03, B04, B05, B06, B07, B08, B8A, B09, B10, B11, B12]</span></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Prithvi bands: [B02, B03, B04, B08, B11, B12]</span></span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Indices: [1, 2, 3, 7, 11, 12]</span></span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>    image <span class="op">=</span> sample[<span class="st">'image'</span>]</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>    selected_bands <span class="op">=</span> image[[<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">7</span>, <span class="dv">11</span>, <span class="dv">12</span>], :, :]</span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {</span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>        <span class="st">'image'</span>: selected_bands,</span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a>        <span class="st">'label'</span>: sample[<span class="st">'label'</span>]</span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> normalize_prithvi(sample):</span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a><span class="co">    Normalize imagery for Prithvi using per-sample normalization.</span></span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a><span class="co">    In production, you would want to use global statistics from the training set.</span></span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a><span class="co">    For this demo, we use per-sample percentile normalization.</span></span>
<span id="cb5-35"><a href="#cb5-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-36"><a href="#cb5-36" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters</span></span>
<span id="cb5-37"><a href="#cb5-37" aria-hidden="true" tabindex="-1"></a><span class="co">    ----------</span></span>
<span id="cb5-38"><a href="#cb5-38" aria-hidden="true" tabindex="-1"></a><span class="co">    sample : dict</span></span>
<span id="cb5-39"><a href="#cb5-39" aria-hidden="true" tabindex="-1"></a><span class="co">        Sample with 'image' and 'label'</span></span>
<span id="cb5-40"><a href="#cb5-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-41"><a href="#cb5-41" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns</span></span>
<span id="cb5-42"><a href="#cb5-42" aria-hidden="true" tabindex="-1"></a><span class="co">    -------</span></span>
<span id="cb5-43"><a href="#cb5-43" aria-hidden="true" tabindex="-1"></a><span class="co">    dict</span></span>
<span id="cb5-44"><a href="#cb5-44" aria-hidden="true" tabindex="-1"></a><span class="co">        Sample with normalized image</span></span>
<span id="cb5-45"><a href="#cb5-45" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb5-46"><a href="#cb5-46" aria-hidden="true" tabindex="-1"></a>    image <span class="op">=</span> sample[<span class="st">'image'</span>]</span>
<span id="cb5-47"><a href="#cb5-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-48"><a href="#cb5-48" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Normalize each band independently using 2nd-98th percentile</span></span>
<span id="cb5-49"><a href="#cb5-49" aria-hidden="true" tabindex="-1"></a>    normalized <span class="op">=</span> torch.zeros_like(image)</span>
<span id="cb5-50"><a href="#cb5-50" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> c <span class="kw">in</span> <span class="bu">range</span>(image.shape[<span class="dv">0</span>]):</span>
<span id="cb5-51"><a href="#cb5-51" aria-hidden="true" tabindex="-1"></a>        band <span class="op">=</span> image[c]</span>
<span id="cb5-52"><a href="#cb5-52" aria-hidden="true" tabindex="-1"></a>        p2, p98 <span class="op">=</span> torch.quantile(band, torch.tensor([<span class="fl">0.02</span>, <span class="fl">0.98</span>]))</span>
<span id="cb5-53"><a href="#cb5-53" aria-hidden="true" tabindex="-1"></a>        normalized[c] <span class="op">=</span> torch.clamp((band <span class="op">-</span> p2) <span class="op">/</span> (p98 <span class="op">-</span> p2 <span class="op">+</span> <span class="fl">1e-8</span>), <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb5-54"><a href="#cb5-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-55"><a href="#cb5-55" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {</span>
<span id="cb5-56"><a href="#cb5-56" aria-hidden="true" tabindex="-1"></a>        <span class="st">'image'</span>: normalized,</span>
<span id="cb5-57"><a href="#cb5-57" aria-hidden="true" tabindex="-1"></a>        <span class="st">'label'</span>: sample[<span class="st">'label'</span>]</span>
<span id="cb5-58"><a href="#cb5-58" aria-hidden="true" tabindex="-1"></a>    }</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="0df61b2f" class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision <span class="im">import</span> transforms</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Compose transforms</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>transform <span class="op">=</span> transforms.Compose([</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>    select_prithvi_bands,</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>    normalize_prithvi  <span class="co"># Critical for Prithvi - expects [0, 1] normalized inputs</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply transforms to datasets</span></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> TransformedDataset(torch.utils.data.Dataset):</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Wrapper to apply transforms to TorchGeo datasets."""</span></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, dataset, transform<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dataset <span class="op">=</span> dataset</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.transform <span class="op">=</span> transform</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__len__</span>(<span class="va">self</span>):</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="bu">len</span>(<span class="va">self</span>.dataset)</span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__getitem__</span>(<span class="va">self</span>, idx):</span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>        sample <span class="op">=</span> <span class="va">self</span>.dataset[idx]</span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.transform:</span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>            sample <span class="op">=</span> <span class="va">self</span>.transform(sample)</span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> sample[<span class="st">'image'</span>], sample[<span class="st">'label'</span>]</span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a>train_dataset_transformed <span class="op">=</span> TransformedDataset(train_dataset, transform)</span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a>val_dataset_transformed <span class="op">=</span> TransformedDataset(val_dataset, transform)</span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a>test_dataset_transformed <span class="op">=</span> TransformedDataset(test_dataset, transform)</span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Test the transformation</span></span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a>sample_img, sample_label <span class="op">=</span> train_dataset_transformed[<span class="dv">0</span>]</span>
<span id="cb6-31"><a href="#cb6-31" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Transformed image shape: </span><span class="sc">{</span>sample_img<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-32"><a href="#cb6-32" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Expected: (6, 64, 64)"</span>)</span>
<span id="cb6-33"><a href="#cb6-33" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Label: </span><span class="sc">{</span>sample_label<span class="sc">}</span><span class="ss"> (</span><span class="sc">{</span>train_dataset<span class="sc">.</span>classes[sample_label]<span class="sc">}</span><span class="ss">)"</span>)</span>
<span id="cb6-34"><a href="#cb6-34" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Value range: [</span><span class="sc">{</span>sample_img<span class="sc">.</span><span class="bu">min</span>()<span class="sc">:.4f}</span><span class="ss">, </span><span class="sc">{</span>sample_img<span class="sc">.</span><span class="bu">max</span>()<span class="sc">:.4f}</span><span class="ss">]"</span>)</span>
<span id="cb6-35"><a href="#cb6-35" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Expected range: [0, 1] after normalization"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="step-4-create-dataloaders" class="level3">
<h3 class="anchored" data-anchor-id="step-4-create-dataloaders">Step 4: Create DataLoaders</h3>
<p>DataLoaders handle batching, shuffling, and parallel data loading.</p>
<div id="e54c305d" class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create DataLoaders</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>train_loader <span class="op">=</span> DataLoader(</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>    train_dataset_transformed,</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span><span class="dv">32</span>,</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>    shuffle<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>    num_workers<span class="op">=</span><span class="dv">0</span>  <span class="co"># Set to 0 for Windows, 4+ for Linux/Mac</span></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>val_loader <span class="op">=</span> DataLoader(</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>    val_dataset_transformed,</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span><span class="dv">32</span>,</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>    shuffle<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>    num_workers<span class="op">=</span><span class="dv">0</span></span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>test_loader <span class="op">=</span> DataLoader(</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>    test_dataset_transformed,</span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span><span class="dv">32</span>,</span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>    shuffle<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>    num_workers<span class="op">=</span><span class="dv">0</span></span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Training batches: </span><span class="sc">{</span><span class="bu">len</span>(train_loader)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Validation batches: </span><span class="sc">{</span><span class="bu">len</span>(val_loader)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Test batches: </span><span class="sc">{</span><span class="bu">len</span>(test_loader)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Test a batch</span></span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true" tabindex="-1"></a>images, labels <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(train_loader))</span>
<span id="cb7-29"><a href="#cb7-29" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Batch shape: </span><span class="sc">{</span>images<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-30"><a href="#cb7-30" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Labels shape: </span><span class="sc">{</span>labels<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-31"><a href="#cb7-31" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Batch on device will be: </span><span class="sc">{</span>images<span class="sc">.</span>to(device)<span class="sc">.</span>device<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="step-5-build-the-model" class="level3">
<h3 class="anchored" data-anchor-id="step-5-build-the-model">Step 5: Build the Model</h3>
<p>TerraTorchâ€™s <code>EncoderDecoderFactory</code> makes it simple to build models. <strong>How <code>build_model</code> Works</strong></p>
<p>The <code>build_model</code> method from <code>EncoderDecoderFactory</code> creates a flexible model by combining a backbone (encoder) with a task-specific decoder head. For classification, the decoder will produce logits of shape <code>[batch_size, num_classes]</code>. This method is highly customizable and is central to TerraTorchâ€™s architectural flexibility.</p>
<p><strong>Key arguments to <code>build_model</code>:</strong></p>
<ul>
<li><code>task</code>: The type of task (<code>"classification"</code>, <code>"segmentation"</code>, <code>"regression"</code>, etc.)</li>
<li><code>backbone</code>: The encoder backbone to use (e.g., <code>"prithvi_eo_v1_100"</code>, <code>"prithvi_eo_v2_300"</code>, <code>"satmae"</code>, <code>"clay"</code>, <code>"timm_resnet50"</code>)</li>
<li><code>decoder</code>: The decoder architecture to attach. For classification, <code>"FCNDecoder"</code> is a typical choice; for segmentation, you might use <code>"SegmentationDecoder"</code> or others suitable for the task.</li>
<li><code>num_classes</code>: The number of output classes for classification (or channels for other tasks)</li>
</ul>
<p><strong>Further arguments</strong> (advanced):</p>
<ul>
<li><code>pretrained</code>: If <code>True</code>, will use pretrained weights for the backbone where available.</li>
<li><code>in_channels</code>: Number of input channels; must match your data (EuroSAT uses 6 bands).</li>
<li><code>freeze_encoder</code>: If <code>True</code>, the backbone weights will not be updated during training.</li>
<li><code>decoder_kwargs</code>: Dictionary of extra arguments for fine-tuning decoder behavior.</li>
</ul>
<p>For official documentation and a full list of arguments, see:<br>
<a href="https://terratorch.readthedocs.io/en/latest/api/terratorch.models.html#terratorch.models.EncoderDecoderFactory.build_model">https://terratorch.readthedocs.io/en/latest/api/terratorch.models.html#terratorch.models.EncoderDecoderFactory.build_model</a></p>
<div id="9f62496f" class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> terratorch.models <span class="im">import</span> EncoderDecoderFactory</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Create model factory</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>model_factory <span class="op">=</span> EncoderDecoderFactory()</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Build classification model with Prithvi backbone</span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>num_classes <span class="op">=</span> <span class="bu">len</span>(train_dataset.classes)</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Suppress expected TerraTorch decoder compatibility warning</span></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> warnings.catch_warnings():</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>    warnings.filterwarnings(<span class="st">"ignore"</span>, message<span class="op">=</span><span class="st">".*includes_head.*"</span>)</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> model_factory.build_model(</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>        task<span class="op">=</span><span class="st">"classification"</span>,</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>        backbone<span class="op">=</span><span class="st">"prithvi_eo_v1_100"</span>,  <span class="co"># 100M parameter Prithvi</span></span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>        decoder<span class="op">=</span><span class="st">"FCNDecoder"</span>,           <span class="co"># Simple fully-convolutional decoder</span></span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>        num_classes<span class="op">=</span>num_classes         <span class="co"># Based on actual dataset</span></span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Move model to device</span></span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> model.to(device)</span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Count parameters</span></span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a>total_params <span class="op">=</span> <span class="bu">sum</span>(p.numel() <span class="cf">for</span> p <span class="kw">in</span> model.parameters())</span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a>trainable_params <span class="op">=</span> <span class="bu">sum</span>(p.numel() <span class="cf">for</span> p <span class="kw">in</span> model.parameters() <span class="cf">if</span> p.requires_grad)</span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Model loaded: Prithvi-100M with FCN decoder"</span>)</span>
<span id="cb8-28"><a href="#cb8-28" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Total parameters: </span><span class="sc">{</span>total_params<span class="sc">:,}</span><span class="ss">"</span>)</span>
<span id="cb8-29"><a href="#cb8-29" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Trainable parameters: </span><span class="sc">{</span>trainable_params<span class="sc">:,}</span><span class="ss">"</span>)</span>
<span id="cb8-30"><a href="#cb8-30" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Model on device: </span><span class="sc">{</span><span class="bu">next</span>(model.parameters())<span class="sc">.</span>device<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Understanding the Architecture
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Encoder (Backbone):</strong></p>
<ul>
<li><code>prithvi_eo_v1_100</code> - Vision Transformer pretrained on HLS imagery</li>
<li>Extracts spatial features from 6-band input</li>
<li>Parameters frozen or fine-tuned depending on task</li>
</ul>
<p><strong>Decoder (Head):</strong></p>
<ul>
<li><code>FCNDecoder</code> - Fully Convolutional Network</li>
<li>Aggregates encoder features</li>
<li>Produces class logits (num_classes outputs)</li>
</ul>
<p><strong>Alternative backbones:</strong> <code>prithvi_eo_v2_300</code>, <code>satmae</code>, <code>scalemae</code>, <code>clay</code>, <code>timm_resnet50</code></p>
</div>
</div>
</section>
</section>
<section id="part-3-zero-shot-inference---baseline-performance" class="level2">
<h2 class="anchored" data-anchor-id="part-3-zero-shot-inference---baseline-performance">Part 3: Zero-Shot Inference - Baseline Performance</h2>
<p>Before training the model, letâ€™s evaluate what the pretrained Prithvi backbone already knows. This establishes a baseline and demonstrates the power of transfer learning.</p>
<section id="understanding-zero-shot-inference" class="level3">
<h3 class="anchored" data-anchor-id="understanding-zero-shot-inference">Understanding Zero-Shot Inference</h3>
<p><strong>Zero-shot inference</strong> means using a model without any task-specific training:</p>
<ul>
<li>The Prithvi backbone was pretrained on massive HLS satellite imagery</li>
<li>It learned general geospatial features (vegetation patterns, water bodies, urban structures)</li>
<li>But it has never seen EuroSAT or these specific land use classes</li>
<li>The classification head is randomly initialized</li>
</ul>
</section>
<section id="step-6-zero-shot-evaluation" class="level3">
<h3 class="anchored" data-anchor-id="step-6-zero-shot-evaluation">Step 6: Zero-Shot Evaluation</h3>
<p>Letâ€™s evaluate the model using the same representative images we visualized earlier - one sample from each class.</p>
<div id="3a3d9967" class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Use the same representative samples from Step 2</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Transform them to 6 bands + normalize</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>zero_shot_images <span class="op">=</span> []</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>zero_shot_labels <span class="op">=</span> []</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="st">"Preparing representative samples for zero-shot evaluation..."</span>)</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> class_idx, image <span class="kw">in</span> samples_per_class.items():</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Apply transforms (band selection + normalization)</span></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>    sample <span class="op">=</span> {<span class="st">'image'</span>: image, <span class="st">'label'</span>: class_idx}</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>    transformed <span class="op">=</span> transform(sample)</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>    zero_shot_images.append(transformed[<span class="st">'image'</span>])</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>    zero_shot_labels.append(transformed[<span class="st">'label'</span>])</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Stack into batch</span></span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>zero_shot_images <span class="op">=</span> torch.stack(zero_shot_images).to(device)</span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>zero_shot_labels <span class="op">=</span> torch.tensor(zero_shot_labels).to(device)</span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Zero-shot evaluation batch: </span><span class="sc">{</span>zero_shot_images<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"One sample per class (</span><span class="sc">{</span><span class="bu">len</span>(train_dataset.classes)<span class="sc">}</span><span class="ss"> total)"</span>)</span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f""</span>)</span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Set model to evaluation mode</span></span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">eval</span>()</span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate zero-shot performance</span></span>
<span id="cb9-26"><a href="#cb9-26" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="st">"Evaluating zero-shot performance..."</span>)</span>
<span id="cb9-27"><a href="#cb9-27" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="st">"="</span> <span class="op">*</span> <span class="dv">60</span>)</span>
<span id="cb9-28"><a href="#cb9-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-29"><a href="#cb9-29" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb9-30"><a href="#cb9-30" aria-hidden="true" tabindex="-1"></a>    outputs <span class="op">=</span> model(zero_shot_images)</span>
<span id="cb9-31"><a href="#cb9-31" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">hasattr</span>(outputs, <span class="st">'output'</span>):</span>
<span id="cb9-32"><a href="#cb9-32" aria-hidden="true" tabindex="-1"></a>        outputs <span class="op">=</span> outputs.output</span>
<span id="cb9-33"><a href="#cb9-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-34"><a href="#cb9-34" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get predictions</span></span>
<span id="cb9-35"><a href="#cb9-35" aria-hidden="true" tabindex="-1"></a>    _, predicted <span class="op">=</span> outputs.<span class="bu">max</span>(<span class="dv">1</span>)</span>
<span id="cb9-36"><a href="#cb9-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-37"><a href="#cb9-37" aria-hidden="true" tabindex="-1"></a>correct <span class="op">=</span> predicted.eq(zero_shot_labels).<span class="bu">sum</span>().item()</span>
<span id="cb9-38"><a href="#cb9-38" aria-hidden="true" tabindex="-1"></a>total <span class="op">=</span> <span class="bu">len</span>(zero_shot_labels)</span>
<span id="cb9-39"><a href="#cb9-39" aria-hidden="true" tabindex="-1"></a>zero_shot_accuracy <span class="op">=</span> correct <span class="op">/</span> total</span>
<span id="cb9-40"><a href="#cb9-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-41"><a href="#cb9-41" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Zero-Shot Accuracy: </span><span class="sc">{</span>zero_shot_accuracy<span class="sc">:.4f}</span><span class="ss"> (</span><span class="sc">{</span>zero_shot_accuracy<span class="op">*</span><span class="dv">100</span><span class="sc">:.2f}</span><span class="ss">%)"</span>)</span>
<span id="cb9-42"><a href="#cb9-42" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Random Baseline: </span><span class="sc">{</span><span class="fl">1.0</span><span class="op">/</span><span class="bu">len</span>(train_dataset.classes)<span class="sc">:.4f}</span><span class="ss"> (</span><span class="sc">{</span><span class="fl">100.0</span><span class="op">/</span><span class="bu">len</span>(train_dataset.classes)<span class="sc">:.2f}</span><span class="ss">%)"</span>)</span>
<span id="cb9-43"><a href="#cb9-43" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Correct: </span><span class="sc">{</span>correct<span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>total<span class="sc">}</span><span class="ss"> samples"</span>)</span>
<span id="cb9-44"><a href="#cb9-44" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f""</span>)</span>
<span id="cb9-45"><a href="#cb9-45" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="st">"Per-Class Zero-Shot Results:"</span>)</span>
<span id="cb9-46"><a href="#cb9-46" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="st">"-"</span> <span class="op">*</span> <span class="dv">60</span>)</span>
<span id="cb9-47"><a href="#cb9-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-48"><a href="#cb9-48" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> idx <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(zero_shot_labels)):</span>
<span id="cb9-49"><a href="#cb9-49" aria-hidden="true" tabindex="-1"></a>    true_label <span class="op">=</span> zero_shot_labels[idx].item()</span>
<span id="cb9-50"><a href="#cb9-50" aria-hidden="true" tabindex="-1"></a>    pred_label <span class="op">=</span> predicted[idx].item()</span>
<span id="cb9-51"><a href="#cb9-51" aria-hidden="true" tabindex="-1"></a>    class_name <span class="op">=</span> train_dataset.classes[true_label]</span>
<span id="cb9-52"><a href="#cb9-52" aria-hidden="true" tabindex="-1"></a>    pred_name <span class="op">=</span> train_dataset.classes[pred_label]</span>
<span id="cb9-53"><a href="#cb9-53" aria-hidden="true" tabindex="-1"></a>    correct_mark <span class="op">=</span> <span class="st">"âœ“"</span> <span class="cf">if</span> true_label <span class="op">==</span> pred_label <span class="cf">else</span> <span class="st">"âœ—"</span></span>
<span id="cb9-54"><a href="#cb9-54" aria-hidden="true" tabindex="-1"></a>    logger.info(<span class="ss">f"  </span><span class="sc">{</span>correct_mark<span class="sc">}</span><span class="ss"> </span><span class="sc">{</span>class_name<span class="sc">:20s}</span><span class="ss"> â†’ </span><span class="sc">{</span>pred_name<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Interpreting Zero-Shot Results
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Expected performance (1 sample per class):</strong></p>
<ul>
<li>Random guessing: ~11% (1 correct out of 9 classes)</li>
<li>Zero-shot Prithvi: 11-44% (1-4 correct out of 9)</li>
<li>Performance varies dramatically by class</li>
</ul>
<p><strong>Classes Prithvi might recognize:</strong></p>
<ul>
<li><strong>Likely correct</strong>: Forest, SeaLake (strong visual signatures, common in HLS training)</li>
<li><strong>Sometimes correct</strong>: Pasture, HerbaceousVegetation (agricultural patterns)</li>
<li><strong>Rarely correct</strong>: Highway, Industrial, Residential (fine-grained urban distinctions)</li>
</ul>
<p><strong>Why?</strong> Prithvi learned general geospatial features during pretraining on HLS imagery. Natural land cover classes with distinct spectral signatures are easier to recognize than specific urban subtypes.</p>
</div>
</div>
</section>
<section id="step-7-visualize-zero-shot-predictions" class="level3">
<h3 class="anchored" data-anchor-id="step-7-visualize-zero-shot-predictions">Step 7: Visualize Zero-Shot Predictions</h3>
<p>Letâ€™s visualize the zero-shot predictions on the same representative images:</p>
<div id="d081765c" class="cell">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize zero-shot predictions</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="st">"Visualizing zero-shot predictions..."</span>)</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>num_vis <span class="op">=</span> <span class="bu">len</span>(samples_per_class)</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>n_cols <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>n_rows <span class="op">=</span> <span class="bu">int</span>(np.ceil(num_vis <span class="op">/</span> n_cols))</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(n_rows, n_cols, figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">3</span><span class="op">*</span>n_rows))</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>axes <span class="op">=</span> axes.ravel()</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Already have predictions from Step 6</span></span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> idx, (class_idx, image) <span class="kw">in</span> <span class="bu">enumerate</span>(samples_per_class.items()):</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>    true_label <span class="op">=</span> class_idx</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>    pred_label <span class="op">=</span> predicted[idx].item()</span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create RGB visualization from original 13-band image</span></span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>    rgb <span class="op">=</span> image[[<span class="dv">3</span>, <span class="dv">2</span>, <span class="dv">1</span>], :, :].numpy()  <span class="co"># Red, Green, Blue</span></span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a>    rgb <span class="op">=</span> np.transpose(rgb, (<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">0</span>))</span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Normalize for display</span></span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a>    p2, p98 <span class="op">=</span> np.percentile(rgb, (<span class="dv">2</span>, <span class="dv">98</span>))</span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a>    rgb_norm <span class="op">=</span> np.clip((rgb <span class="op">-</span> p2) <span class="op">/</span> (p98 <span class="op">-</span> p2), <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Plot</span></span>
<span id="cb10-25"><a href="#cb10-25" aria-hidden="true" tabindex="-1"></a>    axes[idx].imshow(rgb_norm)</span>
<span id="cb10-26"><a href="#cb10-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-27"><a href="#cb10-27" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Color code: green if correct, red if wrong</span></span>
<span id="cb10-28"><a href="#cb10-28" aria-hidden="true" tabindex="-1"></a>    color <span class="op">=</span> <span class="st">'green'</span> <span class="cf">if</span> pred_label <span class="op">==</span> true_label <span class="cf">else</span> <span class="st">'red'</span></span>
<span id="cb10-29"><a href="#cb10-29" aria-hidden="true" tabindex="-1"></a>    axes[idx].set_title(</span>
<span id="cb10-30"><a href="#cb10-30" aria-hidden="true" tabindex="-1"></a>        <span class="ss">f"True: </span><span class="sc">{</span>train_dataset<span class="sc">.</span>classes[true_label]<span class="sc">}</span><span class="ch">\n</span><span class="ss">"</span></span>
<span id="cb10-31"><a href="#cb10-31" aria-hidden="true" tabindex="-1"></a>        <span class="ss">f"Pred: </span><span class="sc">{</span>train_dataset<span class="sc">.</span>classes[pred_label]<span class="sc">}</span><span class="ss">"</span>,</span>
<span id="cb10-32"><a href="#cb10-32" aria-hidden="true" tabindex="-1"></a>        color<span class="op">=</span>color,</span>
<span id="cb10-33"><a href="#cb10-33" aria-hidden="true" tabindex="-1"></a>        fontsize<span class="op">=</span><span class="dv">10</span></span>
<span id="cb10-34"><a href="#cb10-34" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb10-35"><a href="#cb10-35" aria-hidden="true" tabindex="-1"></a>    axes[idx].axis(<span class="st">'off'</span>)</span>
<span id="cb10-36"><a href="#cb10-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-37"><a href="#cb10-37" aria-hidden="true" tabindex="-1"></a><span class="co"># Hide any unused subplots</span></span>
<span id="cb10-38"><a href="#cb10-38" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> idx <span class="kw">in</span> <span class="bu">range</span>(num_vis, <span class="bu">len</span>(axes)):</span>
<span id="cb10-39"><a href="#cb10-39" aria-hidden="true" tabindex="-1"></a>    axes[idx].axis(<span class="st">'off'</span>)</span>
<span id="cb10-40"><a href="#cb10-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-41"><a href="#cb10-41" aria-hidden="true" tabindex="-1"></a>plt.suptitle(<span class="st">"Zero-Shot Predictions (Before Training)"</span>, fontsize<span class="op">=</span><span class="dv">14</span>, y<span class="op">=</span><span class="fl">0.995</span>)</span>
<span id="cb10-42"><a href="#cb10-42" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb10-43"><a href="#cb10-43" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb10-44"><a href="#cb10-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-45"><a href="#cb10-45" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Green titles = correct prediction | Red titles = incorrect prediction"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Zero-Shot Performance Analysis
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>What to look for:</strong></p>
<ol type="1">
<li><strong>Correct predictions</strong>: Classes the model identifies without training</li>
<li><strong>Systematic errors</strong>: Consistent misclassifications reveal what Prithvi confuses</li>
<li><strong>Transfer learning potential</strong>: Better than random = useful pretrained features</li>
</ol>
<p><strong>Common patterns:</strong></p>
<ul>
<li>Natural land cover (forest, water) often recognized</li>
<li>Urban classes frequently confused with each other</li>
<li>Agricultural subtypes hard to distinguish without fine-tuning</li>
</ul>
</div>
</div>
</section>
</section>
<section id="part-4-few-shot-learning---learning-from-limited-data" class="level2">
<h2 class="anchored" data-anchor-id="part-4-few-shot-learning---learning-from-limited-data">Part 4: Few-Shot Learning - Learning from Limited Data</h2>
<p>Zero-shot performance is limited by the randomly initialized decoder. But what if we had just a few examples per class? Letâ€™s explore two few-shot approaches that demonstrate the power of foundation models with minimal data.</p>
<section id="helper-create-few-shot-datasets" class="level3">
<h3 class="anchored" data-anchor-id="helper-create-few-shot-datasets">Helper: Create Few-Shot Datasets</h3>
<p>First, letâ€™s create a helper function to sample K examples per class from the training set.</p>
<div id="09d61bfa" class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> Subset</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> create_few_shot_dataset(dataset, k_shot<span class="op">=</span><span class="dv">5</span>, seed<span class="op">=</span><span class="dv">42</span>):</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Create a dataset with k examples per class.</span></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters</span></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a><span class="co">    ----------</span></span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a><span class="co">    dataset : Dataset</span></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a><span class="co">        Source dataset</span></span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a><span class="co">    k_shot : int</span></span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a><span class="co">        Number of examples per class</span></span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a><span class="co">    seed : int</span></span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a><span class="co">        Random seed for reproducibility</span></span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns</span></span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a><span class="co">    -------</span></span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a><span class="co">    Subset</span></span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a><span class="co">        Subset with k examples per class</span></span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a>    np.random.seed(seed)</span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a>    random.seed(seed)</span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-24"><a href="#cb11-24" aria-hidden="true" tabindex="-1"></a>    num_classes <span class="op">=</span> <span class="bu">len</span>(dataset.classes)</span>
<span id="cb11-25"><a href="#cb11-25" aria-hidden="true" tabindex="-1"></a>    samples_per_class <span class="op">=</span> {i: [] <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(num_classes)}</span>
<span id="cb11-26"><a href="#cb11-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-27"><a href="#cb11-27" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Random sampling to find k examples per class</span></span>
<span id="cb11-28"><a href="#cb11-28" aria-hidden="true" tabindex="-1"></a>    random_indices <span class="op">=</span> random.sample(<span class="bu">range</span>(<span class="bu">len</span>(dataset)), <span class="bu">min</span>(<span class="bu">len</span>(dataset), num_classes <span class="op">*</span> k_shot <span class="op">*</span> <span class="dv">10</span>))</span>
<span id="cb11-29"><a href="#cb11-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-30"><a href="#cb11-30" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> idx <span class="kw">in</span> random_indices:</span>
<span id="cb11-31"><a href="#cb11-31" aria-hidden="true" tabindex="-1"></a>        sample <span class="op">=</span> dataset[idx]</span>
<span id="cb11-32"><a href="#cb11-32" aria-hidden="true" tabindex="-1"></a>        label <span class="op">=</span> sample[<span class="st">'label'</span>]</span>
<span id="cb11-33"><a href="#cb11-33" aria-hidden="true" tabindex="-1"></a>        label_idx <span class="op">=</span> <span class="bu">int</span>(label) <span class="cf">if</span> <span class="bu">hasattr</span>(label, <span class="st">'item'</span>) <span class="cf">else</span> label</span>
<span id="cb11-34"><a href="#cb11-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-35"><a href="#cb11-35" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">len</span>(samples_per_class[label_idx]) <span class="op">&lt;</span> k_shot:</span>
<span id="cb11-36"><a href="#cb11-36" aria-hidden="true" tabindex="-1"></a>            samples_per_class[label_idx].append(idx)</span>
<span id="cb11-37"><a href="#cb11-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-38"><a href="#cb11-38" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Stop when we have k examples for all classes</span></span>
<span id="cb11-39"><a href="#cb11-39" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">all</span>(<span class="bu">len</span>(v) <span class="op">==</span> k_shot <span class="cf">for</span> v <span class="kw">in</span> samples_per_class.values()):</span>
<span id="cb11-40"><a href="#cb11-40" aria-hidden="true" tabindex="-1"></a>            <span class="cf">break</span></span>
<span id="cb11-41"><a href="#cb11-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-42"><a href="#cb11-42" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Flatten to single list of indices</span></span>
<span id="cb11-43"><a href="#cb11-43" aria-hidden="true" tabindex="-1"></a>    indices <span class="op">=</span> [idx <span class="cf">for</span> class_indices <span class="kw">in</span> samples_per_class.values() <span class="cf">for</span> idx <span class="kw">in</span> class_indices]</span>
<span id="cb11-44"><a href="#cb11-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-45"><a href="#cb11-45" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> Subset(dataset, indices), samples_per_class</span>
<span id="cb11-46"><a href="#cb11-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-47"><a href="#cb11-47" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="st">"Few-shot dataset helper created"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="step-6a-prototype-networks---no-training-required" class="level3">
<h3 class="anchored" data-anchor-id="step-6a-prototype-networks---no-training-required">Step 6a: Prototype Networks - No Training Required</h3>
<p>Prototype networks use the modelâ€™s output representations to classify by finding the nearest prototype (mean representation per class). Weâ€™ll use the modelâ€™s logits (pre-softmax outputs) as feature representations.</p>
<p><strong>Key idea</strong>: Even with a randomly initialized decoder, the modelâ€™s output space should show some structure that we can exploit with a few labeled examples.</p>
<div id="3837f5b0" class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create 5-shot support set</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>k_shot <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>few_shot_subset, few_shot_indices <span class="op">=</span> create_few_shot_dataset(train_dataset, k_shot<span class="op">=</span>k_shot)</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Created </span><span class="sc">{</span>k_shot<span class="sc">}</span><span class="ss">-shot dataset:"</span>)</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Total samples: </span><span class="sc">{</span><span class="bu">len</span>(few_shot_subset)<span class="sc">}</span><span class="ss"> (</span><span class="sc">{</span>k_shot<span class="sc">}</span><span class="ss"> per class Ã— </span><span class="sc">{</span><span class="bu">len</span>(train_dataset.classes)<span class="sc">}</span><span class="ss"> classes)"</span>)</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="st">""</span>)</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract features from backbone for support set</span></span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">eval</span>()</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>support_features <span class="op">=</span> []</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>support_labels <span class="op">=</span> []</span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="st">"Extracting features from Prithvi backbone..."</span>)</span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> class_idx, indices <span class="kw">in</span> few_shot_indices.items():</span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>        class_features <span class="op">=</span> []</span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> idx <span class="kw">in</span> indices:</span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a>            sample <span class="op">=</span> train_dataset[idx]</span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Apply transforms</span></span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a>            transformed <span class="op">=</span> transform(sample)</span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a>            image <span class="op">=</span> transformed[<span class="st">'image'</span>].unsqueeze(<span class="dv">0</span>).to(device)</span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Extract features from backbone</span></span>
<span id="cb12-25"><a href="#cb12-25" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Use model forward pass and extract features before final classification</span></span>
<span id="cb12-26"><a href="#cb12-26" aria-hidden="true" tabindex="-1"></a>            outputs <span class="op">=</span> model(image)</span>
<span id="cb12-27"><a href="#cb12-27" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="bu">hasattr</span>(outputs, <span class="st">'output'</span>):</span>
<span id="cb12-28"><a href="#cb12-28" aria-hidden="true" tabindex="-1"></a>                features <span class="op">=</span> outputs.output</span>
<span id="cb12-29"><a href="#cb12-29" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb12-30"><a href="#cb12-30" aria-hidden="true" tabindex="-1"></a>                features <span class="op">=</span> outputs</span>
<span id="cb12-31"><a href="#cb12-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-32"><a href="#cb12-32" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Features are already pooled to (batch, num_classes) by FCNDecoder</span></span>
<span id="cb12-33"><a href="#cb12-33" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Use these as feature representations</span></span>
<span id="cb12-34"><a href="#cb12-34" aria-hidden="true" tabindex="-1"></a>            features <span class="op">=</span> features.squeeze(<span class="dv">0</span>)  <span class="co"># Remove batch dimension</span></span>
<span id="cb12-35"><a href="#cb12-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-36"><a href="#cb12-36" aria-hidden="true" tabindex="-1"></a>            class_features.append(features)</span>
<span id="cb12-37"><a href="#cb12-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-38"><a href="#cb12-38" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Compute prototype (mean of support features)</span></span>
<span id="cb12-39"><a href="#cb12-39" aria-hidden="true" tabindex="-1"></a>        prototype <span class="op">=</span> torch.stack(class_features).mean(dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb12-40"><a href="#cb12-40" aria-hidden="true" tabindex="-1"></a>        support_features.append(prototype)</span>
<span id="cb12-41"><a href="#cb12-41" aria-hidden="true" tabindex="-1"></a>        support_labels.append(class_idx)</span>
<span id="cb12-42"><a href="#cb12-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-43"><a href="#cb12-43" aria-hidden="true" tabindex="-1"></a>support_features <span class="op">=</span> torch.stack(support_features)  <span class="co"># (num_classes, feature_dim)</span></span>
<span id="cb12-44"><a href="#cb12-44" aria-hidden="true" tabindex="-1"></a>support_labels <span class="op">=</span> torch.tensor(support_labels).to(device)</span>
<span id="cb12-45"><a href="#cb12-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-46"><a href="#cb12-46" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Extracted prototypes: </span><span class="sc">{</span>support_features<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb12-47"><a href="#cb12-47" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="st">""</span>)</span>
<span id="cb12-48"><a href="#cb12-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-49"><a href="#cb12-49" aria-hidden="true" tabindex="-1"></a><span class="co"># Classify test samples by nearest prototype</span></span>
<span id="cb12-50"><a href="#cb12-50" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="st">"Classifying with prototype networks..."</span>)</span>
<span id="cb12-51"><a href="#cb12-51" aria-hidden="true" tabindex="-1"></a>test_features <span class="op">=</span> []</span>
<span id="cb12-52"><a href="#cb12-52" aria-hidden="true" tabindex="-1"></a>test_labels <span class="op">=</span> []</span>
<span id="cb12-53"><a href="#cb12-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-54"><a href="#cb12-54" aria-hidden="true" tabindex="-1"></a><span class="co"># Use same representative samples as zero-shot</span></span>
<span id="cb12-55"><a href="#cb12-55" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> class_idx, image <span class="kw">in</span> samples_per_class.items():</span>
<span id="cb12-56"><a href="#cb12-56" aria-hidden="true" tabindex="-1"></a>    sample <span class="op">=</span> {<span class="st">'image'</span>: image, <span class="st">'label'</span>: class_idx}</span>
<span id="cb12-57"><a href="#cb12-57" aria-hidden="true" tabindex="-1"></a>    transformed <span class="op">=</span> transform(sample)</span>
<span id="cb12-58"><a href="#cb12-58" aria-hidden="true" tabindex="-1"></a>    image_tensor <span class="op">=</span> transformed[<span class="st">'image'</span>].unsqueeze(<span class="dv">0</span>).to(device)</span>
<span id="cb12-59"><a href="#cb12-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-60"><a href="#cb12-60" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb12-61"><a href="#cb12-61" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Extract features</span></span>
<span id="cb12-62"><a href="#cb12-62" aria-hidden="true" tabindex="-1"></a>        outputs <span class="op">=</span> model(image_tensor)</span>
<span id="cb12-63"><a href="#cb12-63" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">hasattr</span>(outputs, <span class="st">'output'</span>):</span>
<span id="cb12-64"><a href="#cb12-64" aria-hidden="true" tabindex="-1"></a>            features <span class="op">=</span> outputs.output</span>
<span id="cb12-65"><a href="#cb12-65" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb12-66"><a href="#cb12-66" aria-hidden="true" tabindex="-1"></a>            features <span class="op">=</span> outputs</span>
<span id="cb12-67"><a href="#cb12-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-68"><a href="#cb12-68" aria-hidden="true" tabindex="-1"></a>        features <span class="op">=</span> features.squeeze(<span class="dv">0</span>)  <span class="co"># Remove batch dimension</span></span>
<span id="cb12-69"><a href="#cb12-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-70"><a href="#cb12-70" aria-hidden="true" tabindex="-1"></a>        test_features.append(features)</span>
<span id="cb12-71"><a href="#cb12-71" aria-hidden="true" tabindex="-1"></a>        test_labels.append(class_idx)</span>
<span id="cb12-72"><a href="#cb12-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-73"><a href="#cb12-73" aria-hidden="true" tabindex="-1"></a>test_features <span class="op">=</span> torch.stack(test_features)</span>
<span id="cb12-74"><a href="#cb12-74" aria-hidden="true" tabindex="-1"></a>test_labels <span class="op">=</span> torch.tensor(test_labels).to(device)</span>
<span id="cb12-75"><a href="#cb12-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-76"><a href="#cb12-76" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute distances to prototypes (cosine similarity)</span></span>
<span id="cb12-77"><a href="#cb12-77" aria-hidden="true" tabindex="-1"></a>test_features_norm <span class="op">=</span> torch.nn.functional.normalize(test_features, dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb12-78"><a href="#cb12-78" aria-hidden="true" tabindex="-1"></a>support_features_norm <span class="op">=</span> torch.nn.functional.normalize(support_features, dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb12-79"><a href="#cb12-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-80"><a href="#cb12-80" aria-hidden="true" tabindex="-1"></a>similarities <span class="op">=</span> torch.mm(test_features_norm, support_features_norm.t())  <span class="co"># (test, classes)</span></span>
<span id="cb12-81"><a href="#cb12-81" aria-hidden="true" tabindex="-1"></a>proto_predictions <span class="op">=</span> similarities.argmax(dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb12-82"><a href="#cb12-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-83"><a href="#cb12-83" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate accuracy</span></span>
<span id="cb12-84"><a href="#cb12-84" aria-hidden="true" tabindex="-1"></a>proto_correct <span class="op">=</span> proto_predictions.eq(test_labels).<span class="bu">sum</span>().item()</span>
<span id="cb12-85"><a href="#cb12-85" aria-hidden="true" tabindex="-1"></a>proto_accuracy <span class="op">=</span> proto_correct <span class="op">/</span> <span class="bu">len</span>(test_labels)</span>
<span id="cb12-86"><a href="#cb12-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-87"><a href="#cb12-87" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Prototype Network Results (</span><span class="sc">{</span>k_shot<span class="sc">}</span><span class="ss">-shot)"</span>)</span>
<span id="cb12-88"><a href="#cb12-88" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="st">"="</span> <span class="op">*</span> <span class="dv">60</span>)</span>
<span id="cb12-89"><a href="#cb12-89" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Accuracy: </span><span class="sc">{</span>proto_accuracy<span class="sc">:.4f}</span><span class="ss"> (</span><span class="sc">{</span>proto_accuracy<span class="op">*</span><span class="dv">100</span><span class="sc">:.2f}</span><span class="ss">%)"</span>)</span>
<span id="cb12-90"><a href="#cb12-90" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Zero-shot (Step 6): </span><span class="sc">{</span>zero_shot_accuracy<span class="sc">:.4f}</span><span class="ss"> (</span><span class="sc">{</span>zero_shot_accuracy<span class="op">*</span><span class="dv">100</span><span class="sc">:.2f}</span><span class="ss">%)"</span>)</span>
<span id="cb12-91"><a href="#cb12-91" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Random Baseline: </span><span class="sc">{</span><span class="fl">1.0</span><span class="op">/</span><span class="bu">len</span>(train_dataset.classes)<span class="sc">:.4f}</span><span class="ss"> (</span><span class="sc">{</span><span class="fl">100.0</span><span class="op">/</span><span class="bu">len</span>(train_dataset.classes)<span class="sc">:.2f}</span><span class="ss">%)"</span>)</span>
<span id="cb12-92"><a href="#cb12-92" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Correct: </span><span class="sc">{</span>proto_correct<span class="sc">}</span><span class="ss">/</span><span class="sc">{</span><span class="bu">len</span>(test_labels)<span class="sc">}</span><span class="ss"> samples"</span>)</span>
<span id="cb12-93"><a href="#cb12-93" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="st">""</span>)</span>
<span id="cb12-94"><a href="#cb12-94" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="st">"Per-Class Prototype Results:"</span>)</span>
<span id="cb12-95"><a href="#cb12-95" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="st">"-"</span> <span class="op">*</span> <span class="dv">60</span>)</span>
<span id="cb12-96"><a href="#cb12-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-97"><a href="#cb12-97" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> idx <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(test_labels)):</span>
<span id="cb12-98"><a href="#cb12-98" aria-hidden="true" tabindex="-1"></a>    true_label <span class="op">=</span> test_labels[idx].item()</span>
<span id="cb12-99"><a href="#cb12-99" aria-hidden="true" tabindex="-1"></a>    pred_label <span class="op">=</span> proto_predictions[idx].item()</span>
<span id="cb12-100"><a href="#cb12-100" aria-hidden="true" tabindex="-1"></a>    class_name <span class="op">=</span> train_dataset.classes[true_label]</span>
<span id="cb12-101"><a href="#cb12-101" aria-hidden="true" tabindex="-1"></a>    pred_name <span class="op">=</span> train_dataset.classes[pred_label]</span>
<span id="cb12-102"><a href="#cb12-102" aria-hidden="true" tabindex="-1"></a>    correct_mark <span class="op">=</span> <span class="st">"âœ“"</span> <span class="cf">if</span> true_label <span class="op">==</span> pred_label <span class="cf">else</span> <span class="st">"âœ—"</span></span>
<span id="cb12-103"><a href="#cb12-103" aria-hidden="true" tabindex="-1"></a>    logger.info(<span class="ss">f"  </span><span class="sc">{</span>correct_mark<span class="sc">}</span><span class="ss"> </span><span class="sc">{</span>class_name<span class="sc">:20s}</span><span class="ss"> â†’ </span><span class="sc">{</span>pred_name<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Understanding Prototype Networks
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>How it works:</strong></p>
<ol type="1">
<li>Pass K examples per class through the model to get output representations (logits)</li>
<li>Compute prototype (mean logits) for each class</li>
<li>Classify new samples by finding nearest prototype using cosine similarity</li>
</ol>
<p><strong>Why itâ€™s better than zero-shot:</strong></p>
<ul>
<li>Uses a few labeled examples to establish class centroids in output space</li>
<li>No training required - just forward passes and averaging</li>
<li>Expected performance: 30-50% (vs 11% zero-shot)</li>
</ul>
<p><strong>Key insight</strong>: Even with a randomly initialized decoder, the output space has enough structure from the Prithvi backbone that averaging a few examples per class creates meaningful prototypes.</p>
</div>
</div>
</section>
<section id="step-6b-linear-probing---fast-adaptation" class="level3">
<h3 class="anchored" data-anchor-id="step-6b-linear-probing---fast-adaptation">Step 6b: Linear Probing - Fast Adaptation</h3>
<p>Linear probing freezes the backbone and trains only the decoder head with few examples. This is much faster than full fine-tuning.</p>
<div id="88204d6f" class="cell">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create fresh model for linear probing</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>linear_probe_model <span class="op">=</span> model_factory.build_model(</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>    task<span class="op">=</span><span class="st">"classification"</span>,</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>    backbone<span class="op">=</span><span class="st">"prithvi_eo_v1_100"</span>,</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>    decoder<span class="op">=</span><span class="st">"FCNDecoder"</span>,</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>    num_classes<span class="op">=</span>num_classes</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>linear_probe_model <span class="op">=</span> linear_probe_model.to(device)</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Freeze backbone completely</span></span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="st">"Freezing Prithvi backbone..."</span>)</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> name, param <span class="kw">in</span> linear_probe_model.named_parameters():</span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="st">'encoder'</span> <span class="kw">in</span> name <span class="kw">or</span> <span class="st">'backbone'</span> <span class="kw">in</span> name <span class="kw">or</span> <span class="st">'model.model'</span> <span class="kw">in</span> name:</span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>        param.requires_grad <span class="op">=</span> <span class="va">False</span></span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>trainable <span class="op">=</span> <span class="bu">sum</span>(p.numel() <span class="cf">for</span> p <span class="kw">in</span> linear_probe_model.parameters() <span class="cf">if</span> p.requires_grad)</span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>total <span class="op">=</span> <span class="bu">sum</span>(p.numel() <span class="cf">for</span> p <span class="kw">in</span> linear_probe_model.parameters())</span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Trainable parameters: </span><span class="sc">{</span>trainable<span class="sc">:,}</span><span class="ss"> / </span><span class="sc">{</span>total<span class="sc">:,}</span><span class="ss"> (</span><span class="sc">{</span><span class="dv">100</span><span class="op">*</span>trainable<span class="op">/</span>total<span class="sc">:.1f}</span><span class="ss">%)"</span>)</span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="st">""</span>)</span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Try different k-shot settings</span></span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a>k_shots <span class="op">=</span> [<span class="dv">1</span>, <span class="dv">5</span>, <span class="dv">10</span>]</span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a>linear_probe_results <span class="op">=</span> {}</span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k <span class="kw">in</span> k_shots:</span>
<span id="cb13-26"><a href="#cb13-26" aria-hidden="true" tabindex="-1"></a>    logger.info(<span class="ss">f"Linear Probing: </span><span class="sc">{</span>k<span class="sc">}</span><span class="ss">-shot"</span>)</span>
<span id="cb13-27"><a href="#cb13-27" aria-hidden="true" tabindex="-1"></a>    logger.info(<span class="st">"="</span> <span class="op">*</span> <span class="dv">60</span>)</span>
<span id="cb13-28"><a href="#cb13-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-29"><a href="#cb13-29" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create k-shot dataset</span></span>
<span id="cb13-30"><a href="#cb13-30" aria-hidden="true" tabindex="-1"></a>    few_shot_subset, _ <span class="op">=</span> create_few_shot_dataset(train_dataset, k_shot<span class="op">=</span>k)</span>
<span id="cb13-31"><a href="#cb13-31" aria-hidden="true" tabindex="-1"></a>    few_shot_transformed <span class="op">=</span> TransformedDataset(few_shot_subset, transform)</span>
<span id="cb13-32"><a href="#cb13-32" aria-hidden="true" tabindex="-1"></a>    few_shot_loader <span class="op">=</span> DataLoader(few_shot_transformed, batch_size<span class="op">=</span><span class="bu">min</span>(<span class="dv">32</span>, <span class="bu">len</span>(few_shot_transformed)), shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb13-33"><a href="#cb13-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-34"><a href="#cb13-34" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Reset decoder weights</span></span>
<span id="cb13-35"><a href="#cb13-35" aria-hidden="true" tabindex="-1"></a>    linear_probe_model <span class="op">=</span> model_factory.build_model(</span>
<span id="cb13-36"><a href="#cb13-36" aria-hidden="true" tabindex="-1"></a>        task<span class="op">=</span><span class="st">"classification"</span>,</span>
<span id="cb13-37"><a href="#cb13-37" aria-hidden="true" tabindex="-1"></a>        backbone<span class="op">=</span><span class="st">"prithvi_eo_v1_100"</span>,</span>
<span id="cb13-38"><a href="#cb13-38" aria-hidden="true" tabindex="-1"></a>        decoder<span class="op">=</span><span class="st">"FCNDecoder"</span>,</span>
<span id="cb13-39"><a href="#cb13-39" aria-hidden="true" tabindex="-1"></a>        num_classes<span class="op">=</span>num_classes</span>
<span id="cb13-40"><a href="#cb13-40" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb13-41"><a href="#cb13-41" aria-hidden="true" tabindex="-1"></a>    linear_probe_model <span class="op">=</span> linear_probe_model.to(device)</span>
<span id="cb13-42"><a href="#cb13-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-43"><a href="#cb13-43" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Freeze backbone</span></span>
<span id="cb13-44"><a href="#cb13-44" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> name, param <span class="kw">in</span> linear_probe_model.named_parameters():</span>
<span id="cb13-45"><a href="#cb13-45" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="st">'encoder'</span> <span class="kw">in</span> name <span class="kw">or</span> <span class="st">'backbone'</span> <span class="kw">in</span> name <span class="kw">or</span> <span class="st">'model.model'</span> <span class="kw">in</span> name:</span>
<span id="cb13-46"><a href="#cb13-46" aria-hidden="true" tabindex="-1"></a>            param.requires_grad <span class="op">=</span> <span class="va">False</span></span>
<span id="cb13-47"><a href="#cb13-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-48"><a href="#cb13-48" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Train decoder only</span></span>
<span id="cb13-49"><a href="#cb13-49" aria-hidden="true" tabindex="-1"></a>    probe_optimizer <span class="op">=</span> torch.optim.Adam(</span>
<span id="cb13-50"><a href="#cb13-50" aria-hidden="true" tabindex="-1"></a>        [p <span class="cf">for</span> p <span class="kw">in</span> linear_probe_model.parameters() <span class="cf">if</span> p.requires_grad],</span>
<span id="cb13-51"><a href="#cb13-51" aria-hidden="true" tabindex="-1"></a>        lr<span class="op">=</span><span class="fl">1e-3</span>  <span class="co"># Higher LR since only training head</span></span>
<span id="cb13-52"><a href="#cb13-52" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb13-53"><a href="#cb13-53" aria-hidden="true" tabindex="-1"></a>    probe_criterion <span class="op">=</span> nn.CrossEntropyLoss()</span>
<span id="cb13-54"><a href="#cb13-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-55"><a href="#cb13-55" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Train for more epochs on small dataset</span></span>
<span id="cb13-56"><a href="#cb13-56" aria-hidden="true" tabindex="-1"></a>    epochs <span class="op">=</span> <span class="dv">50</span></span>
<span id="cb13-57"><a href="#cb13-57" aria-hidden="true" tabindex="-1"></a>    linear_probe_model.train()</span>
<span id="cb13-58"><a href="#cb13-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-59"><a href="#cb13-59" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb13-60"><a href="#cb13-60" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> images, labels <span class="kw">in</span> few_shot_loader:</span>
<span id="cb13-61"><a href="#cb13-61" aria-hidden="true" tabindex="-1"></a>            images <span class="op">=</span> images.to(device)</span>
<span id="cb13-62"><a href="#cb13-62" aria-hidden="true" tabindex="-1"></a>            labels <span class="op">=</span> labels.to(device)</span>
<span id="cb13-63"><a href="#cb13-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-64"><a href="#cb13-64" aria-hidden="true" tabindex="-1"></a>            probe_optimizer.zero_grad()</span>
<span id="cb13-65"><a href="#cb13-65" aria-hidden="true" tabindex="-1"></a>            outputs <span class="op">=</span> linear_probe_model(images)</span>
<span id="cb13-66"><a href="#cb13-66" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="bu">hasattr</span>(outputs, <span class="st">'output'</span>):</span>
<span id="cb13-67"><a href="#cb13-67" aria-hidden="true" tabindex="-1"></a>                outputs <span class="op">=</span> outputs.output</span>
<span id="cb13-68"><a href="#cb13-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-69"><a href="#cb13-69" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> probe_criterion(outputs, labels)</span>
<span id="cb13-70"><a href="#cb13-70" aria-hidden="true" tabindex="-1"></a>            loss.backward()</span>
<span id="cb13-71"><a href="#cb13-71" aria-hidden="true" tabindex="-1"></a>            probe_optimizer.step()</span>
<span id="cb13-72"><a href="#cb13-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-73"><a href="#cb13-73" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Evaluate on same test samples</span></span>
<span id="cb13-74"><a href="#cb13-74" aria-hidden="true" tabindex="-1"></a>    linear_probe_model.<span class="bu">eval</span>()</span>
<span id="cb13-75"><a href="#cb13-75" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb13-76"><a href="#cb13-76" aria-hidden="true" tabindex="-1"></a>        outputs <span class="op">=</span> linear_probe_model(zero_shot_images)</span>
<span id="cb13-77"><a href="#cb13-77" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">hasattr</span>(outputs, <span class="st">'output'</span>):</span>
<span id="cb13-78"><a href="#cb13-78" aria-hidden="true" tabindex="-1"></a>            outputs <span class="op">=</span> outputs.output</span>
<span id="cb13-79"><a href="#cb13-79" aria-hidden="true" tabindex="-1"></a>        _, linear_predictions <span class="op">=</span> outputs.<span class="bu">max</span>(<span class="dv">1</span>)</span>
<span id="cb13-80"><a href="#cb13-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-81"><a href="#cb13-81" aria-hidden="true" tabindex="-1"></a>    linear_correct <span class="op">=</span> linear_predictions.eq(zero_shot_labels).<span class="bu">sum</span>().item()</span>
<span id="cb13-82"><a href="#cb13-82" aria-hidden="true" tabindex="-1"></a>    linear_accuracy <span class="op">=</span> linear_correct <span class="op">/</span> <span class="bu">len</span>(zero_shot_labels)</span>
<span id="cb13-83"><a href="#cb13-83" aria-hidden="true" tabindex="-1"></a>    linear_probe_results[k] <span class="op">=</span> linear_accuracy</span>
<span id="cb13-84"><a href="#cb13-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-85"><a href="#cb13-85" aria-hidden="true" tabindex="-1"></a>    logger.info(<span class="ss">f"</span><span class="sc">{</span>k<span class="sc">}</span><span class="ss">-shot Accuracy: </span><span class="sc">{</span>linear_accuracy<span class="sc">:.4f}</span><span class="ss"> (</span><span class="sc">{</span>linear_accuracy<span class="op">*</span><span class="dv">100</span><span class="sc">:.2f}</span><span class="ss">%)"</span>)</span>
<span id="cb13-86"><a href="#cb13-86" aria-hidden="true" tabindex="-1"></a>    logger.info(<span class="ss">f"Correct: </span><span class="sc">{</span>linear_correct<span class="sc">}</span><span class="ss">/</span><span class="sc">{</span><span class="bu">len</span>(zero_shot_labels)<span class="sc">}</span><span class="ss"> samples"</span>)</span>
<span id="cb13-87"><a href="#cb13-87" aria-hidden="true" tabindex="-1"></a>    logger.info(<span class="st">""</span>)</span>
<span id="cb13-88"><a href="#cb13-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-89"><a href="#cb13-89" aria-hidden="true" tabindex="-1"></a><span class="co"># Summary comparison</span></span>
<span id="cb13-90"><a href="#cb13-90" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="st">"Data Efficiency Comparison"</span>)</span>
<span id="cb13-91"><a href="#cb13-91" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="st">"="</span> <span class="op">*</span> <span class="dv">60</span>)</span>
<span id="cb13-92"><a href="#cb13-92" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Zero-shot (0 examples):     </span><span class="sc">{</span>zero_shot_accuracy<span class="sc">:.4f}</span><span class="ss"> (</span><span class="sc">{</span>zero_shot_accuracy<span class="op">*</span><span class="dv">100</span><span class="sc">:.2f}</span><span class="ss">%)"</span>)</span>
<span id="cb13-93"><a href="#cb13-93" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Prototypes (</span><span class="sc">{</span>k_shot<span class="sc">}</span><span class="ss">-shot): </span><span class="sc">{</span>proto_accuracy<span class="sc">:.4f}</span><span class="ss"> (</span><span class="sc">{</span>proto_accuracy<span class="op">*</span><span class="dv">100</span><span class="sc">:.2f}</span><span class="ss">%)"</span>)</span>
<span id="cb13-94"><a href="#cb13-94" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k, acc <span class="kw">in</span> linear_probe_results.items():</span>
<span id="cb13-95"><a href="#cb13-95" aria-hidden="true" tabindex="-1"></a>    logger.info(<span class="ss">f"Linear Probe (</span><span class="sc">{</span>k<span class="sc">}</span><span class="ss">-shot):    </span><span class="sc">{</span>acc<span class="sc">:.4f}</span><span class="ss"> (</span><span class="sc">{</span>acc<span class="op">*</span><span class="dv">100</span><span class="sc">:.2f}</span><span class="ss">%)"</span>)</span>
<span id="cb13-96"><a href="#cb13-96" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Random Baseline:            </span><span class="sc">{</span><span class="fl">1.0</span><span class="op">/</span><span class="bu">len</span>(train_dataset.classes)<span class="sc">:.4f}</span><span class="ss"> (</span><span class="sc">{</span><span class="fl">100.0</span><span class="op">/</span><span class="bu">len</span>(train_dataset.classes)<span class="sc">:.2f}</span><span class="ss">%)"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Understanding Linear Probing
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>How it works:</strong></p>
<ol type="1">
<li>Freeze pretrained backbone (no updates to 100M parameters)</li>
<li>Train only decoder head (~10K parameters)</li>
<li>Use few examples per class</li>
</ol>
<p><strong>Why itâ€™s efficient:</strong></p>
<ul>
<li>Much faster than full fine-tuning (seconds vs minutes)</li>
<li>Less prone to overfitting with few examples</li>
<li>Expected performance: 1-shot (30%), 5-shot (60%), 10-shot (75%)</li>
</ul>
<p><strong>Key insight</strong>: Foundation model features are so good that you can achieve strong performance by just learning a simple mapping (linear layer) from features to classes.</p>
</div>
</div>
</section>
</section>
<section id="part-5-full-fine-tuning---maximum-performance" class="level2">
<h2 class="anchored" data-anchor-id="part-5-full-fine-tuning---maximum-performance">Part 5: Full Fine-Tuning - Maximum Performance</h2>
<p>Now weâ€™ll (briefly!) train the model and compare performance to the zero-shot baseline.</p>
<section id="step-8-define-loss-function" class="level3">
<h3 class="anchored" data-anchor-id="step-8-define-loss-function">Step 8: Define Loss Function</h3>
<p>The loss function is used to train the model. It is a measure of how good the model is at predicting the correct class. We use the <code>CrossEntropyLoss</code> loss function for classification tasks.</p>
<div id="dc82c15a" class="cell" data-tangle="geogfm/training/simple_trainer.py">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>criterion <span class="op">=</span> nn.CrossEntropyLoss()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="step-7-define-optimizer" class="level3">
<h3 class="anchored" data-anchor-id="step-7-define-optimizer">Step 7: Define Optimizer</h3>
<p>The optimizer is used to update the modelâ€™s parameters. We use the <code>Adam</code> optimizer for classification tasks. It is a <a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent">stochastic gradient descent</a> optimizer that is a popular optimizer for deep learning.</p>
<div id="02570d3b" class="cell" data-tangle="geogfm/training/simple_trainer.py" data-mode="append">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> torch.optim.Adam(model.parameters(), lr<span class="op">=</span><span class="fl">1e-4</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="step-6-define-training-loop" class="level3">
<h3 class="anchored" data-anchor-id="step-6-define-training-loop">Step 6: Define Training Loop</h3>
<p>Letâ€™s break down what happens during training and validation of a deep learning model:</p>
<p><strong>Training Loop: Step-by-Step</strong></p>
<ol type="1">
<li><strong>Set model to training mode</strong>: This enables layers like dropout and batch normalization to behave appropriately during training.</li>
<li><strong>Iterate over training batches</strong>: For each batch in the training data:
<ul>
<li><strong>Move data to the device</strong> (CPU or GPU).</li>
<li><strong>Zero (reset) the gradients</strong> from the previous step.</li>
<li><strong>Forward pass</strong>: Input images are passed through the model to produce predictions.</li>
<li><strong>Compute the loss</strong>: The loss function compares predictions to ground-truth labels.</li>
<li><strong>Backward pass</strong>: Compute gradients of the loss with respect to each parameter.</li>
<li><strong>Optimizer step</strong>: Update parameters by taking a step in the direction that reduces the loss.</li>
<li><strong>Track statistics</strong>: Optionally record loss and accuracy for reporting.</li>
</ul></li>
</ol>
<div id="8ff19723" class="cell" data-tangle="geogfm/training/simple_trainer.py">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_one_epoch(model, train_loader, criterion, optimizer, device):</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a><span class="co">    Train for one epoch.</span></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters</span></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a><span class="co">    ----------</span></span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a><span class="co">    model : nn.Module</span></span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a><span class="co">        The model to train</span></span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a><span class="co">    train_loader : DataLoader</span></span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a><span class="co">        Training data loader</span></span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a><span class="co">    criterion : nn.Module</span></span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a><span class="co">        Loss function</span></span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a><span class="co">    optimizer : torch.optim.Optimizer</span></span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a><span class="co">        Optimizer for parameter updates</span></span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a><span class="co">    device : torch.device</span></span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a><span class="co">        Device to run on</span></span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns</span></span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a><span class="co">    -------</span></span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a><span class="co">    tuple</span></span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a><span class="co">        (average_loss, accuracy)</span></span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a>    model.train() <span class="co"># Set model to training mode</span></span>
<span id="cb16-27"><a href="#cb16-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-28"><a href="#cb16-28" aria-hidden="true" tabindex="-1"></a>    running_loss <span class="op">=</span> <span class="fl">0.0</span> <span class="co"># Running loss</span></span>
<span id="cb16-29"><a href="#cb16-29" aria-hidden="true" tabindex="-1"></a>    correct <span class="op">=</span> <span class="dv">0</span> <span class="co"># Correct predictions</span></span>
<span id="cb16-30"><a href="#cb16-30" aria-hidden="true" tabindex="-1"></a>    total <span class="op">=</span> <span class="dv">0</span> <span class="co"># Total predictions</span></span>
<span id="cb16-31"><a href="#cb16-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-32"><a href="#cb16-32" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> images, labels <span class="kw">in</span> train_loader:</span>
<span id="cb16-33"><a href="#cb16-33" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Move data to device</span></span>
<span id="cb16-34"><a href="#cb16-34" aria-hidden="true" tabindex="-1"></a>        images <span class="op">=</span> images.to(device) <span class="co"># Move data to device</span></span>
<span id="cb16-35"><a href="#cb16-35" aria-hidden="true" tabindex="-1"></a>        labels <span class="op">=</span> labels.to(device) <span class="co"># Move data to device</span></span>
<span id="cb16-36"><a href="#cb16-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-37"><a href="#cb16-37" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Zero gradients</span></span>
<span id="cb16-38"><a href="#cb16-38" aria-hidden="true" tabindex="-1"></a>        optimizer.zero_grad()</span>
<span id="cb16-39"><a href="#cb16-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-40"><a href="#cb16-40" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Forward pass</span></span>
<span id="cb16-41"><a href="#cb16-41" aria-hidden="true" tabindex="-1"></a>        outputs <span class="op">=</span> model(images)</span>
<span id="cb16-42"><a href="#cb16-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-43"><a href="#cb16-43" aria-hidden="true" tabindex="-1"></a>        <span class="co"># TerraTorch models return ModelOutput object</span></span>
<span id="cb16-44"><a href="#cb16-44" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Extract the tensor</span></span>
<span id="cb16-45"><a href="#cb16-45" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">hasattr</span>(outputs, <span class="st">'output'</span>):</span>
<span id="cb16-46"><a href="#cb16-46" aria-hidden="true" tabindex="-1"></a>            outputs <span class="op">=</span> outputs.output <span class="co"># Extract tensor from ModelOutput</span></span>
<span id="cb16-47"><a href="#cb16-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-48"><a href="#cb16-48" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Compute loss</span></span>
<span id="cb16-49"><a href="#cb16-49" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> criterion(outputs, labels) </span>
<span id="cb16-50"><a href="#cb16-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-51"><a href="#cb16-51" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Backward pass</span></span>
<span id="cb16-52"><a href="#cb16-52" aria-hidden="true" tabindex="-1"></a>        loss.backward()</span>
<span id="cb16-53"><a href="#cb16-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-54"><a href="#cb16-54" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Update parameters</span></span>
<span id="cb16-55"><a href="#cb16-55" aria-hidden="true" tabindex="-1"></a>        optimizer.step()</span>
<span id="cb16-56"><a href="#cb16-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-57"><a href="#cb16-57" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Track metrics</span></span>
<span id="cb16-58"><a href="#cb16-58" aria-hidden="true" tabindex="-1"></a>        running_loss <span class="op">+=</span> loss.item() <span class="co"># Add loss to running loss</span></span>
<span id="cb16-59"><a href="#cb16-59" aria-hidden="true" tabindex="-1"></a>        _, predicted <span class="op">=</span> outputs.<span class="bu">max</span>(<span class="dv">1</span>) <span class="co"># Get predicted class</span></span>
<span id="cb16-60"><a href="#cb16-60" aria-hidden="true" tabindex="-1"></a>        total <span class="op">+=</span> labels.size(<span class="dv">0</span>) <span class="co"># Add number of labels to total</span></span>
<span id="cb16-61"><a href="#cb16-61" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Add number of correct predictions to total</span></span>
<span id="cb16-62"><a href="#cb16-62" aria-hidden="true" tabindex="-1"></a>        correct <span class="op">+=</span> predicted.eq(labels).<span class="bu">sum</span>().item()</span>
<span id="cb16-63"><a href="#cb16-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-64"><a href="#cb16-64" aria-hidden="true" tabindex="-1"></a>    epoch_loss <span class="op">=</span> running_loss <span class="op">/</span> <span class="bu">len</span>(train_loader) <span class="co"># Calculate average loss</span></span>
<span id="cb16-65"><a href="#cb16-65" aria-hidden="true" tabindex="-1"></a>    epoch_acc <span class="op">=</span> correct <span class="op">/</span> total <span class="co"># Calculate average accuracy</span></span>
<span id="cb16-66"><a href="#cb16-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-67"><a href="#cb16-67" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> epoch_loss, epoch_acc</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>Validation Loop: Step-by-Step</strong></p>
<ol type="1">
<li><strong>Set model to evaluation mode</strong>: This disables/dropouts and sets batch normalization to use running statistics.</li>
<li><strong>Disable gradients</strong>: Turn off gradient computation to reduce memory and computation cost.</li>
<li><strong>Iterate over validation batches</strong>: For each batch in the validation data:
<ul>
<li><strong>Move data to the device</strong>.</li>
<li><strong>Forward pass</strong>: Pass images through the model to get predictions.</li>
<li><strong>Compute the loss</strong>: Evaluate how well predictions match ground-truth labels.</li>
<li><strong>Track statistics</strong>: Record loss and accuracy, just as in training.</li>
</ul></li>
</ol>
<div id="c8adb2bf" class="cell" data-tangle="geogfm/training/simple_trainer.py" data-mode="append">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> validate(model, val_loader, criterion, device):</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Validate the model.</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters</span></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a><span class="co">    ----------</span></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a><span class="co">    model : nn.Module</span></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a><span class="co">        The model to validate</span></span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a><span class="co">    val_loader : DataLoader</span></span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a><span class="co">        Validation data loader</span></span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a><span class="co">    criterion : nn.Module</span></span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a><span class="co">        Loss function</span></span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a><span class="co">    device : torch.device</span></span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a><span class="co">        Device to run on</span></span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns</span></span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a><span class="co">    -------</span></span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a><span class="co">    tuple</span></span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a><span class="co">        (average_loss, accuracy)</span></span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">eval</span>() <span class="co"># Set model to evaluation mode</span></span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a>    running_loss <span class="op">=</span> <span class="fl">0.0</span> <span class="co"># Running loss</span></span>
<span id="cb17-24"><a href="#cb17-24" aria-hidden="true" tabindex="-1"></a>    correct <span class="op">=</span> <span class="dv">0</span> <span class="co"># Correct predictions</span></span>
<span id="cb17-25"><a href="#cb17-25" aria-hidden="true" tabindex="-1"></a>    total <span class="op">=</span> <span class="dv">0</span> <span class="co"># Total predictions</span></span>
<span id="cb17-26"><a href="#cb17-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-27"><a href="#cb17-27" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb17-28"><a href="#cb17-28" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> images, labels <span class="kw">in</span> val_loader:</span>
<span id="cb17-29"><a href="#cb17-29" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Move data to device</span></span>
<span id="cb17-30"><a href="#cb17-30" aria-hidden="true" tabindex="-1"></a>            images <span class="op">=</span> images.to(device) <span class="co"># Move data to device</span></span>
<span id="cb17-31"><a href="#cb17-31" aria-hidden="true" tabindex="-1"></a>            labels <span class="op">=</span> labels.to(device) <span class="co"># Move data to device</span></span>
<span id="cb17-32"><a href="#cb17-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-33"><a href="#cb17-33" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Forward pass</span></span>
<span id="cb17-34"><a href="#cb17-34" aria-hidden="true" tabindex="-1"></a>            outputs <span class="op">=</span> model(images)</span>
<span id="cb17-35"><a href="#cb17-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-36"><a href="#cb17-36" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Extract tensor from ModelOutput</span></span>
<span id="cb17-37"><a href="#cb17-37" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="bu">hasattr</span>(outputs, <span class="st">'output'</span>):</span>
<span id="cb17-38"><a href="#cb17-38" aria-hidden="true" tabindex="-1"></a>                outputs <span class="op">=</span> outputs.output <span class="co"># Extract tensor from ModelOutput</span></span>
<span id="cb17-39"><a href="#cb17-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-40"><a href="#cb17-40" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Compute loss</span></span>
<span id="cb17-41"><a href="#cb17-41" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> criterion(outputs, labels) <span class="co"># Compute loss</span></span>
<span id="cb17-42"><a href="#cb17-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-43"><a href="#cb17-43" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Track metrics</span></span>
<span id="cb17-44"><a href="#cb17-44" aria-hidden="true" tabindex="-1"></a>            running_loss <span class="op">+=</span> loss.item() <span class="co"># Add loss to running loss</span></span>
<span id="cb17-45"><a href="#cb17-45" aria-hidden="true" tabindex="-1"></a>            _, predicted <span class="op">=</span> outputs.<span class="bu">max</span>(<span class="dv">1</span>) <span class="co"># Get predicted class</span></span>
<span id="cb17-46"><a href="#cb17-46" aria-hidden="true" tabindex="-1"></a>            total <span class="op">+=</span> labels.size(<span class="dv">0</span>) <span class="co"># Add number of labels to total</span></span>
<span id="cb17-47"><a href="#cb17-47" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Add number of correct predictions to total</span></span>
<span id="cb17-48"><a href="#cb17-48" aria-hidden="true" tabindex="-1"></a>            correct <span class="op">+=</span> predicted.eq(labels).<span class="bu">sum</span>().item()</span>
<span id="cb17-49"><a href="#cb17-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-50"><a href="#cb17-50" aria-hidden="true" tabindex="-1"></a>    epoch_loss <span class="op">=</span> running_loss <span class="op">/</span> <span class="bu">len</span>(val_loader) <span class="co"># Calculate average loss</span></span>
<span id="cb17-51"><a href="#cb17-51" aria-hidden="true" tabindex="-1"></a>    epoch_acc <span class="op">=</span> correct <span class="op">/</span> total <span class="co"># Calculate average accuracy</span></span>
<span id="cb17-52"><a href="#cb17-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-53"><a href="#cb17-53" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> epoch_loss, epoch_acc</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>Key Differences between Training and Validation Loops</strong>:</p>
<ul>
<li><strong>Parameter updates</strong>: Only the training loop updates parameters via backpropagation and optimizer steps; the validation loop does not.</li>
<li><strong>Model mode</strong>: The training loop uses <code>model.train()</code>; the validation loop uses <code>model.eval()</code>.</li>
<li><strong>Gradient calculation</strong>: Gradients are computed (and accumulated) in training, but turned off in validation (using <code>torch.no_grad()</code>).</li>
<li><strong>Purpose</strong>: Training optimizes the modelâ€™s weights, while validation evaluates the modelâ€™s current performance without influencing parameters.</li>
</ul>
<p>By writing out these loops explicitly, we gain transparency: itâ€™s much easier to spot bugs, add logging, customize behavior, and truly understand every step of model training.</p>
</section>
<section id="step-7-develop-a-training-loop-the-model" class="level3">
<h3 class="anchored" data-anchor-id="step-7-develop-a-training-loop-the-model">Step 7: Develop a Training Loop the Model</h3>
<p>Letâ€™s put it all together in the <code>train_model</code> function. This function:</p>
<ul>
<li>Implements both the training and validation loops.</li>
<li>Sets up the training and validation data loaders, and the optimizer.</li>
<li>Records the training and validation loss and accuracy for each epoch.</li>
<li>Prints the progress every 5 epochs.</li>
<li>Returns the training history (loss and accuracy for each epoch).</li>
</ul>
<div id="8a14a026" class="cell" data-tangle="geogfm/training/simple_trainer.py" data-mode="append">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_model(</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>    model, <span class="co"># Model to train</span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>    train_loader, </span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>    val_loader, <span class="co"># Validation data</span></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>    device<span class="op">=</span><span class="va">None</span>, <span class="co"># Device to use for training </span></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>    epochs<span class="op">=</span><span class="dv">15</span>, <span class="co"># Number of epochs</span></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>    lr<span class="op">=</span><span class="fl">1e-4</span>, <span class="co"># Learning rate</span></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>    criterion<span class="op">=</span><span class="va">None</span>, <span class="co"># Loss function</span></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>    optimizer<span class="op">=</span><span class="va">None</span>, <span class="co"># Optimizer</span></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a><span class="co">    Full training loop.</span></span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters</span></span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a><span class="co">    ----------</span></span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a><span class="co">    model : nn.Module</span></span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a><span class="co">        Model to train</span></span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a><span class="co">    train_loader : DataLoader</span></span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a><span class="co">        Training data</span></span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a><span class="co">    val_loader : DataLoader</span></span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a><span class="co">        Validation data</span></span>
<span id="cb18-22"><a href="#cb18-22" aria-hidden="true" tabindex="-1"></a><span class="co">    epochs : int</span></span>
<span id="cb18-23"><a href="#cb18-23" aria-hidden="true" tabindex="-1"></a><span class="co">        Number of epochs, default is 15</span></span>
<span id="cb18-24"><a href="#cb18-24" aria-hidden="true" tabindex="-1"></a><span class="co">    lr : float</span></span>
<span id="cb18-25"><a href="#cb18-25" aria-hidden="true" tabindex="-1"></a><span class="co">        Learning rate, default is 1e-4</span></span>
<span id="cb18-26"><a href="#cb18-26" aria-hidden="true" tabindex="-1"></a><span class="co">    device : torch.device</span></span>
<span id="cb18-27"><a href="#cb18-27" aria-hidden="true" tabindex="-1"></a><span class="co">        Device to use</span></span>
<span id="cb18-28"><a href="#cb18-28" aria-hidden="true" tabindex="-1"></a><span class="co">    criterion : nn.Module</span></span>
<span id="cb18-29"><a href="#cb18-29" aria-hidden="true" tabindex="-1"></a><span class="co">        Loss function, default is CrossEntropyLoss</span></span>
<span id="cb18-30"><a href="#cb18-30" aria-hidden="true" tabindex="-1"></a><span class="co">    optimizer : torch.optim.Optimizer</span></span>
<span id="cb18-31"><a href="#cb18-31" aria-hidden="true" tabindex="-1"></a><span class="co">        Optimizer, default is Adam</span></span>
<span id="cb18-32"><a href="#cb18-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-33"><a href="#cb18-33" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns</span></span>
<span id="cb18-34"><a href="#cb18-34" aria-hidden="true" tabindex="-1"></a><span class="co">    -------</span></span>
<span id="cb18-35"><a href="#cb18-35" aria-hidden="true" tabindex="-1"></a><span class="co">    dict</span></span>
<span id="cb18-36"><a href="#cb18-36" aria-hidden="true" tabindex="-1"></a><span class="co">        Training history with losses and accuracies</span></span>
<span id="cb18-37"><a href="#cb18-37" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb18-38"><a href="#cb18-38" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Setup training</span></span>
<span id="cb18-39"><a href="#cb18-39" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> criterion <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb18-40"><a href="#cb18-40" aria-hidden="true" tabindex="-1"></a>        logger.info(<span class="st">"Using default loss function: CrossEntropyLoss"</span>)</span>
<span id="cb18-41"><a href="#cb18-41" aria-hidden="true" tabindex="-1"></a>        criterion <span class="op">=</span> nn.CrossEntropyLoss()</span>
<span id="cb18-42"><a href="#cb18-42" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> optimizer <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb18-43"><a href="#cb18-43" aria-hidden="true" tabindex="-1"></a>        logger.info(<span class="st">"Using default optimizer: Adam"</span>)</span>
<span id="cb18-44"><a href="#cb18-44" aria-hidden="true" tabindex="-1"></a>        optimizer <span class="op">=</span> torch.optim.Adam(model.parameters(), lr<span class="op">=</span>lr)</span>
<span id="cb18-45"><a href="#cb18-45" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> device <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb18-46"><a href="#cb18-46" aria-hidden="true" tabindex="-1"></a>        logger.info(<span class="st">"Using default device: cpu"</span>)</span>
<span id="cb18-47"><a href="#cb18-47" aria-hidden="true" tabindex="-1"></a>        device <span class="op">=</span> <span class="st">'cpu'</span></span>
<span id="cb18-48"><a href="#cb18-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-49"><a href="#cb18-49" aria-hidden="true" tabindex="-1"></a>    history <span class="op">=</span> {</span>
<span id="cb18-50"><a href="#cb18-50" aria-hidden="true" tabindex="-1"></a>        <span class="st">'train_loss'</span>: [],  <span class="co"># Training loss</span></span>
<span id="cb18-51"><a href="#cb18-51" aria-hidden="true" tabindex="-1"></a>        <span class="st">'train_acc'</span>: [],  <span class="co"># Training accuracy</span></span>
<span id="cb18-52"><a href="#cb18-52" aria-hidden="true" tabindex="-1"></a>        <span class="st">'val_loss'</span>: [],  <span class="co"># Validation loss</span></span>
<span id="cb18-53"><a href="#cb18-53" aria-hidden="true" tabindex="-1"></a>        <span class="st">'val_acc'</span>: []  <span class="co"># Validation accuracy</span></span>
<span id="cb18-54"><a href="#cb18-54" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb18-55"><a href="#cb18-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-56"><a href="#cb18-56" aria-hidden="true" tabindex="-1"></a>    logger.info(<span class="ss">f"Training for </span><span class="sc">{</span>epochs<span class="sc">}</span><span class="ss"> epochs..."</span>)</span>
<span id="cb18-57"><a href="#cb18-57" aria-hidden="true" tabindex="-1"></a>    logger.info(<span class="ss">f"Device: </span><span class="sc">{</span>device<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb18-58"><a href="#cb18-58" aria-hidden="true" tabindex="-1"></a>    logger.info(<span class="ss">f"Learning rate: </span><span class="sc">{</span>lr<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb18-59"><a href="#cb18-59" aria-hidden="true" tabindex="-1"></a>    logger.info(<span class="ss">f""</span>)</span>
<span id="cb18-60"><a href="#cb18-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-61"><a href="#cb18-61" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb18-62"><a href="#cb18-62" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Train</span></span>
<span id="cb18-63"><a href="#cb18-63" aria-hidden="true" tabindex="-1"></a>        train_loss, train_acc <span class="op">=</span> train_one_epoch(</span>
<span id="cb18-64"><a href="#cb18-64" aria-hidden="true" tabindex="-1"></a>            model, train_loader, criterion, optimizer, device</span>
<span id="cb18-65"><a href="#cb18-65" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb18-66"><a href="#cb18-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-67"><a href="#cb18-67" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Validate</span></span>
<span id="cb18-68"><a href="#cb18-68" aria-hidden="true" tabindex="-1"></a>        val_loss, val_acc <span class="op">=</span> validate(</span>
<span id="cb18-69"><a href="#cb18-69" aria-hidden="true" tabindex="-1"></a>            model, val_loader, criterion, device</span>
<span id="cb18-70"><a href="#cb18-70" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb18-71"><a href="#cb18-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-72"><a href="#cb18-72" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Record history</span></span>
<span id="cb18-73"><a href="#cb18-73" aria-hidden="true" tabindex="-1"></a>        history[<span class="st">'train_loss'</span>].append(train_loss)</span>
<span id="cb18-74"><a href="#cb18-74" aria-hidden="true" tabindex="-1"></a>        history[<span class="st">'train_acc'</span>].append(train_acc)</span>
<span id="cb18-75"><a href="#cb18-75" aria-hidden="true" tabindex="-1"></a>        history[<span class="st">'val_loss'</span>].append(val_loss)</span>
<span id="cb18-76"><a href="#cb18-76" aria-hidden="true" tabindex="-1"></a>        history[<span class="st">'val_acc'</span>].append(val_acc)</span>
<span id="cb18-77"><a href="#cb18-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-78"><a href="#cb18-78" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Print progress every 5 epochs</span></span>
<span id="cb18-79"><a href="#cb18-79" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> (epoch <span class="op">+</span> <span class="dv">1</span>) <span class="op">%</span> <span class="dv">5</span> <span class="op">==</span> <span class="dv">0</span> <span class="kw">or</span> epoch <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb18-80"><a href="#cb18-80" aria-hidden="true" tabindex="-1"></a>            logger.info(<span class="ss">f"Epoch </span><span class="sc">{</span>epoch<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>epochs<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb18-81"><a href="#cb18-81" aria-hidden="true" tabindex="-1"></a>            logger.info(<span class="ss">f"  Train Loss: </span><span class="sc">{</span>train_loss<span class="sc">:.4f}</span><span class="ss">, Train Acc: </span><span class="sc">{</span>train_acc<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb18-82"><a href="#cb18-82" aria-hidden="true" tabindex="-1"></a>            logger.info(<span class="ss">f"  Val Loss: </span><span class="sc">{</span>val_loss<span class="sc">:.4f}</span><span class="ss">, Val Acc: </span><span class="sc">{</span>val_acc<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb18-83"><a href="#cb18-83" aria-hidden="true" tabindex="-1"></a>            logger.info(<span class="ss">f""</span>)</span>
<span id="cb18-84"><a href="#cb18-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-85"><a href="#cb18-85" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> history</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="step-8-train-the-model" class="level3">
<h3 class="anchored" data-anchor-id="step-8-train-the-model">Step 8: Train the Model</h3>
<pre><code>Before we train the model, let's set up some key training parameters. This is just for demonstration purposes. In practice, you would want to use a larger number of epochs and a smaller learning rate.</code></pre>
<ul>
<li><code>EPOCHS</code>: The number of complete passes through the training dataset. For demonstration, weâ€™ll use 15 epochs. Increasing this can lead to better results, but takes longer.</li>
<li><code>LEARNING_RATE</code>: This controls how much the model weights are updated during training. A smaller value (like <code>1e-4</code>) means smaller, more stable updatesâ€”generally safer for fine-tuning.</li>
<li>Weâ€™ll use these values in the training loop to show how the model gradually learns and improves over time.</li>
</ul>
<p>Each epoch is a complete pass through the training dataset, and the model is updated based on the loss and accuracy. One EPOCH will take longer than one batch, because it will process all the training data.</p>
<div id="35b737a9" class="cell">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Training configuration</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>EPOCHS <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>LEARNING_RATE <span class="op">=</span> <span class="fl">1e-4</span></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the model</span></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> train_model(</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>    model<span class="op">=</span>model,</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>    train_loader<span class="op">=</span>train_loader,</span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>    val_loader<span class="op">=</span>val_loader,</span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>    epochs<span class="op">=</span>EPOCHS,</span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>    lr<span class="op">=</span>LEARNING_RATE,</span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>    device<span class="op">=</span>device, </span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a>    criterion<span class="op">=</span>criterion, <span class="co"># Our CrossEntropyLoss loss function</span></span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a>    optimizer<span class="op">=</span>optimizer <span class="co"># Our Adam optimizer</span></span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-17"><a href="#cb20-17" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="st">"Training complete!"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Training Tips
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>For better accuracy (production):</strong></p>
<ul>
<li>Increase epochs to 50-100</li>
<li>Add learning rate scheduling</li>
<li>Use data augmentation (random flips, rotations)</li>
<li>Fine-tune the entire model (unfreeze backbone)</li>
</ul>
<p><strong>For faster training:</strong></p>
<ul>
<li>Reduce batch size if GPU memory limited</li>
<li>Use mixed precision (torch.cuda.amp)</li>
<li>Freeze backbone layers (only train decoder)</li>
</ul>
</div>
</div>
</section>
<section id="step-9-visualize-training-progress" class="level3">
<h3 class="anchored" data-anchor-id="step-9-visualize-training-progress">Step 9: Visualize Training Progress</h3>
<div id="c088ed70" class="cell">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>fig, (ax1, ax2) <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">4</span>))</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>epochs_range <span class="op">=</span> <span class="bu">range</span>(<span class="dv">1</span>, EPOCHS <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot loss</span></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>ax1.plot(epochs_range, history[<span class="st">'train_loss'</span>], label<span class="op">=</span><span class="st">'Train'</span>, marker<span class="op">=</span><span class="st">'o'</span>)</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>ax1.plot(epochs_range, history[<span class="st">'val_loss'</span>], label<span class="op">=</span><span class="st">'Validation'</span>, marker<span class="op">=</span><span class="st">'s'</span>)</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>ax1.set_xlabel(<span class="st">'Epoch'</span>)</span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>ax1.set_ylabel(<span class="st">'Loss'</span>)</span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>ax1.set_title(<span class="st">'Training and Validation Loss'</span>)</span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>ax1.legend()</span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>ax1.grid(alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot accuracy</span></span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a>ax2.plot(epochs_range, history[<span class="st">'train_acc'</span>], label<span class="op">=</span><span class="st">'Train'</span>, marker<span class="op">=</span><span class="st">'o'</span>)</span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a>ax2.plot(epochs_range, history[<span class="st">'val_acc'</span>], label<span class="op">=</span><span class="st">'Validation'</span>, marker<span class="op">=</span><span class="st">'s'</span>)</span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a>ax2.set_xlabel(<span class="st">'Epoch'</span>)</span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a>ax2.set_ylabel(<span class="st">'Accuracy'</span>)</span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a>ax2.set_title(<span class="st">'Training and Validation Accuracy'</span>)</span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a>ax2.legend()</span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a>ax2.grid(alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb21-22"><a href="#cb21-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-23"><a href="#cb21-23" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb21-24"><a href="#cb21-24" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb21-25"><a href="#cb21-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-26"><a href="#cb21-26" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Final Training Accuracy: </span><span class="sc">{</span>history[<span class="st">'train_acc'</span>][<span class="op">-</span><span class="dv">1</span>]<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb21-27"><a href="#cb21-27" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Final Validation Accuracy: </span><span class="sc">{</span>history[<span class="st">'val_acc'</span>][<span class="op">-</span><span class="dv">1</span>]<span class="sc">:.4f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="step-10-evaluate-on-test-set" class="level3">
<h3 class="anchored" data-anchor-id="step-10-evaluate-on-test-set">Step 10: Evaluate on Test Set</h3>
<div id="248eaa4f" class="cell" data-tangle="geogfm/training/simple_trainer.py" data-mode="append">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> evaluate_model(model, test_loader, device):</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Evaluate model on test set.</span></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters</span></span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a><span class="co">    ----------</span></span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a><span class="co">    model : nn.Module</span></span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a><span class="co">        Trained model</span></span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a><span class="co">    test_loader : DataLoader</span></span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a><span class="co">        Test data</span></span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a><span class="co">    device : torch.device</span></span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a><span class="co">        Device to use</span></span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns</span></span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a><span class="co">    -------</span></span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a><span class="co">    dict</span></span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a><span class="co">        Test metrics including accuracy and per-class accuracy</span></span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb22-19"><a href="#cb22-19" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">eval</span>()</span>
<span id="cb22-20"><a href="#cb22-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-21"><a href="#cb22-21" aria-hidden="true" tabindex="-1"></a>    correct <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb22-22"><a href="#cb22-22" aria-hidden="true" tabindex="-1"></a>    total <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb22-23"><a href="#cb22-23" aria-hidden="true" tabindex="-1"></a>    class_correct <span class="op">=</span> {}</span>
<span id="cb22-24"><a href="#cb22-24" aria-hidden="true" tabindex="-1"></a>    class_total <span class="op">=</span> {}</span>
<span id="cb22-25"><a href="#cb22-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-26"><a href="#cb22-26" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb22-27"><a href="#cb22-27" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> images, labels <span class="kw">in</span> test_loader:</span>
<span id="cb22-28"><a href="#cb22-28" aria-hidden="true" tabindex="-1"></a>            images <span class="op">=</span> images.to(device)</span>
<span id="cb22-29"><a href="#cb22-29" aria-hidden="true" tabindex="-1"></a>            labels <span class="op">=</span> labels.to(device)</span>
<span id="cb22-30"><a href="#cb22-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-31"><a href="#cb22-31" aria-hidden="true" tabindex="-1"></a>            outputs <span class="op">=</span> model(images)</span>
<span id="cb22-32"><a href="#cb22-32" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="bu">hasattr</span>(outputs, <span class="st">'output'</span>):</span>
<span id="cb22-33"><a href="#cb22-33" aria-hidden="true" tabindex="-1"></a>                outputs <span class="op">=</span> outputs.output</span>
<span id="cb22-34"><a href="#cb22-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-35"><a href="#cb22-35" aria-hidden="true" tabindex="-1"></a>            _, predicted <span class="op">=</span> outputs.<span class="bu">max</span>(<span class="dv">1</span>)</span>
<span id="cb22-36"><a href="#cb22-36" aria-hidden="true" tabindex="-1"></a>            total <span class="op">+=</span> labels.size(<span class="dv">0</span>)</span>
<span id="cb22-37"><a href="#cb22-37" aria-hidden="true" tabindex="-1"></a>            correct <span class="op">+=</span> predicted.eq(labels).<span class="bu">sum</span>().item()</span>
<span id="cb22-38"><a href="#cb22-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-39"><a href="#cb22-39" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Per-class accuracy</span></span>
<span id="cb22-40"><a href="#cb22-40" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> label, pred <span class="kw">in</span> <span class="bu">zip</span>(labels, predicted):</span>
<span id="cb22-41"><a href="#cb22-41" aria-hidden="true" tabindex="-1"></a>                label_item <span class="op">=</span> label.item()</span>
<span id="cb22-42"><a href="#cb22-42" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> label_item <span class="kw">not</span> <span class="kw">in</span> class_correct:</span>
<span id="cb22-43"><a href="#cb22-43" aria-hidden="true" tabindex="-1"></a>                    class_correct[label_item] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb22-44"><a href="#cb22-44" aria-hidden="true" tabindex="-1"></a>                    class_total[label_item] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb22-45"><a href="#cb22-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-46"><a href="#cb22-46" aria-hidden="true" tabindex="-1"></a>                class_total[label_item] <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb22-47"><a href="#cb22-47" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> label <span class="op">==</span> pred:</span>
<span id="cb22-48"><a href="#cb22-48" aria-hidden="true" tabindex="-1"></a>                    class_correct[label_item] <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb22-49"><a href="#cb22-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-50"><a href="#cb22-50" aria-hidden="true" tabindex="-1"></a>    overall_acc <span class="op">=</span> correct <span class="op">/</span> total</span>
<span id="cb22-51"><a href="#cb22-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-52"><a href="#cb22-52" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compute per-class accuracies</span></span>
<span id="cb22-53"><a href="#cb22-53" aria-hidden="true" tabindex="-1"></a>    per_class_acc <span class="op">=</span> {}</span>
<span id="cb22-54"><a href="#cb22-54" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> label_idx <span class="kw">in</span> class_correct.keys():</span>
<span id="cb22-55"><a href="#cb22-55" aria-hidden="true" tabindex="-1"></a>        per_class_acc[label_idx] <span class="op">=</span> class_correct[label_idx] <span class="op">/</span> class_total[label_idx]</span>
<span id="cb22-56"><a href="#cb22-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-57"><a href="#cb22-57" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {</span>
<span id="cb22-58"><a href="#cb22-58" aria-hidden="true" tabindex="-1"></a>        <span class="st">'overall_accuracy'</span>: overall_acc,</span>
<span id="cb22-59"><a href="#cb22-59" aria-hidden="true" tabindex="-1"></a>        <span class="st">'per_class_accuracy'</span>: per_class_acc,</span>
<span id="cb22-60"><a href="#cb22-60" aria-hidden="true" tabindex="-1"></a>        <span class="st">'total_samples'</span>: total</span>
<span id="cb22-61"><a href="#cb22-61" aria-hidden="true" tabindex="-1"></a>    }</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="db3f4438" class="cell">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate on test set</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>test_results <span class="op">=</span> evaluate_model(model, test_loader, device)</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Test Set Evaluation"</span>)</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"="</span> <span class="op">*</span> <span class="dv">50</span>)</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Overall Accuracy: </span><span class="sc">{</span>test_results[<span class="st">'overall_accuracy'</span>]<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Total Test Samples: </span><span class="sc">{</span>test_results[<span class="st">'total_samples'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Per-Class Accuracy:"</span>)</span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"-"</span> <span class="op">*</span> <span class="dv">50</span>)</span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> label_idx, acc <span class="kw">in</span> <span class="bu">sorted</span>(test_results[<span class="st">'per_class_accuracy'</span>].items()):</span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a>    class_name <span class="op">=</span> train_dataset.classes[label_idx]</span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a>    logger.info(<span class="ss">f"  </span><span class="sc">{</span>class_name<span class="sc">:20s}</span><span class="ss">: </span><span class="sc">{</span>acc<span class="sc">:.4f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Expected Performance
</div>
</div>
<div class="callout-body-container callout-body">
<p>With only a limited number of epochs of training, you should see:</p>
<ul>
<li><strong>Overall accuracy: 80-95%</strong></li>
<li>Some improvement in accuracy on distinct classes (Forest, Water)</li>
<li>Some improvement in accuracy on similar classes (Annual vs Permanent Crop)</li>
</ul>
</div>
</div>
</section>
<section id="step-11-visualize-predictions" class="level3">
<h3 class="anchored" data-anchor-id="step-11-visualize-predictions">Step 11: Visualize Predictions</h3>
<p>Letâ€™s see what the model is predicting.</p>
<div id="7d921e59" class="cell" data-tangle="geogfm/training/simple_trainer.py" data-mode="append">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> visualize_predictions(model, dataset, class_names, device, num_samples<span class="op">=</span><span class="dv">9</span>):</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Visualize model predictions on random samples.</span></span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters</span></span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a><span class="co">    ----------</span></span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a><span class="co">    model : nn.Module</span></span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a><span class="co">        Trained model</span></span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a><span class="co">    dataset : Dataset</span></span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a><span class="co">        Dataset to sample from</span></span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a><span class="co">    class_names : list</span></span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a><span class="co">        List of class names</span></span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a><span class="co">    device : torch.device</span></span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a><span class="co">        Device to use</span></span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a><span class="co">    num_samples : int</span></span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a><span class="co">        Number of samples to visualize</span></span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb24-20"><a href="#cb24-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-21"><a href="#cb24-21" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">eval</span>()</span>
<span id="cb24-22"><a href="#cb24-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-23"><a href="#cb24-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get random samples</span></span>
<span id="cb24-24"><a href="#cb24-24" aria-hidden="true" tabindex="-1"></a>    indices <span class="op">=</span> np.random.choice(<span class="bu">len</span>(dataset), num_samples, replace<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb24-25"><a href="#cb24-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-26"><a href="#cb24-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create subplot grid</span></span>
<span id="cb24-27"><a href="#cb24-27" aria-hidden="true" tabindex="-1"></a>    rows <span class="op">=</span> <span class="bu">int</span>(np.sqrt(num_samples))</span>
<span id="cb24-28"><a href="#cb24-28" aria-hidden="true" tabindex="-1"></a>    cols <span class="op">=</span> <span class="bu">int</span>(np.ceil(num_samples <span class="op">/</span> rows))</span>
<span id="cb24-29"><a href="#cb24-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-30"><a href="#cb24-30" aria-hidden="true" tabindex="-1"></a>    fig, axes <span class="op">=</span> plt.subplots(rows, cols, figsize<span class="op">=</span>(<span class="dv">3</span><span class="op">*</span>cols, <span class="dv">3</span><span class="op">*</span>rows))</span>
<span id="cb24-31"><a href="#cb24-31" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> num_samples <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb24-32"><a href="#cb24-32" aria-hidden="true" tabindex="-1"></a>        axes <span class="op">=</span> [axes]</span>
<span id="cb24-33"><a href="#cb24-33" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb24-34"><a href="#cb24-34" aria-hidden="true" tabindex="-1"></a>        axes <span class="op">=</span> axes.ravel()</span>
<span id="cb24-35"><a href="#cb24-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-36"><a href="#cb24-36" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb24-37"><a href="#cb24-37" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> idx, sample_idx <span class="kw">in</span> <span class="bu">enumerate</span>(indices):</span>
<span id="cb24-38"><a href="#cb24-38" aria-hidden="true" tabindex="-1"></a>            image, true_label <span class="op">=</span> dataset[sample_idx]</span>
<span id="cb24-39"><a href="#cb24-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-40"><a href="#cb24-40" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Get prediction</span></span>
<span id="cb24-41"><a href="#cb24-41" aria-hidden="true" tabindex="-1"></a>            image_batch <span class="op">=</span> image.unsqueeze(<span class="dv">0</span>).to(device)</span>
<span id="cb24-42"><a href="#cb24-42" aria-hidden="true" tabindex="-1"></a>            output <span class="op">=</span> model(image_batch)</span>
<span id="cb24-43"><a href="#cb24-43" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="bu">hasattr</span>(output, <span class="st">'output'</span>):</span>
<span id="cb24-44"><a href="#cb24-44" aria-hidden="true" tabindex="-1"></a>                output <span class="op">=</span> output.output</span>
<span id="cb24-45"><a href="#cb24-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-46"><a href="#cb24-46" aria-hidden="true" tabindex="-1"></a>            _, predicted <span class="op">=</span> output.<span class="bu">max</span>(<span class="dv">1</span>)</span>
<span id="cb24-47"><a href="#cb24-47" aria-hidden="true" tabindex="-1"></a>            pred_label <span class="op">=</span> predicted.item()</span>
<span id="cb24-48"><a href="#cb24-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-49"><a href="#cb24-49" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Create RGB visualization from first 3 bands</span></span>
<span id="cb24-50"><a href="#cb24-50" aria-hidden="true" tabindex="-1"></a>            rgb <span class="op">=</span> image[[<span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">0</span>], :, :].numpy()  <span class="co"># Assuming bands 2,1,0 are R,G,B-like</span></span>
<span id="cb24-51"><a href="#cb24-51" aria-hidden="true" tabindex="-1"></a>            rgb <span class="op">=</span> np.transpose(rgb, (<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">0</span>))</span>
<span id="cb24-52"><a href="#cb24-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-53"><a href="#cb24-53" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Normalize for display</span></span>
<span id="cb24-54"><a href="#cb24-54" aria-hidden="true" tabindex="-1"></a>            rgb_min, rgb_max <span class="op">=</span> rgb.<span class="bu">min</span>(), rgb.<span class="bu">max</span>()</span>
<span id="cb24-55"><a href="#cb24-55" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> rgb_max <span class="op">&gt;</span> rgb_min:</span>
<span id="cb24-56"><a href="#cb24-56" aria-hidden="true" tabindex="-1"></a>                rgb_norm <span class="op">=</span> (rgb <span class="op">-</span> rgb_min) <span class="op">/</span> (rgb_max <span class="op">-</span> rgb_min)</span>
<span id="cb24-57"><a href="#cb24-57" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb24-58"><a href="#cb24-58" aria-hidden="true" tabindex="-1"></a>                rgb_norm <span class="op">=</span> rgb</span>
<span id="cb24-59"><a href="#cb24-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-60"><a href="#cb24-60" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Plot</span></span>
<span id="cb24-61"><a href="#cb24-61" aria-hidden="true" tabindex="-1"></a>            axes[idx].imshow(rgb_norm)</span>
<span id="cb24-62"><a href="#cb24-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-63"><a href="#cb24-63" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Color code: green if correct, red if wrong</span></span>
<span id="cb24-64"><a href="#cb24-64" aria-hidden="true" tabindex="-1"></a>            color <span class="op">=</span> <span class="st">'green'</span> <span class="cf">if</span> pred_label <span class="op">==</span> true_label <span class="cf">else</span> <span class="st">'red'</span></span>
<span id="cb24-65"><a href="#cb24-65" aria-hidden="true" tabindex="-1"></a>            axes[idx].set_title(</span>
<span id="cb24-66"><a href="#cb24-66" aria-hidden="true" tabindex="-1"></a>                <span class="ss">f"True: </span><span class="sc">{</span>class_names[true_label]<span class="sc">}</span><span class="ch">\n</span><span class="ss">"</span></span>
<span id="cb24-67"><a href="#cb24-67" aria-hidden="true" tabindex="-1"></a>                <span class="ss">f"Pred: </span><span class="sc">{</span>class_names[pred_label]<span class="sc">}</span><span class="ss">"</span>,</span>
<span id="cb24-68"><a href="#cb24-68" aria-hidden="true" tabindex="-1"></a>                color<span class="op">=</span>color,</span>
<span id="cb24-69"><a href="#cb24-69" aria-hidden="true" tabindex="-1"></a>                fontsize<span class="op">=</span><span class="dv">9</span></span>
<span id="cb24-70"><a href="#cb24-70" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb24-71"><a href="#cb24-71" aria-hidden="true" tabindex="-1"></a>            axes[idx].axis(<span class="st">'off'</span>)</span>
<span id="cb24-72"><a href="#cb24-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-73"><a href="#cb24-73" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb24-74"><a href="#cb24-74" aria-hidden="true" tabindex="-1"></a>    plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="f88b0abd" class="cell">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize predictions</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>visualize_predictions(</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>    model<span class="op">=</span>model,</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>    dataset<span class="op">=</span>test_dataset_transformed,</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>    class_names<span class="op">=</span>train_dataset.classes,</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>    device<span class="op">=</span>device,</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>    num_samples<span class="op">=</span><span class="dv">9</span></span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="key-takeaways" class="level2">
<h2 class="anchored" data-anchor-id="key-takeaways">Key Takeaways</h2>
<section id="what-you-learned" class="level3">
<h3 class="anchored" data-anchor-id="what-you-learned">What You Learned</h3>
<ol type="1">
<li><p><strong>Library-Native Workflows</strong></p>
<ul>
<li>TorchGeo for standardized datasets</li>
<li>TerraTorch for foundation models</li>
<li>No custom data loading needed</li>
</ul></li>
<li><p><strong>Progressive Transfer Learning Approaches</strong></p>
<ul>
<li><strong>Zero-shot (0 examples)</strong>: ~11% - Random decoder, backbone features only</li>
<li><strong>Prototype Networks (5 examples/class)</strong>: ~30-50% - No training, just output space averaging</li>
<li><strong>Linear Probing (1-10 examples/class)</strong>: ~30-75% - Train decoder only, backbone frozen</li>
<li><strong>Full Fine-tuning (thousands of examples)</strong>: ~80-95% - Train entire model</li>
</ul></li>
<li><p><strong>Data Efficiency of Foundation Models</strong></p>
<ul>
<li>Pretrained features enable learning from minimal data</li>
<li>5-10 examples per class can achieve 60-75% accuracy</li>
<li>Huge reduction in labeling effort vs training from scratch</li>
<li>Foundation models make few-shot learning practical</li>
</ul></li>
<li><p><strong>Explicit Training Loops</strong></p>
<ul>
<li>Full visibility into training process</li>
<li>Easy to debug and modify</li>
<li>Understand every step</li>
<li>Compare training regimes side-by-side</li>
</ul></li>
</ol>
</section>
<section id="next-steps" class="level3">
<h3 class="anchored" data-anchor-id="next-steps">Next Steps</h3>
<p><strong>Week 3b will introduce:</strong></p>
<ul>
<li>PyTorch Lightning for automation</li>
<li>TerraTorch Tasks interface</li>
<li>Experiment tracking and logging</li>
<li>Multi-GPU training</li>
<li>Production deployment patterns</li>
</ul>
<p><strong>For now, practice with:</strong></p>
<ul>
<li>Different TorchGeo datasets (BigEarthNet, Sen12MS, etc.)</li>
<li>Different backbones (SatMAE, ScaleMAE, Clay)</li>
<li>Different k-shot settings (try 3-shot, 20-shot, 50-shot)</li>
<li>Compare prototype networks vs linear probing</li>
<li>Longer training runs for full fine-tuning (50-100 epochs)</li>
</ul>
</section>
</section>
<section id="resources" class="level2">
<h2 class="anchored" data-anchor-id="resources">Resources</h2>
<section id="documentation" class="level3">
<h3 class="anchored" data-anchor-id="documentation">Documentation</h3>
<ul>
<li><a href="https://torchgeo.readthedocs.io/">TorchGeo Docs</a></li>
<li><a href="https://github.com/IBM/terratorch">TerraTorch GitHub</a></li>
<li><a href="https://huggingface.co/ibm-nasa-geospatial">Prithvi Models</a></li>
</ul>
</section>
<section id="datasets" class="level3">
<h3 class="anchored" data-anchor-id="datasets">Datasets</h3>
<ul>
<li><a href="https://ieeexplore.ieee.org/document/8736785">EuroSAT Paper</a></li>
<li><a href="https://torchgeo.readthedocs.io/en/stable/api/datasets.html">TorchGeo Datasets</a></li>
</ul>
</section>
<section id="models" class="level3">
<h3 class="anchored" data-anchor-id="models">Models</h3>
<ul>
<li><a href="https://github.com/IBM/terratorch/blob/main/MODEL_ZOO.md">TerraTorch Model Zoo</a></li>
<li><a href="https://arxiv.org/abs/2310.18660">Prithvi Paper</a></li>
</ul>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Extension Ideas
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Try these modifications:</strong></p>
<ol type="1">
<li><strong>Few-Shot Variations</strong>: Compare different K values (1, 3, 5, 10, 20, 50)</li>
<li><strong>Distance Metrics</strong>: Try Euclidean distance instead of cosine similarity for prototypes</li>
<li><strong>Feature Visualization</strong>: Use t-SNE or UMAP to visualize Prithvi feature clusters</li>
<li><strong>Data Augmentation</strong>: Add random flips, rotations for few-shot training</li>
<li><strong>Learning Rate Scheduling</strong>: Use ReduceLROnPlateau or CosineAnnealingLR</li>
<li><strong>Ensemble</strong>: Combine prototype networks + linear probing predictions</li>
<li><strong>Cross-Dataset Transfer</strong>: Train on EuroSAT, test on BigEarthNet</li>
<li><strong>Export</strong>: Save model weights and load for inference</li>
</ol>
<p>All of these build on the foundation you learned today.</p>
</div>
</div>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Troubleshooting
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Common Issues:</strong></p>
<p><strong>â€œRuntimeError: CUDA out of memoryâ€</strong></p>
<ul>
<li>Reduce batch size</li>
<li>Use smaller model</li>
<li>Use gradient checkpointing</li>
</ul>
<p><strong>â€œImportError: No module named â€˜terratorchâ€™â€</strong></p>
<ul>
<li>Install: <code>pip install terratorch</code></li>
<li>Verify: <code>python -c "import terratorch; print(terratorch.__version__)"</code></li>
</ul>
<p><strong>â€œDownload failedâ€</strong></p>
<ul>
<li>Check internet connection</li>
<li>Manually download EuroSAT from source</li>
<li>Set download=False and point to existing data</li>
</ul>
<p><strong>â€œModel output shape mismatchâ€</strong></p>
<ul>
<li>Verify band selection (6 bands for Prithvi)</li>
<li>Check num_classes matches dataset</li>
<li>Ensure transforms applied correctly</li>
</ul>
<p><strong>Low accuracy (&lt;50%)</strong></p>
<ul>
<li>Verify labels are correct</li>
<li>Check data normalization</li>
<li>Increase training epochs</li>
<li>Try different learning rate</li>
</ul>
</div>
</div>


<!-- -->

</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "î§‹";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/kcaylor\.github\.io\/GEOG-288KC-geospatial-foundation-models");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb26" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Week 3a: TerraTorch Foundations"</span></span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a><span class="an">subtitle:</span><span class="co"> "Traditional PyTorch approach with TorchGeo and TerraTorch"</span></span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a><span class="an">jupyter:</span><span class="co"> geoai</span></span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a><span class="an">format:</span></span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a><span class="co">  html:</span></span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a><span class="co">    toc: true</span></span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a><span class="co">    toc-depth: 3</span></span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a><span class="co">    code-fold: false</span></span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a><span class="fu">## Introduction</span></span>
<span id="cb26-13"><a href="#cb26-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-14"><a href="#cb26-14" aria-hidden="true" tabindex="-1"></a>This session introduces foundation model workflows using TorchGeo and TerraTorch. You'll learn to work with benchmark datasets, build production-ready models, and understand the fundamentals of geospatial deep learning with explicit PyTorch training loops.</span>
<span id="cb26-15"><a href="#cb26-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-16"><a href="#cb26-16" aria-hidden="true" tabindex="-1"></a>:::{.callout-tip}</span>
<span id="cb26-17"><a href="#cb26-17" aria-hidden="true" tabindex="-1"></a><span class="fu">## Learning Objectives</span></span>
<span id="cb26-18"><a href="#cb26-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-19"><a href="#cb26-19" aria-hidden="true" tabindex="-1"></a>By the end of this session, you will be able to:</span>
<span id="cb26-20"><a href="#cb26-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-21"><a href="#cb26-21" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Load benchmark datasets using TorchGeo</span>
<span id="cb26-22"><a href="#cb26-22" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Build foundation models using TerraTorch's EncoderDecoderFactory</span>
<span id="cb26-23"><a href="#cb26-23" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Evaluate zero-shot performance and understand transfer learning</span>
<span id="cb26-24"><a href="#cb26-24" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>Implement few-shot learning with prototype networks</span>
<span id="cb26-25"><a href="#cb26-25" aria-hidden="true" tabindex="-1"></a><span class="ss">5. </span>Use linear probing for efficient model adaptation</span>
<span id="cb26-26"><a href="#cb26-26" aria-hidden="true" tabindex="-1"></a><span class="ss">6. </span>Train models using explicit PyTorch loops</span>
<span id="cb26-27"><a href="#cb26-27" aria-hidden="true" tabindex="-1"></a><span class="ss">7. </span>Compare data efficiency across different training regimes</span>
<span id="cb26-28"><a href="#cb26-28" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb26-29"><a href="#cb26-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-30"><a href="#cb26-30" aria-hidden="true" tabindex="-1"></a>:::{.callout-note}</span>
<span id="cb26-31"><a href="#cb26-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-32"><a href="#cb26-32" aria-hidden="true" tabindex="-1"></a><span class="fu">## Why This Approach?</span></span>
<span id="cb26-33"><a href="#cb26-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-34"><a href="#cb26-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-35"><a href="#cb26-35" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Traditional PyTorch training loops (see every step)</span>
<span id="cb26-36"><a href="#cb26-36" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Manual metric calculation (understand the math)</span>
<span id="cb26-37"><a href="#cb26-37" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Explicit device management (visible <span class="in">`.to(device)`</span>)</span>
<span id="cb26-38"><a href="#cb26-38" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Debuggable workflows (inspect intermediate values)</span>
<span id="cb26-39"><a href="#cb26-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-40"><a href="#cb26-40" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb26-41"><a href="#cb26-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-42"><a href="#cb26-42" aria-hidden="true" tabindex="-1"></a><span class="fu">## Part 1: The TorchGeo/TerraTorch Ecosystem</span></span>
<span id="cb26-43"><a href="#cb26-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-44"><a href="#cb26-44" aria-hidden="true" tabindex="-1"></a><span class="fu">### The Library Stack</span></span>
<span id="cb26-45"><a href="#cb26-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-46"><a href="#cb26-46" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-47"><a href="#cb26-47" aria-hidden="true" tabindex="-1"></a><span class="in">â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”</span></span>
<span id="cb26-48"><a href="#cb26-48" aria-hidden="true" tabindex="-1"></a><span class="in">â”‚   Your Project Code                 â”‚</span></span>
<span id="cb26-49"><a href="#cb26-49" aria-hidden="true" tabindex="-1"></a><span class="in">â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤</span></span>
<span id="cb26-50"><a href="#cb26-50" aria-hidden="true" tabindex="-1"></a><span class="in">â”‚   TerraTorch (Model Factory)        â”‚ â† Foundation models</span></span>
<span id="cb26-51"><a href="#cb26-51" aria-hidden="true" tabindex="-1"></a><span class="in">â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤</span></span>
<span id="cb26-52"><a href="#cb26-52" aria-hidden="true" tabindex="-1"></a><span class="in">â”‚   TorchGeo (Dataset Handling)       â”‚ â† Geospatial data</span></span>
<span id="cb26-53"><a href="#cb26-53" aria-hidden="true" tabindex="-1"></a><span class="in">â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤</span></span>
<span id="cb26-54"><a href="#cb26-54" aria-hidden="true" tabindex="-1"></a><span class="in">â”‚   PyTorch (Deep Learning)           â”‚ â† Core framework</span></span>
<span id="cb26-55"><a href="#cb26-55" aria-hidden="true" tabindex="-1"></a><span class="in">â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜</span></span>
<span id="cb26-56"><a href="#cb26-56" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-57"><a href="#cb26-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-58"><a href="#cb26-58" aria-hidden="true" tabindex="-1"></a>**TorchGeo** provides:</span>
<span id="cb26-59"><a href="#cb26-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-60"><a href="#cb26-60" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Benchmark datasets (EuroSAT, BigEarthNet, etc.)</span>
<span id="cb26-61"><a href="#cb26-61" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Geospatial data transforms</span>
<span id="cb26-62"><a href="#cb26-62" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Samplers for efficient loading</span>
<span id="cb26-63"><a href="#cb26-63" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Plotting and visualization utilities</span>
<span id="cb26-64"><a href="#cb26-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-65"><a href="#cb26-65" aria-hidden="true" tabindex="-1"></a>**TerraTorch** provides:</span>
<span id="cb26-66"><a href="#cb26-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-67"><a href="#cb26-67" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Pre-trained foundation models (Prithvi, SatMAE, etc.)</span>
<span id="cb26-68"><a href="#cb26-68" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Model factory for easy configuration</span>
<span id="cb26-69"><a href="#cb26-69" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Encoder-decoder architectures</span>
<span id="cb26-70"><a href="#cb26-70" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Task-specific heads</span>
<span id="cb26-71"><a href="#cb26-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-72"><a href="#cb26-72" aria-hidden="true" tabindex="-1"></a><span class="fu">### The EuroSAT Benchmark</span></span>
<span id="cb26-73"><a href="#cb26-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-74"><a href="#cb26-74" aria-hidden="true" tabindex="-1"></a>EuroSAT is a land use classification dataset based on Sentinel-2 imagery.</span>
<span id="cb26-75"><a href="#cb26-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-76"><a href="#cb26-76" aria-hidden="true" tabindex="-1"></a>**Dataset Statistics:**</span>
<span id="cb26-77"><a href="#cb26-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-78"><a href="#cb26-78" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Total images:** ~27,000</span>
<span id="cb26-79"><a href="#cb26-79" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Image size:** 64Ã—64 pixels</span>
<span id="cb26-80"><a href="#cb26-80" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Bands:** 13 (all Sentinel-2 bands)</span>
<span id="cb26-81"><a href="#cb26-81" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Resolution:** 10m, 20m, 60m (resampled to uniform grid)</span>
<span id="cb26-82"><a href="#cb26-82" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Classes:** 10 land use categories (original dataset)</span>
<span id="cb26-83"><a href="#cb26-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-84"><a href="#cb26-84" aria-hidden="true" tabindex="-1"></a>**Note:** The TorchGeo version may have 9 classes. The code dynamically adapts to the actual number of classes in <span class="in">`train_dataset.classes`</span>.</span>
<span id="cb26-85"><a href="#cb26-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-86"><a href="#cb26-86" aria-hidden="true" tabindex="-1"></a>**Typical Land Use Classes:**</span>
<span id="cb26-87"><a href="#cb26-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-88"><a href="#cb26-88" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>AnnualCrop</span>
<span id="cb26-89"><a href="#cb26-89" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Forest</span>
<span id="cb26-90"><a href="#cb26-90" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>HerbaceousVegetation</span>
<span id="cb26-91"><a href="#cb26-91" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>Highway</span>
<span id="cb26-92"><a href="#cb26-92" aria-hidden="true" tabindex="-1"></a><span class="ss">5. </span>Industrial</span>
<span id="cb26-93"><a href="#cb26-93" aria-hidden="true" tabindex="-1"></a><span class="ss">6. </span>Pasture</span>
<span id="cb26-94"><a href="#cb26-94" aria-hidden="true" tabindex="-1"></a><span class="ss">7. </span>PermanentCrop</span>
<span id="cb26-95"><a href="#cb26-95" aria-hidden="true" tabindex="-1"></a><span class="ss">8. </span>Residential</span>
<span id="cb26-96"><a href="#cb26-96" aria-hidden="true" tabindex="-1"></a><span class="ss">9. </span>River (may be merged with SeaLake in some versions)</span>
<span id="cb26-97"><a href="#cb26-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-98"><a href="#cb26-98" aria-hidden="true" tabindex="-1"></a>**Published Benchmarks:**</span>
<span id="cb26-99"><a href="#cb26-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-100"><a href="#cb26-100" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>ResNet-50: ~98% accuracy</span>
<span id="cb26-101"><a href="#cb26-101" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>VGG-16: ~97% accuracy</span>
<span id="cb26-102"><a href="#cb26-102" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>AlexNet: ~94% accuracy</span>
<span id="cb26-103"><a href="#cb26-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-104"><a href="#cb26-104" aria-hidden="true" tabindex="-1"></a>**Citation:**</span>
<span id="cb26-105"><a href="#cb26-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-106"><a href="#cb26-106" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Helber, P., Bischke, B., Dengel, A., &amp; Borth, D. (2019). EuroSAT: A novel dataset and deep learning benchmark for land use and land cover classification. *IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing*, 12(7), 2217-2226.</span></span>
<span id="cb26-107"><a href="#cb26-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-108"><a href="#cb26-108" aria-hidden="true" tabindex="-1"></a><span class="fu">### Setup and Installation</span></span>
<span id="cb26-109"><a href="#cb26-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-112"><a href="#cb26-112" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-113"><a href="#cb26-113" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb26-114"><a href="#cb26-114" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb26-115"><a href="#cb26-115" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> DataLoader</span>
<span id="cb26-116"><a href="#cb26-116" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb26-117"><a href="#cb26-117" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb26-118"><a href="#cb26-118" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pathlib <span class="im">import</span> Path</span>
<span id="cb26-119"><a href="#cb26-119" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> logging</span>
<span id="cb26-120"><a href="#cb26-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-121"><a href="#cb26-121" aria-hidden="true" tabindex="-1"></a>logger <span class="op">=</span> logging.getLogger(<span class="va">__name__</span>)</span>
<span id="cb26-122"><a href="#cb26-122" aria-hidden="true" tabindex="-1"></a><span class="co"># Set logging level to INFO</span></span>
<span id="cb26-123"><a href="#cb26-123" aria-hidden="true" tabindex="-1"></a>logger.setLevel(logging.INFO)</span>
<span id="cb26-124"><a href="#cb26-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-125"><a href="#cb26-125" aria-hidden="true" tabindex="-1"></a><span class="co"># Clear any existing handlers to prevent duplication</span></span>
<span id="cb26-126"><a href="#cb26-126" aria-hidden="true" tabindex="-1"></a>logger.handlers.clear()</span>
<span id="cb26-127"><a href="#cb26-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-128"><a href="#cb26-128" aria-hidden="true" tabindex="-1"></a><span class="co"># Add handler for Jupyter notebook output</span></span>
<span id="cb26-129"><a href="#cb26-129" aria-hidden="true" tabindex="-1"></a>handler <span class="op">=</span> logging.StreamHandler()</span>
<span id="cb26-130"><a href="#cb26-130" aria-hidden="true" tabindex="-1"></a>handler.setLevel(logging.INFO)</span>
<span id="cb26-131"><a href="#cb26-131" aria-hidden="true" tabindex="-1"></a>formatter <span class="op">=</span> logging.Formatter(<span class="st">'</span><span class="sc">%(message)s</span><span class="st">'</span>)</span>
<span id="cb26-132"><a href="#cb26-132" aria-hidden="true" tabindex="-1"></a>handler.setFormatter(formatter)</span>
<span id="cb26-133"><a href="#cb26-133" aria-hidden="true" tabindex="-1"></a>logger.addHandler(handler)</span>
<span id="cb26-134"><a href="#cb26-134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-135"><a href="#cb26-135" aria-hidden="true" tabindex="-1"></a><span class="co"># Prevent messages from propagating to root logger</span></span>
<span id="cb26-136"><a href="#cb26-136" aria-hidden="true" tabindex="-1"></a>logger.propagate <span class="op">=</span> <span class="va">False</span></span>
<span id="cb26-137"><a href="#cb26-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-138"><a href="#cb26-138" aria-hidden="true" tabindex="-1"></a><span class="co"># Set random seeds for reproducibility</span></span>
<span id="cb26-139"><a href="#cb26-139" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">42</span>)</span>
<span id="cb26-140"><a href="#cb26-140" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb26-141"><a href="#cb26-141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-142"><a href="#cb26-142" aria-hidden="true" tabindex="-1"></a><span class="co"># Device selection</span></span>
<span id="cb26-143"><a href="#cb26-143" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> torch.cuda.is_available():</span>
<span id="cb26-144"><a href="#cb26-144" aria-hidden="true" tabindex="-1"></a>    device <span class="op">=</span> torch.device(<span class="st">'cuda'</span>)</span>
<span id="cb26-145"><a href="#cb26-145" aria-hidden="true" tabindex="-1"></a>    logger.info(<span class="ss">f"Using CUDA GPU: </span><span class="sc">{</span>torch<span class="sc">.</span>cuda<span class="sc">.</span>get_device_name(<span class="dv">0</span>)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb26-146"><a href="#cb26-146" aria-hidden="true" tabindex="-1"></a><span class="cf">elif</span> torch.backends.mps.is_available():</span>
<span id="cb26-147"><a href="#cb26-147" aria-hidden="true" tabindex="-1"></a>    device <span class="op">=</span> torch.device(<span class="st">'mps'</span>)</span>
<span id="cb26-148"><a href="#cb26-148" aria-hidden="true" tabindex="-1"></a>    logger.info(<span class="st">"Using Apple Silicon MPS"</span>)</span>
<span id="cb26-149"><a href="#cb26-149" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb26-150"><a href="#cb26-150" aria-hidden="true" tabindex="-1"></a>    device <span class="op">=</span> torch.device(<span class="st">'cpu'</span>)</span>
<span id="cb26-151"><a href="#cb26-151" aria-hidden="true" tabindex="-1"></a>    logger.info(<span class="st">"Using CPU (training will be slower)"</span>)</span>
<span id="cb26-152"><a href="#cb26-152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-153"><a href="#cb26-153" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"PyTorch version: </span><span class="sc">{</span>torch<span class="sc">.</span>__version__<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb26-154"><a href="#cb26-154" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-155"><a href="#cb26-155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-156"><a href="#cb26-156" aria-hidden="true" tabindex="-1"></a><span class="fu">## Part 2: Classification with EuroSAT</span></span>
<span id="cb26-157"><a href="#cb26-157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-158"><a href="#cb26-158" aria-hidden="true" tabindex="-1"></a><span class="fu">### Step 1: Load the Dataset</span></span>
<span id="cb26-159"><a href="#cb26-159" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-160"><a href="#cb26-160" aria-hidden="true" tabindex="-1"></a>TorchGeo makes loading benchmark datasets simple and standardized.</span>
<span id="cb26-161"><a href="#cb26-161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-164"><a href="#cb26-164" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-165"><a href="#cb26-165" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchgeo.datasets <span class="im">import</span> EuroSAT</span>
<span id="cb26-166"><a href="#cb26-166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-167"><a href="#cb26-167" aria-hidden="true" tabindex="-1"></a><span class="co"># Define data directory</span></span>
<span id="cb26-168"><a href="#cb26-168" aria-hidden="true" tabindex="-1"></a>data_dir <span class="op">=</span> Path(<span class="st">"data"</span>)</span>
<span id="cb26-169"><a href="#cb26-169" aria-hidden="true" tabindex="-1"></a>data_dir.mkdir(exist_ok<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb26-170"><a href="#cb26-170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-171"><a href="#cb26-171" aria-hidden="true" tabindex="-1"></a><span class="co"># Load EuroSAT dataset with all bands</span></span>
<span id="cb26-172"><a href="#cb26-172" aria-hidden="true" tabindex="-1"></a><span class="co"># First time will download ~90MB dataset</span></span>
<span id="cb26-173"><a href="#cb26-173" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="st">"Loading EuroSAT dataset..."</span>)</span>
<span id="cb26-174"><a href="#cb26-174" aria-hidden="true" tabindex="-1"></a>train_dataset <span class="op">=</span> EuroSAT(</span>
<span id="cb26-175"><a href="#cb26-175" aria-hidden="true" tabindex="-1"></a>    root<span class="op">=</span><span class="bu">str</span>(data_dir),</span>
<span id="cb26-176"><a href="#cb26-176" aria-hidden="true" tabindex="-1"></a>    split<span class="op">=</span><span class="st">"train"</span>,</span>
<span id="cb26-177"><a href="#cb26-177" aria-hidden="true" tabindex="-1"></a>    download<span class="op">=</span><span class="va">True</span></span>
<span id="cb26-178"><a href="#cb26-178" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb26-179"><a href="#cb26-179" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-180"><a href="#cb26-180" aria-hidden="true" tabindex="-1"></a>val_dataset <span class="op">=</span> EuroSAT(</span>
<span id="cb26-181"><a href="#cb26-181" aria-hidden="true" tabindex="-1"></a>    root<span class="op">=</span><span class="bu">str</span>(data_dir),</span>
<span id="cb26-182"><a href="#cb26-182" aria-hidden="true" tabindex="-1"></a>    split<span class="op">=</span><span class="st">"val"</span>,</span>
<span id="cb26-183"><a href="#cb26-183" aria-hidden="true" tabindex="-1"></a>    download<span class="op">=</span><span class="va">True</span></span>
<span id="cb26-184"><a href="#cb26-184" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb26-185"><a href="#cb26-185" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-186"><a href="#cb26-186" aria-hidden="true" tabindex="-1"></a>test_dataset <span class="op">=</span> EuroSAT(</span>
<span id="cb26-187"><a href="#cb26-187" aria-hidden="true" tabindex="-1"></a>    root<span class="op">=</span><span class="bu">str</span>(data_dir),</span>
<span id="cb26-188"><a href="#cb26-188" aria-hidden="true" tabindex="-1"></a>    split<span class="op">=</span><span class="st">"test"</span>,</span>
<span id="cb26-189"><a href="#cb26-189" aria-hidden="true" tabindex="-1"></a>    download<span class="op">=</span><span class="va">True</span></span>
<span id="cb26-190"><a href="#cb26-190" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb26-191"><a href="#cb26-191" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-192"><a href="#cb26-192" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Training samples: </span><span class="sc">{</span><span class="bu">len</span>(train_dataset)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb26-193"><a href="#cb26-193" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Validation samples: </span><span class="sc">{</span><span class="bu">len</span>(val_dataset)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb26-194"><a href="#cb26-194" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Test samples: </span><span class="sc">{</span><span class="bu">len</span>(test_dataset)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb26-195"><a href="#cb26-195" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Number of classes: </span><span class="sc">{</span><span class="bu">len</span>(train_dataset.classes)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb26-196"><a href="#cb26-196" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Classes: </span><span class="sc">{</span>train_dataset<span class="sc">.</span>classes<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb26-197"><a href="#cb26-197" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-198"><a href="#cb26-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-199"><a href="#cb26-199" aria-hidden="true" tabindex="-1"></a>:::{.callout-note}</span>
<span id="cb26-200"><a href="#cb26-200" aria-hidden="true" tabindex="-1"></a><span class="fu">## Understanding the Dataset Object</span></span>
<span id="cb26-201"><a href="#cb26-201" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-202"><a href="#cb26-202" aria-hidden="true" tabindex="-1"></a>The <span class="in">`train_dataset`</span> is a PyTorch <span class="in">`Dataset`</span> object with:</span>
<span id="cb26-203"><a href="#cb26-203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-204"><a href="#cb26-204" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`__len__()`</span> - Returns number of samples</span>
<span id="cb26-205"><a href="#cb26-205" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`__getitem__(idx)`</span> - Returns (image, label) tuple</span>
<span id="cb26-206"><a href="#cb26-206" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`.classes`</span> - List of class names</span>
<span id="cb26-207"><a href="#cb26-207" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`.split`</span> - Current split (train/val/test)</span>
<span id="cb26-208"><a href="#cb26-208" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-209"><a href="#cb26-209" aria-hidden="true" tabindex="-1"></a>This standardization means the same code works for any TorchGeo dataset.</span>
<span id="cb26-210"><a href="#cb26-210" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb26-211"><a href="#cb26-211" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-212"><a href="#cb26-212" aria-hidden="true" tabindex="-1"></a><span class="fu">### Step 2: Explore the Data</span></span>
<span id="cb26-213"><a href="#cb26-213" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-214"><a href="#cb26-214" aria-hidden="true" tabindex="-1"></a>Let's visualize samples from each class to understand what we're working with.</span>
<span id="cb26-215"><a href="#cb26-215" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-218"><a href="#cb26-218" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-219"><a href="#cb26-219" aria-hidden="true" tabindex="-1"></a><span class="co"># Get one sample from each class efficiently using random sampling</span></span>
<span id="cb26-220"><a href="#cb26-220" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb26-221"><a href="#cb26-221" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-222"><a href="#cb26-222" aria-hidden="true" tabindex="-1"></a>samples_per_class <span class="op">=</span> {}</span>
<span id="cb26-223"><a href="#cb26-223" aria-hidden="true" tabindex="-1"></a>num_classes <span class="op">=</span> <span class="bu">len</span>(train_dataset.classes)</span>
<span id="cb26-224"><a href="#cb26-224" aria-hidden="true" tabindex="-1"></a>dataset_size <span class="op">=</span> <span class="bu">len</span>(train_dataset)</span>
<span id="cb26-225"><a href="#cb26-225" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-226"><a href="#cb26-226" aria-hidden="true" tabindex="-1"></a><span class="co"># Random sampling is much faster than sequential scan</span></span>
<span id="cb26-227"><a href="#cb26-227" aria-hidden="true" tabindex="-1"></a><span class="co"># Sample more indices than classes to ensure we find all classes quickly</span></span>
<span id="cb26-228"><a href="#cb26-228" aria-hidden="true" tabindex="-1"></a>random_indices <span class="op">=</span> random.sample(<span class="bu">range</span>(dataset_size), <span class="bu">min</span>(dataset_size, num_classes <span class="op">*</span> <span class="dv">10</span>))</span>
<span id="cb26-229"><a href="#cb26-229" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-230"><a href="#cb26-230" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Sampling representative images (one per class)..."</span>)</span>
<span id="cb26-231"><a href="#cb26-231" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> idx <span class="kw">in</span> random_indices:</span>
<span id="cb26-232"><a href="#cb26-232" aria-hidden="true" tabindex="-1"></a>    sample <span class="op">=</span> train_dataset[idx]</span>
<span id="cb26-233"><a href="#cb26-233" aria-hidden="true" tabindex="-1"></a>    image <span class="op">=</span> sample[<span class="st">"image"</span>]</span>
<span id="cb26-234"><a href="#cb26-234" aria-hidden="true" tabindex="-1"></a>    label <span class="op">=</span> sample[<span class="st">"label"</span>]</span>
<span id="cb26-235"><a href="#cb26-235" aria-hidden="true" tabindex="-1"></a>    class_idx <span class="op">=</span> <span class="bu">int</span>(label) <span class="cf">if</span> <span class="bu">hasattr</span>(label, <span class="st">"item"</span>) <span class="cf">else</span> label</span>
<span id="cb26-236"><a href="#cb26-236" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-237"><a href="#cb26-237" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> class_idx <span class="kw">not</span> <span class="kw">in</span> samples_per_class:</span>
<span id="cb26-238"><a href="#cb26-238" aria-hidden="true" tabindex="-1"></a>        samples_per_class[class_idx] <span class="op">=</span> image</span>
<span id="cb26-239"><a href="#cb26-239" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-240"><a href="#cb26-240" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Stop once we have all classes</span></span>
<span id="cb26-241"><a href="#cb26-241" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">set</span>(samples_per_class.keys()) <span class="op">==</span> <span class="bu">set</span>(<span class="bu">range</span>(num_classes)):</span>
<span id="cb26-242"><a href="#cb26-242" aria-hidden="true" tabindex="-1"></a>        logger.info(<span class="ss">f"Found all </span><span class="sc">{</span>num_classes<span class="sc">}</span><span class="ss"> classes in </span><span class="sc">{</span><span class="bu">len</span>(samples_per_class)<span class="sc">}</span><span class="ss"> samples"</span>)</span>
<span id="cb26-243"><a href="#cb26-243" aria-hidden="true" tabindex="-1"></a>        <span class="cf">break</span></span>
<span id="cb26-244"><a href="#cb26-244" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-245"><a href="#cb26-245" aria-hidden="true" tabindex="-1"></a><span class="co"># Create RGB composite for visualization</span></span>
<span id="cb26-246"><a href="#cb26-246" aria-hidden="true" tabindex="-1"></a><span class="co"># EuroSAT bands: [B01, B02, B03, B04, B05, B06, B07, B08, B8A, B09, B10, B11, B12]</span></span>
<span id="cb26-247"><a href="#cb26-247" aria-hidden="true" tabindex="-1"></a><span class="co"># RGB = B04 (Red), B03 (Green), B02 (Blue) = indices [3, 2, 1]</span></span>
<span id="cb26-248"><a href="#cb26-248" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-249"><a href="#cb26-249" aria-hidden="true" tabindex="-1"></a><span class="co"># Dynamic grid based on actual number of classes found</span></span>
<span id="cb26-250"><a href="#cb26-250" aria-hidden="true" tabindex="-1"></a>n_samples <span class="op">=</span> <span class="bu">len</span>(samples_per_class)</span>
<span id="cb26-251"><a href="#cb26-251" aria-hidden="true" tabindex="-1"></a>n_cols <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb26-252"><a href="#cb26-252" aria-hidden="true" tabindex="-1"></a>n_rows <span class="op">=</span> <span class="bu">int</span>(np.ceil(n_samples <span class="op">/</span> n_cols))</span>
<span id="cb26-253"><a href="#cb26-253" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-254"><a href="#cb26-254" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(n_rows, n_cols, figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">3</span><span class="op">*</span>n_rows))</span>
<span id="cb26-255"><a href="#cb26-255" aria-hidden="true" tabindex="-1"></a>axes <span class="op">=</span> axes.ravel()</span>
<span id="cb26-256"><a href="#cb26-256" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-257"><a href="#cb26-257" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> idx, (label, image) <span class="kw">in</span> <span class="bu">enumerate</span>(samples_per_class.items()):</span>
<span id="cb26-258"><a href="#cb26-258" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Extract RGB bands</span></span>
<span id="cb26-259"><a href="#cb26-259" aria-hidden="true" tabindex="-1"></a>    rgb <span class="op">=</span> image[[<span class="dv">3</span>, <span class="dv">2</span>, <span class="dv">1</span>], :, :].numpy()  <span class="co"># Red, Green, Blue</span></span>
<span id="cb26-260"><a href="#cb26-260" aria-hidden="true" tabindex="-1"></a>    rgb <span class="op">=</span> np.transpose(rgb, (<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">0</span>))  <span class="co"># (H, W, C)</span></span>
<span id="cb26-261"><a href="#cb26-261" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-262"><a href="#cb26-262" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Normalize for display (using percentile stretch)</span></span>
<span id="cb26-263"><a href="#cb26-263" aria-hidden="true" tabindex="-1"></a>    p2, p98 <span class="op">=</span> np.percentile(rgb, (<span class="dv">2</span>, <span class="dv">98</span>))</span>
<span id="cb26-264"><a href="#cb26-264" aria-hidden="true" tabindex="-1"></a>    rgb_norm <span class="op">=</span> np.clip((rgb <span class="op">-</span> p2) <span class="op">/</span> (p98 <span class="op">-</span> p2), <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb26-265"><a href="#cb26-265" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-266"><a href="#cb26-266" aria-hidden="true" tabindex="-1"></a>    axes[idx].imshow(rgb_norm)</span>
<span id="cb26-267"><a href="#cb26-267" aria-hidden="true" tabindex="-1"></a>    axes[idx].set_title(train_dataset.classes[label])</span>
<span id="cb26-268"><a href="#cb26-268" aria-hidden="true" tabindex="-1"></a>    axes[idx].axis(<span class="st">'off'</span>)</span>
<span id="cb26-269"><a href="#cb26-269" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-270"><a href="#cb26-270" aria-hidden="true" tabindex="-1"></a><span class="co"># Hide any unused subplots</span></span>
<span id="cb26-271"><a href="#cb26-271" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> idx <span class="kw">in</span> <span class="bu">range</span>(n_samples, <span class="bu">len</span>(axes)):</span>
<span id="cb26-272"><a href="#cb26-272" aria-hidden="true" tabindex="-1"></a>    axes[idx].axis(<span class="st">'off'</span>)</span>
<span id="cb26-273"><a href="#cb26-273" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-274"><a href="#cb26-274" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb26-275"><a href="#cb26-275" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb26-276"><a href="#cb26-276" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-277"><a href="#cb26-277" aria-hidden="true" tabindex="-1"></a><span class="co"># Print band information and data range</span></span>
<span id="cb26-278"><a href="#cb26-278" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Image shape: </span><span class="sc">{</span>image<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb26-279"><a href="#cb26-279" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Bands: 13 Sentinel-2 bands"</span>)</span>
<span id="cb26-280"><a href="#cb26-280" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Spatial size: 64Ã—64 pixels"</span>)</span>
<span id="cb26-281"><a href="#cb26-281" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f""</span>)</span>
<span id="cb26-282"><a href="#cb26-282" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Raw EuroSAT data range:"</span>)</span>
<span id="cb26-283"><a href="#cb26-283" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"  Min value: </span><span class="sc">{</span>image<span class="sc">.</span><span class="bu">min</span>()<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb26-284"><a href="#cb26-284" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"  Max value: </span><span class="sc">{</span>image<span class="sc">.</span><span class="bu">max</span>()<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb26-285"><a href="#cb26-285" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"  Mean value: </span><span class="sc">{</span>image<span class="sc">.</span>mean()<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb26-286"><a href="#cb26-286" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f""</span>)</span>
<span id="cb26-287"><a href="#cb26-287" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"This confirms EuroSAT is NOT pre-normalized!"</span>)</span>
<span id="cb26-288"><a href="#cb26-288" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Typical Sentinel-2 range: 0-10000 (surface reflectance Ã— 10000)"</span>)</span>
<span id="cb26-289"><a href="#cb26-289" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-290"><a href="#cb26-290" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-291"><a href="#cb26-291" aria-hidden="true" tabindex="-1"></a>:::{.callout-tip}</span>
<span id="cb26-292"><a href="#cb26-292" aria-hidden="true" tabindex="-1"></a><span class="fu">## Band Selection Strategy</span></span>
<span id="cb26-293"><a href="#cb26-293" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-294"><a href="#cb26-294" aria-hidden="true" tabindex="-1"></a>**Challenge:** Prithvi expects 6 bands, EuroSAT has 13 bands.</span>
<span id="cb26-295"><a href="#cb26-295" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-296"><a href="#cb26-296" aria-hidden="true" tabindex="-1"></a>**Solution:** Select the 6 bands Prithvi was trained on:</span>
<span id="cb26-297"><a href="#cb26-297" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-298"><a href="#cb26-298" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>B02 (Blue) - 10m</span>
<span id="cb26-299"><a href="#cb26-299" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>B03 (Green) - 10m</span>
<span id="cb26-300"><a href="#cb26-300" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>B04 (Red) - 10m</span>
<span id="cb26-301"><a href="#cb26-301" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>B08 (NIR) - 10m</span>
<span id="cb26-302"><a href="#cb26-302" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>B11 (SWIR1) - 20m</span>
<span id="cb26-303"><a href="#cb26-303" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>B12 (SWIR2) - 20m</span>
<span id="cb26-304"><a href="#cb26-304" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-305"><a href="#cb26-305" aria-hidden="true" tabindex="-1"></a>EuroSAT indices: <span class="co">[</span><span class="ot">1, 2, 3, 7, 11, 12</span><span class="co">]</span></span>
<span id="cb26-306"><a href="#cb26-306" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb26-307"><a href="#cb26-307" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-308"><a href="#cb26-308" aria-hidden="true" tabindex="-1"></a><span class="fu">### Step 3: Create Data Transforms</span></span>
<span id="cb26-309"><a href="#cb26-309" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-310"><a href="#cb26-310" aria-hidden="true" tabindex="-1"></a>We need to select the correct bands and normalize the data for Prithvi.</span>
<span id="cb26-311"><a href="#cb26-311" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-312"><a href="#cb26-312" aria-hidden="true" tabindex="-1"></a>**Critical Understanding:**</span>
<span id="cb26-313"><a href="#cb26-313" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-314"><a href="#cb26-314" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**EuroSAT raw data**: Sentinel-2 surface reflectance values (typically 0-10000+)</span>
<span id="cb26-315"><a href="#cb26-315" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Prithvi expects**: Normalized values in range <span class="co">[</span><span class="ot">0, 1</span><span class="co">]</span></span>
<span id="cb26-316"><a href="#cb26-316" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Why this matters**: Without normalization, the model gets completely out-of-distribution inputs</span>
<span id="cb26-317"><a href="#cb26-317" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Result without normalization**: Zero-shot accuracy ~10% (random guessing)</span>
<span id="cb26-318"><a href="#cb26-318" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-321"><a href="#cb26-321" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-322"><a href="#cb26-322" aria-hidden="true" tabindex="-1"></a><span class="co">#| tangle: geogfm/training/eurosat_utils.py</span></span>
<span id="cb26-323"><a href="#cb26-323" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb26-324"><a href="#cb26-324" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-325"><a href="#cb26-325" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> select_prithvi_bands(sample):</span>
<span id="cb26-326"><a href="#cb26-326" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb26-327"><a href="#cb26-327" aria-hidden="true" tabindex="-1"></a><span class="co">    Select the 6 bands Prithvi was trained on from EuroSAT's 13 bands.</span></span>
<span id="cb26-328"><a href="#cb26-328" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-329"><a href="#cb26-329" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters</span></span>
<span id="cb26-330"><a href="#cb26-330" aria-hidden="true" tabindex="-1"></a><span class="co">    ----------</span></span>
<span id="cb26-331"><a href="#cb26-331" aria-hidden="true" tabindex="-1"></a><span class="co">    sample : dict</span></span>
<span id="cb26-332"><a href="#cb26-332" aria-hidden="true" tabindex="-1"></a><span class="co">        TorchGeo sample with 'image' and 'label' keys</span></span>
<span id="cb26-333"><a href="#cb26-333" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-334"><a href="#cb26-334" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns</span></span>
<span id="cb26-335"><a href="#cb26-335" aria-hidden="true" tabindex="-1"></a><span class="co">    -------</span></span>
<span id="cb26-336"><a href="#cb26-336" aria-hidden="true" tabindex="-1"></a><span class="co">    dict</span></span>
<span id="cb26-337"><a href="#cb26-337" aria-hidden="true" tabindex="-1"></a><span class="co">        Sample with 6-band image</span></span>
<span id="cb26-338"><a href="#cb26-338" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb26-339"><a href="#cb26-339" aria-hidden="true" tabindex="-1"></a>    <span class="co"># EuroSAT band order: [B01, B02, B03, B04, B05, B06, B07, B08, B8A, B09, B10, B11, B12]</span></span>
<span id="cb26-340"><a href="#cb26-340" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Prithvi bands: [B02, B03, B04, B08, B11, B12]</span></span>
<span id="cb26-341"><a href="#cb26-341" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Indices: [1, 2, 3, 7, 11, 12]</span></span>
<span id="cb26-342"><a href="#cb26-342" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-343"><a href="#cb26-343" aria-hidden="true" tabindex="-1"></a>    image <span class="op">=</span> sample[<span class="st">'image'</span>]</span>
<span id="cb26-344"><a href="#cb26-344" aria-hidden="true" tabindex="-1"></a>    selected_bands <span class="op">=</span> image[[<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">7</span>, <span class="dv">11</span>, <span class="dv">12</span>], :, :]</span>
<span id="cb26-345"><a href="#cb26-345" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-346"><a href="#cb26-346" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {</span>
<span id="cb26-347"><a href="#cb26-347" aria-hidden="true" tabindex="-1"></a>        <span class="st">'image'</span>: selected_bands,</span>
<span id="cb26-348"><a href="#cb26-348" aria-hidden="true" tabindex="-1"></a>        <span class="st">'label'</span>: sample[<span class="st">'label'</span>]</span>
<span id="cb26-349"><a href="#cb26-349" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb26-350"><a href="#cb26-350" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-351"><a href="#cb26-351" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> normalize_prithvi(sample):</span>
<span id="cb26-352"><a href="#cb26-352" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb26-353"><a href="#cb26-353" aria-hidden="true" tabindex="-1"></a><span class="co">    Normalize imagery for Prithvi using per-sample normalization.</span></span>
<span id="cb26-354"><a href="#cb26-354" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-355"><a href="#cb26-355" aria-hidden="true" tabindex="-1"></a><span class="co">    In production, you would want to use global statistics from the training set.</span></span>
<span id="cb26-356"><a href="#cb26-356" aria-hidden="true" tabindex="-1"></a><span class="co">    For this demo, we use per-sample percentile normalization.</span></span>
<span id="cb26-357"><a href="#cb26-357" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-358"><a href="#cb26-358" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters</span></span>
<span id="cb26-359"><a href="#cb26-359" aria-hidden="true" tabindex="-1"></a><span class="co">    ----------</span></span>
<span id="cb26-360"><a href="#cb26-360" aria-hidden="true" tabindex="-1"></a><span class="co">    sample : dict</span></span>
<span id="cb26-361"><a href="#cb26-361" aria-hidden="true" tabindex="-1"></a><span class="co">        Sample with 'image' and 'label'</span></span>
<span id="cb26-362"><a href="#cb26-362" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-363"><a href="#cb26-363" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns</span></span>
<span id="cb26-364"><a href="#cb26-364" aria-hidden="true" tabindex="-1"></a><span class="co">    -------</span></span>
<span id="cb26-365"><a href="#cb26-365" aria-hidden="true" tabindex="-1"></a><span class="co">    dict</span></span>
<span id="cb26-366"><a href="#cb26-366" aria-hidden="true" tabindex="-1"></a><span class="co">        Sample with normalized image</span></span>
<span id="cb26-367"><a href="#cb26-367" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb26-368"><a href="#cb26-368" aria-hidden="true" tabindex="-1"></a>    image <span class="op">=</span> sample[<span class="st">'image'</span>]</span>
<span id="cb26-369"><a href="#cb26-369" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-370"><a href="#cb26-370" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Normalize each band independently using 2nd-98th percentile</span></span>
<span id="cb26-371"><a href="#cb26-371" aria-hidden="true" tabindex="-1"></a>    normalized <span class="op">=</span> torch.zeros_like(image)</span>
<span id="cb26-372"><a href="#cb26-372" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> c <span class="kw">in</span> <span class="bu">range</span>(image.shape[<span class="dv">0</span>]):</span>
<span id="cb26-373"><a href="#cb26-373" aria-hidden="true" tabindex="-1"></a>        band <span class="op">=</span> image[c]</span>
<span id="cb26-374"><a href="#cb26-374" aria-hidden="true" tabindex="-1"></a>        p2, p98 <span class="op">=</span> torch.quantile(band, torch.tensor([<span class="fl">0.02</span>, <span class="fl">0.98</span>]))</span>
<span id="cb26-375"><a href="#cb26-375" aria-hidden="true" tabindex="-1"></a>        normalized[c] <span class="op">=</span> torch.clamp((band <span class="op">-</span> p2) <span class="op">/</span> (p98 <span class="op">-</span> p2 <span class="op">+</span> <span class="fl">1e-8</span>), <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb26-376"><a href="#cb26-376" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-377"><a href="#cb26-377" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {</span>
<span id="cb26-378"><a href="#cb26-378" aria-hidden="true" tabindex="-1"></a>        <span class="st">'image'</span>: normalized,</span>
<span id="cb26-379"><a href="#cb26-379" aria-hidden="true" tabindex="-1"></a>        <span class="st">'label'</span>: sample[<span class="st">'label'</span>]</span>
<span id="cb26-380"><a href="#cb26-380" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb26-381"><a href="#cb26-381" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-382"><a href="#cb26-382" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-385"><a href="#cb26-385" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-386"><a href="#cb26-386" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision <span class="im">import</span> transforms</span>
<span id="cb26-387"><a href="#cb26-387" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-388"><a href="#cb26-388" aria-hidden="true" tabindex="-1"></a><span class="co"># Compose transforms</span></span>
<span id="cb26-389"><a href="#cb26-389" aria-hidden="true" tabindex="-1"></a>transform <span class="op">=</span> transforms.Compose([</span>
<span id="cb26-390"><a href="#cb26-390" aria-hidden="true" tabindex="-1"></a>    select_prithvi_bands,</span>
<span id="cb26-391"><a href="#cb26-391" aria-hidden="true" tabindex="-1"></a>    normalize_prithvi  <span class="co"># Critical for Prithvi - expects [0, 1] normalized inputs</span></span>
<span id="cb26-392"><a href="#cb26-392" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb26-393"><a href="#cb26-393" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-394"><a href="#cb26-394" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply transforms to datasets</span></span>
<span id="cb26-395"><a href="#cb26-395" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> TransformedDataset(torch.utils.data.Dataset):</span>
<span id="cb26-396"><a href="#cb26-396" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Wrapper to apply transforms to TorchGeo datasets."""</span></span>
<span id="cb26-397"><a href="#cb26-397" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, dataset, transform<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb26-398"><a href="#cb26-398" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dataset <span class="op">=</span> dataset</span>
<span id="cb26-399"><a href="#cb26-399" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.transform <span class="op">=</span> transform</span>
<span id="cb26-400"><a href="#cb26-400" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-401"><a href="#cb26-401" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__len__</span>(<span class="va">self</span>):</span>
<span id="cb26-402"><a href="#cb26-402" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="bu">len</span>(<span class="va">self</span>.dataset)</span>
<span id="cb26-403"><a href="#cb26-403" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-404"><a href="#cb26-404" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__getitem__</span>(<span class="va">self</span>, idx):</span>
<span id="cb26-405"><a href="#cb26-405" aria-hidden="true" tabindex="-1"></a>        sample <span class="op">=</span> <span class="va">self</span>.dataset[idx]</span>
<span id="cb26-406"><a href="#cb26-406" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.transform:</span>
<span id="cb26-407"><a href="#cb26-407" aria-hidden="true" tabindex="-1"></a>            sample <span class="op">=</span> <span class="va">self</span>.transform(sample)</span>
<span id="cb26-408"><a href="#cb26-408" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> sample[<span class="st">'image'</span>], sample[<span class="st">'label'</span>]</span>
<span id="cb26-409"><a href="#cb26-409" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-410"><a href="#cb26-410" aria-hidden="true" tabindex="-1"></a>train_dataset_transformed <span class="op">=</span> TransformedDataset(train_dataset, transform)</span>
<span id="cb26-411"><a href="#cb26-411" aria-hidden="true" tabindex="-1"></a>val_dataset_transformed <span class="op">=</span> TransformedDataset(val_dataset, transform)</span>
<span id="cb26-412"><a href="#cb26-412" aria-hidden="true" tabindex="-1"></a>test_dataset_transformed <span class="op">=</span> TransformedDataset(test_dataset, transform)</span>
<span id="cb26-413"><a href="#cb26-413" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-414"><a href="#cb26-414" aria-hidden="true" tabindex="-1"></a><span class="co"># Test the transformation</span></span>
<span id="cb26-415"><a href="#cb26-415" aria-hidden="true" tabindex="-1"></a>sample_img, sample_label <span class="op">=</span> train_dataset_transformed[<span class="dv">0</span>]</span>
<span id="cb26-416"><a href="#cb26-416" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Transformed image shape: </span><span class="sc">{</span>sample_img<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb26-417"><a href="#cb26-417" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Expected: (6, 64, 64)"</span>)</span>
<span id="cb26-418"><a href="#cb26-418" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Label: </span><span class="sc">{</span>sample_label<span class="sc">}</span><span class="ss"> (</span><span class="sc">{</span>train_dataset<span class="sc">.</span>classes[sample_label]<span class="sc">}</span><span class="ss">)"</span>)</span>
<span id="cb26-419"><a href="#cb26-419" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Value range: [</span><span class="sc">{</span>sample_img<span class="sc">.</span><span class="bu">min</span>()<span class="sc">:.4f}</span><span class="ss">, </span><span class="sc">{</span>sample_img<span class="sc">.</span><span class="bu">max</span>()<span class="sc">:.4f}</span><span class="ss">]"</span>)</span>
<span id="cb26-420"><a href="#cb26-420" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Expected range: [0, 1] after normalization"</span>)</span>
<span id="cb26-421"><a href="#cb26-421" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-422"><a href="#cb26-422" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-423"><a href="#cb26-423" aria-hidden="true" tabindex="-1"></a><span class="fu">### Step 4: Create DataLoaders</span></span>
<span id="cb26-424"><a href="#cb26-424" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-425"><a href="#cb26-425" aria-hidden="true" tabindex="-1"></a>DataLoaders handle batching, shuffling, and parallel data loading.</span>
<span id="cb26-426"><a href="#cb26-426" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-429"><a href="#cb26-429" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-430"><a href="#cb26-430" aria-hidden="true" tabindex="-1"></a><span class="co"># Create DataLoaders</span></span>
<span id="cb26-431"><a href="#cb26-431" aria-hidden="true" tabindex="-1"></a>train_loader <span class="op">=</span> DataLoader(</span>
<span id="cb26-432"><a href="#cb26-432" aria-hidden="true" tabindex="-1"></a>    train_dataset_transformed,</span>
<span id="cb26-433"><a href="#cb26-433" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span><span class="dv">32</span>,</span>
<span id="cb26-434"><a href="#cb26-434" aria-hidden="true" tabindex="-1"></a>    shuffle<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb26-435"><a href="#cb26-435" aria-hidden="true" tabindex="-1"></a>    num_workers<span class="op">=</span><span class="dv">0</span>  <span class="co"># Set to 0 for Windows, 4+ for Linux/Mac</span></span>
<span id="cb26-436"><a href="#cb26-436" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb26-437"><a href="#cb26-437" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-438"><a href="#cb26-438" aria-hidden="true" tabindex="-1"></a>val_loader <span class="op">=</span> DataLoader(</span>
<span id="cb26-439"><a href="#cb26-439" aria-hidden="true" tabindex="-1"></a>    val_dataset_transformed,</span>
<span id="cb26-440"><a href="#cb26-440" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span><span class="dv">32</span>,</span>
<span id="cb26-441"><a href="#cb26-441" aria-hidden="true" tabindex="-1"></a>    shuffle<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb26-442"><a href="#cb26-442" aria-hidden="true" tabindex="-1"></a>    num_workers<span class="op">=</span><span class="dv">0</span></span>
<span id="cb26-443"><a href="#cb26-443" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb26-444"><a href="#cb26-444" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-445"><a href="#cb26-445" aria-hidden="true" tabindex="-1"></a>test_loader <span class="op">=</span> DataLoader(</span>
<span id="cb26-446"><a href="#cb26-446" aria-hidden="true" tabindex="-1"></a>    test_dataset_transformed,</span>
<span id="cb26-447"><a href="#cb26-447" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span><span class="dv">32</span>,</span>
<span id="cb26-448"><a href="#cb26-448" aria-hidden="true" tabindex="-1"></a>    shuffle<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb26-449"><a href="#cb26-449" aria-hidden="true" tabindex="-1"></a>    num_workers<span class="op">=</span><span class="dv">0</span></span>
<span id="cb26-450"><a href="#cb26-450" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb26-451"><a href="#cb26-451" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-452"><a href="#cb26-452" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Training batches: </span><span class="sc">{</span><span class="bu">len</span>(train_loader)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb26-453"><a href="#cb26-453" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Validation batches: </span><span class="sc">{</span><span class="bu">len</span>(val_loader)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb26-454"><a href="#cb26-454" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Test batches: </span><span class="sc">{</span><span class="bu">len</span>(test_loader)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb26-455"><a href="#cb26-455" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-456"><a href="#cb26-456" aria-hidden="true" tabindex="-1"></a><span class="co"># Test a batch</span></span>
<span id="cb26-457"><a href="#cb26-457" aria-hidden="true" tabindex="-1"></a>images, labels <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(train_loader))</span>
<span id="cb26-458"><a href="#cb26-458" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Batch shape: </span><span class="sc">{</span>images<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb26-459"><a href="#cb26-459" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Labels shape: </span><span class="sc">{</span>labels<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb26-460"><a href="#cb26-460" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Batch on device will be: </span><span class="sc">{</span>images<span class="sc">.</span>to(device)<span class="sc">.</span>device<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb26-461"><a href="#cb26-461" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-462"><a href="#cb26-462" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-463"><a href="#cb26-463" aria-hidden="true" tabindex="-1"></a><span class="fu">### Step 5: Build the Model</span></span>
<span id="cb26-464"><a href="#cb26-464" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-465"><a href="#cb26-465" aria-hidden="true" tabindex="-1"></a>TerraTorch's <span class="in">`EncoderDecoderFactory`</span> makes it simple to build models.</span>
<span id="cb26-466"><a href="#cb26-466" aria-hidden="true" tabindex="-1"></a>**How `build_model` Works**</span>
<span id="cb26-467"><a href="#cb26-467" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-468"><a href="#cb26-468" aria-hidden="true" tabindex="-1"></a>The <span class="in">`build_model`</span> method from <span class="in">`EncoderDecoderFactory`</span> creates a flexible model by combining a backbone (encoder) with a task-specific decoder head. For classification, the decoder will produce logits of shape <span class="in">`[batch_size, num_classes]`</span>. This method is highly customizable and is central to TerraTorch's architectural flexibility.</span>
<span id="cb26-469"><a href="#cb26-469" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-470"><a href="#cb26-470" aria-hidden="true" tabindex="-1"></a>**Key arguments to `build_model`:**</span>
<span id="cb26-471"><a href="#cb26-471" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-472"><a href="#cb26-472" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`task`</span>: The type of task (<span class="in">`"classification"`</span>, <span class="in">`"segmentation"`</span>, <span class="in">`"regression"`</span>, etc.)</span>
<span id="cb26-473"><a href="#cb26-473" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`backbone`</span>: The encoder backbone to use (e.g., <span class="in">`"prithvi_eo_v1_100"`</span>, <span class="in">`"prithvi_eo_v2_300"`</span>, <span class="in">`"satmae"`</span>, <span class="in">`"clay"`</span>, <span class="in">`"timm_resnet50"`</span>)</span>
<span id="cb26-474"><a href="#cb26-474" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`decoder`</span>: The decoder architecture to attach. For classification, <span class="in">`"FCNDecoder"`</span> is a typical choice; for segmentation, you might use <span class="in">`"SegmentationDecoder"`</span> or others suitable for the task.</span>
<span id="cb26-475"><a href="#cb26-475" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`num_classes`</span>: The number of output classes for classification (or channels for other tasks)</span>
<span id="cb26-476"><a href="#cb26-476" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-477"><a href="#cb26-477" aria-hidden="true" tabindex="-1"></a>**Further arguments** (advanced):</span>
<span id="cb26-478"><a href="#cb26-478" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-479"><a href="#cb26-479" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`pretrained`</span>: If <span class="in">`True`</span>, will use pretrained weights for the backbone where available.</span>
<span id="cb26-480"><a href="#cb26-480" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`in_channels`</span>: Number of input channels; must match your data (EuroSAT uses 6 bands).</span>
<span id="cb26-481"><a href="#cb26-481" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`freeze_encoder`</span>: If <span class="in">`True`</span>, the backbone weights will not be updated during training.</span>
<span id="cb26-482"><a href="#cb26-482" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`decoder_kwargs`</span>: Dictionary of extra arguments for fine-tuning decoder behavior.</span>
<span id="cb26-483"><a href="#cb26-483" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-484"><a href="#cb26-484" aria-hidden="true" tabindex="-1"></a>For official documentation and a full list of arguments, see:  </span>
<span id="cb26-485"><a href="#cb26-485" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">https://terratorch.readthedocs.io/en/latest/api/terratorch.models.html#terratorch.models.EncoderDecoderFactory.build_model</span><span class="co">](https://terratorch.readthedocs.io/en/latest/api/terratorch.models.html#terratorch.models.EncoderDecoderFactory.build_model)</span></span>
<span id="cb26-486"><a href="#cb26-486" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-487"><a href="#cb26-487" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-490"><a href="#cb26-490" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-491"><a href="#cb26-491" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> terratorch.models <span class="im">import</span> EncoderDecoderFactory</span>
<span id="cb26-492"><a href="#cb26-492" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb26-493"><a href="#cb26-493" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-494"><a href="#cb26-494" aria-hidden="true" tabindex="-1"></a><span class="co"># Create model factory</span></span>
<span id="cb26-495"><a href="#cb26-495" aria-hidden="true" tabindex="-1"></a>model_factory <span class="op">=</span> EncoderDecoderFactory()</span>
<span id="cb26-496"><a href="#cb26-496" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-497"><a href="#cb26-497" aria-hidden="true" tabindex="-1"></a><span class="co"># Build classification model with Prithvi backbone</span></span>
<span id="cb26-498"><a href="#cb26-498" aria-hidden="true" tabindex="-1"></a>num_classes <span class="op">=</span> <span class="bu">len</span>(train_dataset.classes)</span>
<span id="cb26-499"><a href="#cb26-499" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-500"><a href="#cb26-500" aria-hidden="true" tabindex="-1"></a><span class="co"># Suppress expected TerraTorch decoder compatibility warning</span></span>
<span id="cb26-501"><a href="#cb26-501" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> warnings.catch_warnings():</span>
<span id="cb26-502"><a href="#cb26-502" aria-hidden="true" tabindex="-1"></a>    warnings.filterwarnings(<span class="st">"ignore"</span>, message<span class="op">=</span><span class="st">".*includes_head.*"</span>)</span>
<span id="cb26-503"><a href="#cb26-503" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> model_factory.build_model(</span>
<span id="cb26-504"><a href="#cb26-504" aria-hidden="true" tabindex="-1"></a>        task<span class="op">=</span><span class="st">"classification"</span>,</span>
<span id="cb26-505"><a href="#cb26-505" aria-hidden="true" tabindex="-1"></a>        backbone<span class="op">=</span><span class="st">"prithvi_eo_v1_100"</span>,  <span class="co"># 100M parameter Prithvi</span></span>
<span id="cb26-506"><a href="#cb26-506" aria-hidden="true" tabindex="-1"></a>        decoder<span class="op">=</span><span class="st">"FCNDecoder"</span>,           <span class="co"># Simple fully-convolutional decoder</span></span>
<span id="cb26-507"><a href="#cb26-507" aria-hidden="true" tabindex="-1"></a>        num_classes<span class="op">=</span>num_classes         <span class="co"># Based on actual dataset</span></span>
<span id="cb26-508"><a href="#cb26-508" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb26-509"><a href="#cb26-509" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-510"><a href="#cb26-510" aria-hidden="true" tabindex="-1"></a><span class="co"># Move model to device</span></span>
<span id="cb26-511"><a href="#cb26-511" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> model.to(device)</span>
<span id="cb26-512"><a href="#cb26-512" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-513"><a href="#cb26-513" aria-hidden="true" tabindex="-1"></a><span class="co"># Count parameters</span></span>
<span id="cb26-514"><a href="#cb26-514" aria-hidden="true" tabindex="-1"></a>total_params <span class="op">=</span> <span class="bu">sum</span>(p.numel() <span class="cf">for</span> p <span class="kw">in</span> model.parameters())</span>
<span id="cb26-515"><a href="#cb26-515" aria-hidden="true" tabindex="-1"></a>trainable_params <span class="op">=</span> <span class="bu">sum</span>(p.numel() <span class="cf">for</span> p <span class="kw">in</span> model.parameters() <span class="cf">if</span> p.requires_grad)</span>
<span id="cb26-516"><a href="#cb26-516" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-517"><a href="#cb26-517" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Model loaded: Prithvi-100M with FCN decoder"</span>)</span>
<span id="cb26-518"><a href="#cb26-518" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Total parameters: </span><span class="sc">{</span>total_params<span class="sc">:,}</span><span class="ss">"</span>)</span>
<span id="cb26-519"><a href="#cb26-519" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Trainable parameters: </span><span class="sc">{</span>trainable_params<span class="sc">:,}</span><span class="ss">"</span>)</span>
<span id="cb26-520"><a href="#cb26-520" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Model on device: </span><span class="sc">{</span><span class="bu">next</span>(model.parameters())<span class="sc">.</span>device<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb26-521"><a href="#cb26-521" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-522"><a href="#cb26-522" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-523"><a href="#cb26-523" aria-hidden="true" tabindex="-1"></a>:::{.callout-note}</span>
<span id="cb26-524"><a href="#cb26-524" aria-hidden="true" tabindex="-1"></a><span class="fu">## Understanding the Architecture</span></span>
<span id="cb26-525"><a href="#cb26-525" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-526"><a href="#cb26-526" aria-hidden="true" tabindex="-1"></a>**Encoder (Backbone):**</span>
<span id="cb26-527"><a href="#cb26-527" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-528"><a href="#cb26-528" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`prithvi_eo_v1_100`</span> - Vision Transformer pretrained on HLS imagery</span>
<span id="cb26-529"><a href="#cb26-529" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Extracts spatial features from 6-band input</span>
<span id="cb26-530"><a href="#cb26-530" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Parameters frozen or fine-tuned depending on task</span>
<span id="cb26-531"><a href="#cb26-531" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-532"><a href="#cb26-532" aria-hidden="true" tabindex="-1"></a>**Decoder (Head):**</span>
<span id="cb26-533"><a href="#cb26-533" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-534"><a href="#cb26-534" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`FCNDecoder`</span> - Fully Convolutional Network</span>
<span id="cb26-535"><a href="#cb26-535" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Aggregates encoder features</span>
<span id="cb26-536"><a href="#cb26-536" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Produces class logits (num_classes outputs)</span>
<span id="cb26-537"><a href="#cb26-537" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-538"><a href="#cb26-538" aria-hidden="true" tabindex="-1"></a>**Alternative backbones:** <span class="in">`prithvi_eo_v2_300`</span>, <span class="in">`satmae`</span>, <span class="in">`scalemae`</span>, <span class="in">`clay`</span>, <span class="in">`timm_resnet50`</span></span>
<span id="cb26-539"><a href="#cb26-539" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb26-540"><a href="#cb26-540" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-541"><a href="#cb26-541" aria-hidden="true" tabindex="-1"></a><span class="fu">## Part 3: Zero-Shot Inference - Baseline Performance</span></span>
<span id="cb26-542"><a href="#cb26-542" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-543"><a href="#cb26-543" aria-hidden="true" tabindex="-1"></a>Before training the model, let's evaluate what the pretrained Prithvi backbone already knows. This establishes a baseline and demonstrates the power of transfer learning.</span>
<span id="cb26-544"><a href="#cb26-544" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-545"><a href="#cb26-545" aria-hidden="true" tabindex="-1"></a><span class="fu">### Understanding Zero-Shot Inference</span></span>
<span id="cb26-546"><a href="#cb26-546" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-547"><a href="#cb26-547" aria-hidden="true" tabindex="-1"></a>**Zero-shot inference** means using a model without any task-specific training:</span>
<span id="cb26-548"><a href="#cb26-548" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-549"><a href="#cb26-549" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The Prithvi backbone was pretrained on massive HLS satellite imagery</span>
<span id="cb26-550"><a href="#cb26-550" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>It learned general geospatial features (vegetation patterns, water bodies, urban structures)</span>
<span id="cb26-551"><a href="#cb26-551" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>But it has never seen EuroSAT or these specific land use classes</span>
<span id="cb26-552"><a href="#cb26-552" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>The classification head is randomly initialized</span>
<span id="cb26-553"><a href="#cb26-553" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-554"><a href="#cb26-554" aria-hidden="true" tabindex="-1"></a><span class="fu">### Step 6: Zero-Shot Evaluation</span></span>
<span id="cb26-555"><a href="#cb26-555" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-556"><a href="#cb26-556" aria-hidden="true" tabindex="-1"></a>Let's evaluate the model using the same representative images we visualized earlier - one sample from each class.</span>
<span id="cb26-557"><a href="#cb26-557" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-560"><a href="#cb26-560" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-561"><a href="#cb26-561" aria-hidden="true" tabindex="-1"></a><span class="co"># Use the same representative samples from Step 2</span></span>
<span id="cb26-562"><a href="#cb26-562" aria-hidden="true" tabindex="-1"></a><span class="co"># Transform them to 6 bands + normalize</span></span>
<span id="cb26-563"><a href="#cb26-563" aria-hidden="true" tabindex="-1"></a>zero_shot_images <span class="op">=</span> []</span>
<span id="cb26-564"><a href="#cb26-564" aria-hidden="true" tabindex="-1"></a>zero_shot_labels <span class="op">=</span> []</span>
<span id="cb26-565"><a href="#cb26-565" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-566"><a href="#cb26-566" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="st">"Preparing representative samples for zero-shot evaluation..."</span>)</span>
<span id="cb26-567"><a href="#cb26-567" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> class_idx, image <span class="kw">in</span> samples_per_class.items():</span>
<span id="cb26-568"><a href="#cb26-568" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Apply transforms (band selection + normalization)</span></span>
<span id="cb26-569"><a href="#cb26-569" aria-hidden="true" tabindex="-1"></a>    sample <span class="op">=</span> {<span class="st">'image'</span>: image, <span class="st">'label'</span>: class_idx}</span>
<span id="cb26-570"><a href="#cb26-570" aria-hidden="true" tabindex="-1"></a>    transformed <span class="op">=</span> transform(sample)</span>
<span id="cb26-571"><a href="#cb26-571" aria-hidden="true" tabindex="-1"></a>    zero_shot_images.append(transformed[<span class="st">'image'</span>])</span>
<span id="cb26-572"><a href="#cb26-572" aria-hidden="true" tabindex="-1"></a>    zero_shot_labels.append(transformed[<span class="st">'label'</span>])</span>
<span id="cb26-573"><a href="#cb26-573" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-574"><a href="#cb26-574" aria-hidden="true" tabindex="-1"></a><span class="co"># Stack into batch</span></span>
<span id="cb26-575"><a href="#cb26-575" aria-hidden="true" tabindex="-1"></a>zero_shot_images <span class="op">=</span> torch.stack(zero_shot_images).to(device)</span>
<span id="cb26-576"><a href="#cb26-576" aria-hidden="true" tabindex="-1"></a>zero_shot_labels <span class="op">=</span> torch.tensor(zero_shot_labels).to(device)</span>
<span id="cb26-577"><a href="#cb26-577" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-578"><a href="#cb26-578" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Zero-shot evaluation batch: </span><span class="sc">{</span>zero_shot_images<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb26-579"><a href="#cb26-579" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"One sample per class (</span><span class="sc">{</span><span class="bu">len</span>(train_dataset.classes)<span class="sc">}</span><span class="ss"> total)"</span>)</span>
<span id="cb26-580"><a href="#cb26-580" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f""</span>)</span>
<span id="cb26-581"><a href="#cb26-581" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-582"><a href="#cb26-582" aria-hidden="true" tabindex="-1"></a><span class="co"># Set model to evaluation mode</span></span>
<span id="cb26-583"><a href="#cb26-583" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">eval</span>()</span>
<span id="cb26-584"><a href="#cb26-584" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-585"><a href="#cb26-585" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate zero-shot performance</span></span>
<span id="cb26-586"><a href="#cb26-586" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="st">"Evaluating zero-shot performance..."</span>)</span>
<span id="cb26-587"><a href="#cb26-587" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="st">"="</span> <span class="op">*</span> <span class="dv">60</span>)</span>
<span id="cb26-588"><a href="#cb26-588" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-589"><a href="#cb26-589" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb26-590"><a href="#cb26-590" aria-hidden="true" tabindex="-1"></a>    outputs <span class="op">=</span> model(zero_shot_images)</span>
<span id="cb26-591"><a href="#cb26-591" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">hasattr</span>(outputs, <span class="st">'output'</span>):</span>
<span id="cb26-592"><a href="#cb26-592" aria-hidden="true" tabindex="-1"></a>        outputs <span class="op">=</span> outputs.output</span>
<span id="cb26-593"><a href="#cb26-593" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-594"><a href="#cb26-594" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get predictions</span></span>
<span id="cb26-595"><a href="#cb26-595" aria-hidden="true" tabindex="-1"></a>    _, predicted <span class="op">=</span> outputs.<span class="bu">max</span>(<span class="dv">1</span>)</span>
<span id="cb26-596"><a href="#cb26-596" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-597"><a href="#cb26-597" aria-hidden="true" tabindex="-1"></a>correct <span class="op">=</span> predicted.eq(zero_shot_labels).<span class="bu">sum</span>().item()</span>
<span id="cb26-598"><a href="#cb26-598" aria-hidden="true" tabindex="-1"></a>total <span class="op">=</span> <span class="bu">len</span>(zero_shot_labels)</span>
<span id="cb26-599"><a href="#cb26-599" aria-hidden="true" tabindex="-1"></a>zero_shot_accuracy <span class="op">=</span> correct <span class="op">/</span> total</span>
<span id="cb26-600"><a href="#cb26-600" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-601"><a href="#cb26-601" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Zero-Shot Accuracy: </span><span class="sc">{</span>zero_shot_accuracy<span class="sc">:.4f}</span><span class="ss"> (</span><span class="sc">{</span>zero_shot_accuracy<span class="op">*</span><span class="dv">100</span><span class="sc">:.2f}</span><span class="ss">%)"</span>)</span>
<span id="cb26-602"><a href="#cb26-602" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Random Baseline: </span><span class="sc">{</span><span class="fl">1.0</span><span class="op">/</span><span class="bu">len</span>(train_dataset.classes)<span class="sc">:.4f}</span><span class="ss"> (</span><span class="sc">{</span><span class="fl">100.0</span><span class="op">/</span><span class="bu">len</span>(train_dataset.classes)<span class="sc">:.2f}</span><span class="ss">%)"</span>)</span>
<span id="cb26-603"><a href="#cb26-603" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Correct: </span><span class="sc">{</span>correct<span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>total<span class="sc">}</span><span class="ss"> samples"</span>)</span>
<span id="cb26-604"><a href="#cb26-604" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f""</span>)</span>
<span id="cb26-605"><a href="#cb26-605" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="st">"Per-Class Zero-Shot Results:"</span>)</span>
<span id="cb26-606"><a href="#cb26-606" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="st">"-"</span> <span class="op">*</span> <span class="dv">60</span>)</span>
<span id="cb26-607"><a href="#cb26-607" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-608"><a href="#cb26-608" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> idx <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(zero_shot_labels)):</span>
<span id="cb26-609"><a href="#cb26-609" aria-hidden="true" tabindex="-1"></a>    true_label <span class="op">=</span> zero_shot_labels[idx].item()</span>
<span id="cb26-610"><a href="#cb26-610" aria-hidden="true" tabindex="-1"></a>    pred_label <span class="op">=</span> predicted[idx].item()</span>
<span id="cb26-611"><a href="#cb26-611" aria-hidden="true" tabindex="-1"></a>    class_name <span class="op">=</span> train_dataset.classes[true_label]</span>
<span id="cb26-612"><a href="#cb26-612" aria-hidden="true" tabindex="-1"></a>    pred_name <span class="op">=</span> train_dataset.classes[pred_label]</span>
<span id="cb26-613"><a href="#cb26-613" aria-hidden="true" tabindex="-1"></a>    correct_mark <span class="op">=</span> <span class="st">"âœ“"</span> <span class="cf">if</span> true_label <span class="op">==</span> pred_label <span class="cf">else</span> <span class="st">"âœ—"</span></span>
<span id="cb26-614"><a href="#cb26-614" aria-hidden="true" tabindex="-1"></a>    logger.info(<span class="ss">f"  </span><span class="sc">{</span>correct_mark<span class="sc">}</span><span class="ss"> </span><span class="sc">{</span>class_name<span class="sc">:20s}</span><span class="ss"> â†’ </span><span class="sc">{</span>pred_name<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb26-615"><a href="#cb26-615" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-616"><a href="#cb26-616" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-617"><a href="#cb26-617" aria-hidden="true" tabindex="-1"></a>:::{.callout-note}</span>
<span id="cb26-618"><a href="#cb26-618" aria-hidden="true" tabindex="-1"></a><span class="fu">## Interpreting Zero-Shot Results</span></span>
<span id="cb26-619"><a href="#cb26-619" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-620"><a href="#cb26-620" aria-hidden="true" tabindex="-1"></a>**Expected performance (1 sample per class):**</span>
<span id="cb26-621"><a href="#cb26-621" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-622"><a href="#cb26-622" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Random guessing: ~11% (1 correct out of 9 classes)</span>
<span id="cb26-623"><a href="#cb26-623" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Zero-shot Prithvi: 11-44% (1-4 correct out of 9)</span>
<span id="cb26-624"><a href="#cb26-624" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Performance varies dramatically by class</span>
<span id="cb26-625"><a href="#cb26-625" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-626"><a href="#cb26-626" aria-hidden="true" tabindex="-1"></a>**Classes Prithvi might recognize:**</span>
<span id="cb26-627"><a href="#cb26-627" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-628"><a href="#cb26-628" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Likely correct**: Forest, SeaLake (strong visual signatures, common in HLS training)</span>
<span id="cb26-629"><a href="#cb26-629" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Sometimes correct**: Pasture, HerbaceousVegetation (agricultural patterns)</span>
<span id="cb26-630"><a href="#cb26-630" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Rarely correct**: Highway, Industrial, Residential (fine-grained urban distinctions)</span>
<span id="cb26-631"><a href="#cb26-631" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-632"><a href="#cb26-632" aria-hidden="true" tabindex="-1"></a>**Why?** Prithvi learned general geospatial features during pretraining on HLS imagery. Natural land cover classes with distinct spectral signatures are easier to recognize than specific urban subtypes.</span>
<span id="cb26-633"><a href="#cb26-633" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb26-634"><a href="#cb26-634" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-635"><a href="#cb26-635" aria-hidden="true" tabindex="-1"></a><span class="fu">### Step 7: Visualize Zero-Shot Predictions</span></span>
<span id="cb26-636"><a href="#cb26-636" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-637"><a href="#cb26-637" aria-hidden="true" tabindex="-1"></a>Let's visualize the zero-shot predictions on the same representative images:</span>
<span id="cb26-638"><a href="#cb26-638" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-641"><a href="#cb26-641" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-642"><a href="#cb26-642" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize zero-shot predictions</span></span>
<span id="cb26-643"><a href="#cb26-643" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="st">"Visualizing zero-shot predictions..."</span>)</span>
<span id="cb26-644"><a href="#cb26-644" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-645"><a href="#cb26-645" aria-hidden="true" tabindex="-1"></a>num_vis <span class="op">=</span> <span class="bu">len</span>(samples_per_class)</span>
<span id="cb26-646"><a href="#cb26-646" aria-hidden="true" tabindex="-1"></a>n_cols <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb26-647"><a href="#cb26-647" aria-hidden="true" tabindex="-1"></a>n_rows <span class="op">=</span> <span class="bu">int</span>(np.ceil(num_vis <span class="op">/</span> n_cols))</span>
<span id="cb26-648"><a href="#cb26-648" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-649"><a href="#cb26-649" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(n_rows, n_cols, figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">3</span><span class="op">*</span>n_rows))</span>
<span id="cb26-650"><a href="#cb26-650" aria-hidden="true" tabindex="-1"></a>axes <span class="op">=</span> axes.ravel()</span>
<span id="cb26-651"><a href="#cb26-651" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-652"><a href="#cb26-652" aria-hidden="true" tabindex="-1"></a><span class="co"># Already have predictions from Step 6</span></span>
<span id="cb26-653"><a href="#cb26-653" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> idx, (class_idx, image) <span class="kw">in</span> <span class="bu">enumerate</span>(samples_per_class.items()):</span>
<span id="cb26-654"><a href="#cb26-654" aria-hidden="true" tabindex="-1"></a>    true_label <span class="op">=</span> class_idx</span>
<span id="cb26-655"><a href="#cb26-655" aria-hidden="true" tabindex="-1"></a>    pred_label <span class="op">=</span> predicted[idx].item()</span>
<span id="cb26-656"><a href="#cb26-656" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-657"><a href="#cb26-657" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create RGB visualization from original 13-band image</span></span>
<span id="cb26-658"><a href="#cb26-658" aria-hidden="true" tabindex="-1"></a>    rgb <span class="op">=</span> image[[<span class="dv">3</span>, <span class="dv">2</span>, <span class="dv">1</span>], :, :].numpy()  <span class="co"># Red, Green, Blue</span></span>
<span id="cb26-659"><a href="#cb26-659" aria-hidden="true" tabindex="-1"></a>    rgb <span class="op">=</span> np.transpose(rgb, (<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">0</span>))</span>
<span id="cb26-660"><a href="#cb26-660" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-661"><a href="#cb26-661" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Normalize for display</span></span>
<span id="cb26-662"><a href="#cb26-662" aria-hidden="true" tabindex="-1"></a>    p2, p98 <span class="op">=</span> np.percentile(rgb, (<span class="dv">2</span>, <span class="dv">98</span>))</span>
<span id="cb26-663"><a href="#cb26-663" aria-hidden="true" tabindex="-1"></a>    rgb_norm <span class="op">=</span> np.clip((rgb <span class="op">-</span> p2) <span class="op">/</span> (p98 <span class="op">-</span> p2), <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb26-664"><a href="#cb26-664" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-665"><a href="#cb26-665" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Plot</span></span>
<span id="cb26-666"><a href="#cb26-666" aria-hidden="true" tabindex="-1"></a>    axes[idx].imshow(rgb_norm)</span>
<span id="cb26-667"><a href="#cb26-667" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-668"><a href="#cb26-668" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Color code: green if correct, red if wrong</span></span>
<span id="cb26-669"><a href="#cb26-669" aria-hidden="true" tabindex="-1"></a>    color <span class="op">=</span> <span class="st">'green'</span> <span class="cf">if</span> pred_label <span class="op">==</span> true_label <span class="cf">else</span> <span class="st">'red'</span></span>
<span id="cb26-670"><a href="#cb26-670" aria-hidden="true" tabindex="-1"></a>    axes[idx].set_title(</span>
<span id="cb26-671"><a href="#cb26-671" aria-hidden="true" tabindex="-1"></a>        <span class="ss">f"True: </span><span class="sc">{</span>train_dataset<span class="sc">.</span>classes[true_label]<span class="sc">}</span><span class="ch">\n</span><span class="ss">"</span></span>
<span id="cb26-672"><a href="#cb26-672" aria-hidden="true" tabindex="-1"></a>        <span class="ss">f"Pred: </span><span class="sc">{</span>train_dataset<span class="sc">.</span>classes[pred_label]<span class="sc">}</span><span class="ss">"</span>,</span>
<span id="cb26-673"><a href="#cb26-673" aria-hidden="true" tabindex="-1"></a>        color<span class="op">=</span>color,</span>
<span id="cb26-674"><a href="#cb26-674" aria-hidden="true" tabindex="-1"></a>        fontsize<span class="op">=</span><span class="dv">10</span></span>
<span id="cb26-675"><a href="#cb26-675" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb26-676"><a href="#cb26-676" aria-hidden="true" tabindex="-1"></a>    axes[idx].axis(<span class="st">'off'</span>)</span>
<span id="cb26-677"><a href="#cb26-677" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-678"><a href="#cb26-678" aria-hidden="true" tabindex="-1"></a><span class="co"># Hide any unused subplots</span></span>
<span id="cb26-679"><a href="#cb26-679" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> idx <span class="kw">in</span> <span class="bu">range</span>(num_vis, <span class="bu">len</span>(axes)):</span>
<span id="cb26-680"><a href="#cb26-680" aria-hidden="true" tabindex="-1"></a>    axes[idx].axis(<span class="st">'off'</span>)</span>
<span id="cb26-681"><a href="#cb26-681" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-682"><a href="#cb26-682" aria-hidden="true" tabindex="-1"></a>plt.suptitle(<span class="st">"Zero-Shot Predictions (Before Training)"</span>, fontsize<span class="op">=</span><span class="dv">14</span>, y<span class="op">=</span><span class="fl">0.995</span>)</span>
<span id="cb26-683"><a href="#cb26-683" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb26-684"><a href="#cb26-684" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb26-685"><a href="#cb26-685" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-686"><a href="#cb26-686" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Green titles = correct prediction | Red titles = incorrect prediction"</span>)</span>
<span id="cb26-687"><a href="#cb26-687" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-688"><a href="#cb26-688" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-689"><a href="#cb26-689" aria-hidden="true" tabindex="-1"></a>:::{.callout-tip}</span>
<span id="cb26-690"><a href="#cb26-690" aria-hidden="true" tabindex="-1"></a><span class="fu">## Zero-Shot Performance Analysis</span></span>
<span id="cb26-691"><a href="#cb26-691" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-692"><a href="#cb26-692" aria-hidden="true" tabindex="-1"></a>**What to look for:**</span>
<span id="cb26-693"><a href="#cb26-693" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-694"><a href="#cb26-694" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**Correct predictions**: Classes the model identifies without training</span>
<span id="cb26-695"><a href="#cb26-695" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**Systematic errors**: Consistent misclassifications reveal what Prithvi confuses</span>
<span id="cb26-696"><a href="#cb26-696" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>**Transfer learning potential**: Better than random = useful pretrained features</span>
<span id="cb26-697"><a href="#cb26-697" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-698"><a href="#cb26-698" aria-hidden="true" tabindex="-1"></a>**Common patterns:**</span>
<span id="cb26-699"><a href="#cb26-699" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-700"><a href="#cb26-700" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Natural land cover (forest, water) often recognized</span>
<span id="cb26-701"><a href="#cb26-701" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Urban classes frequently confused with each other</span>
<span id="cb26-702"><a href="#cb26-702" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Agricultural subtypes hard to distinguish without fine-tuning</span>
<span id="cb26-703"><a href="#cb26-703" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb26-704"><a href="#cb26-704" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-705"><a href="#cb26-705" aria-hidden="true" tabindex="-1"></a><span class="fu">## Part 4: Few-Shot Learning - Learning from Limited Data</span></span>
<span id="cb26-706"><a href="#cb26-706" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-707"><a href="#cb26-707" aria-hidden="true" tabindex="-1"></a>Zero-shot performance is limited by the randomly initialized decoder. But what if we had just a few examples per class? Let's explore two few-shot approaches that demonstrate the power of foundation models with minimal data.</span>
<span id="cb26-708"><a href="#cb26-708" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-709"><a href="#cb26-709" aria-hidden="true" tabindex="-1"></a><span class="fu">### Helper: Create Few-Shot Datasets</span></span>
<span id="cb26-710"><a href="#cb26-710" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-711"><a href="#cb26-711" aria-hidden="true" tabindex="-1"></a>First, let's create a helper function to sample K examples per class from the training set.</span>
<span id="cb26-712"><a href="#cb26-712" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-715"><a href="#cb26-715" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-716"><a href="#cb26-716" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> Subset</span>
<span id="cb26-717"><a href="#cb26-717" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-718"><a href="#cb26-718" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> create_few_shot_dataset(dataset, k_shot<span class="op">=</span><span class="dv">5</span>, seed<span class="op">=</span><span class="dv">42</span>):</span>
<span id="cb26-719"><a href="#cb26-719" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb26-720"><a href="#cb26-720" aria-hidden="true" tabindex="-1"></a><span class="co">    Create a dataset with k examples per class.</span></span>
<span id="cb26-721"><a href="#cb26-721" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-722"><a href="#cb26-722" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters</span></span>
<span id="cb26-723"><a href="#cb26-723" aria-hidden="true" tabindex="-1"></a><span class="co">    ----------</span></span>
<span id="cb26-724"><a href="#cb26-724" aria-hidden="true" tabindex="-1"></a><span class="co">    dataset : Dataset</span></span>
<span id="cb26-725"><a href="#cb26-725" aria-hidden="true" tabindex="-1"></a><span class="co">        Source dataset</span></span>
<span id="cb26-726"><a href="#cb26-726" aria-hidden="true" tabindex="-1"></a><span class="co">    k_shot : int</span></span>
<span id="cb26-727"><a href="#cb26-727" aria-hidden="true" tabindex="-1"></a><span class="co">        Number of examples per class</span></span>
<span id="cb26-728"><a href="#cb26-728" aria-hidden="true" tabindex="-1"></a><span class="co">    seed : int</span></span>
<span id="cb26-729"><a href="#cb26-729" aria-hidden="true" tabindex="-1"></a><span class="co">        Random seed for reproducibility</span></span>
<span id="cb26-730"><a href="#cb26-730" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-731"><a href="#cb26-731" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns</span></span>
<span id="cb26-732"><a href="#cb26-732" aria-hidden="true" tabindex="-1"></a><span class="co">    -------</span></span>
<span id="cb26-733"><a href="#cb26-733" aria-hidden="true" tabindex="-1"></a><span class="co">    Subset</span></span>
<span id="cb26-734"><a href="#cb26-734" aria-hidden="true" tabindex="-1"></a><span class="co">        Subset with k examples per class</span></span>
<span id="cb26-735"><a href="#cb26-735" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb26-736"><a href="#cb26-736" aria-hidden="true" tabindex="-1"></a>    np.random.seed(seed)</span>
<span id="cb26-737"><a href="#cb26-737" aria-hidden="true" tabindex="-1"></a>    random.seed(seed)</span>
<span id="cb26-738"><a href="#cb26-738" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-739"><a href="#cb26-739" aria-hidden="true" tabindex="-1"></a>    num_classes <span class="op">=</span> <span class="bu">len</span>(dataset.classes)</span>
<span id="cb26-740"><a href="#cb26-740" aria-hidden="true" tabindex="-1"></a>    samples_per_class <span class="op">=</span> {i: [] <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(num_classes)}</span>
<span id="cb26-741"><a href="#cb26-741" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-742"><a href="#cb26-742" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Random sampling to find k examples per class</span></span>
<span id="cb26-743"><a href="#cb26-743" aria-hidden="true" tabindex="-1"></a>    random_indices <span class="op">=</span> random.sample(<span class="bu">range</span>(<span class="bu">len</span>(dataset)), <span class="bu">min</span>(<span class="bu">len</span>(dataset), num_classes <span class="op">*</span> k_shot <span class="op">*</span> <span class="dv">10</span>))</span>
<span id="cb26-744"><a href="#cb26-744" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-745"><a href="#cb26-745" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> idx <span class="kw">in</span> random_indices:</span>
<span id="cb26-746"><a href="#cb26-746" aria-hidden="true" tabindex="-1"></a>        sample <span class="op">=</span> dataset[idx]</span>
<span id="cb26-747"><a href="#cb26-747" aria-hidden="true" tabindex="-1"></a>        label <span class="op">=</span> sample[<span class="st">'label'</span>]</span>
<span id="cb26-748"><a href="#cb26-748" aria-hidden="true" tabindex="-1"></a>        label_idx <span class="op">=</span> <span class="bu">int</span>(label) <span class="cf">if</span> <span class="bu">hasattr</span>(label, <span class="st">'item'</span>) <span class="cf">else</span> label</span>
<span id="cb26-749"><a href="#cb26-749" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-750"><a href="#cb26-750" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">len</span>(samples_per_class[label_idx]) <span class="op">&lt;</span> k_shot:</span>
<span id="cb26-751"><a href="#cb26-751" aria-hidden="true" tabindex="-1"></a>            samples_per_class[label_idx].append(idx)</span>
<span id="cb26-752"><a href="#cb26-752" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-753"><a href="#cb26-753" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Stop when we have k examples for all classes</span></span>
<span id="cb26-754"><a href="#cb26-754" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">all</span>(<span class="bu">len</span>(v) <span class="op">==</span> k_shot <span class="cf">for</span> v <span class="kw">in</span> samples_per_class.values()):</span>
<span id="cb26-755"><a href="#cb26-755" aria-hidden="true" tabindex="-1"></a>            <span class="cf">break</span></span>
<span id="cb26-756"><a href="#cb26-756" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-757"><a href="#cb26-757" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Flatten to single list of indices</span></span>
<span id="cb26-758"><a href="#cb26-758" aria-hidden="true" tabindex="-1"></a>    indices <span class="op">=</span> [idx <span class="cf">for</span> class_indices <span class="kw">in</span> samples_per_class.values() <span class="cf">for</span> idx <span class="kw">in</span> class_indices]</span>
<span id="cb26-759"><a href="#cb26-759" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-760"><a href="#cb26-760" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> Subset(dataset, indices), samples_per_class</span>
<span id="cb26-761"><a href="#cb26-761" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-762"><a href="#cb26-762" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="st">"Few-shot dataset helper created"</span>)</span>
<span id="cb26-763"><a href="#cb26-763" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-764"><a href="#cb26-764" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-765"><a href="#cb26-765" aria-hidden="true" tabindex="-1"></a><span class="fu">### Step 6a: Prototype Networks - No Training Required</span></span>
<span id="cb26-766"><a href="#cb26-766" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-767"><a href="#cb26-767" aria-hidden="true" tabindex="-1"></a>Prototype networks use the model's output representations to classify by finding the nearest prototype (mean representation per class). We'll use the model's logits (pre-softmax outputs) as feature representations.</span>
<span id="cb26-768"><a href="#cb26-768" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-769"><a href="#cb26-769" aria-hidden="true" tabindex="-1"></a>**Key idea**: Even with a randomly initialized decoder, the model's output space should show some structure that we can exploit with a few labeled examples.</span>
<span id="cb26-770"><a href="#cb26-770" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-773"><a href="#cb26-773" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-774"><a href="#cb26-774" aria-hidden="true" tabindex="-1"></a><span class="co"># Create 5-shot support set</span></span>
<span id="cb26-775"><a href="#cb26-775" aria-hidden="true" tabindex="-1"></a>k_shot <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb26-776"><a href="#cb26-776" aria-hidden="true" tabindex="-1"></a>few_shot_subset, few_shot_indices <span class="op">=</span> create_few_shot_dataset(train_dataset, k_shot<span class="op">=</span>k_shot)</span>
<span id="cb26-777"><a href="#cb26-777" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-778"><a href="#cb26-778" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Created </span><span class="sc">{</span>k_shot<span class="sc">}</span><span class="ss">-shot dataset:"</span>)</span>
<span id="cb26-779"><a href="#cb26-779" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Total samples: </span><span class="sc">{</span><span class="bu">len</span>(few_shot_subset)<span class="sc">}</span><span class="ss"> (</span><span class="sc">{</span>k_shot<span class="sc">}</span><span class="ss"> per class Ã— </span><span class="sc">{</span><span class="bu">len</span>(train_dataset.classes)<span class="sc">}</span><span class="ss"> classes)"</span>)</span>
<span id="cb26-780"><a href="#cb26-780" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="st">""</span>)</span>
<span id="cb26-781"><a href="#cb26-781" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-782"><a href="#cb26-782" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract features from backbone for support set</span></span>
<span id="cb26-783"><a href="#cb26-783" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">eval</span>()</span>
<span id="cb26-784"><a href="#cb26-784" aria-hidden="true" tabindex="-1"></a>support_features <span class="op">=</span> []</span>
<span id="cb26-785"><a href="#cb26-785" aria-hidden="true" tabindex="-1"></a>support_labels <span class="op">=</span> []</span>
<span id="cb26-786"><a href="#cb26-786" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-787"><a href="#cb26-787" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="st">"Extracting features from Prithvi backbone..."</span>)</span>
<span id="cb26-788"><a href="#cb26-788" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb26-789"><a href="#cb26-789" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> class_idx, indices <span class="kw">in</span> few_shot_indices.items():</span>
<span id="cb26-790"><a href="#cb26-790" aria-hidden="true" tabindex="-1"></a>        class_features <span class="op">=</span> []</span>
<span id="cb26-791"><a href="#cb26-791" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> idx <span class="kw">in</span> indices:</span>
<span id="cb26-792"><a href="#cb26-792" aria-hidden="true" tabindex="-1"></a>            sample <span class="op">=</span> train_dataset[idx]</span>
<span id="cb26-793"><a href="#cb26-793" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Apply transforms</span></span>
<span id="cb26-794"><a href="#cb26-794" aria-hidden="true" tabindex="-1"></a>            transformed <span class="op">=</span> transform(sample)</span>
<span id="cb26-795"><a href="#cb26-795" aria-hidden="true" tabindex="-1"></a>            image <span class="op">=</span> transformed[<span class="st">'image'</span>].unsqueeze(<span class="dv">0</span>).to(device)</span>
<span id="cb26-796"><a href="#cb26-796" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-797"><a href="#cb26-797" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Extract features from backbone</span></span>
<span id="cb26-798"><a href="#cb26-798" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Use model forward pass and extract features before final classification</span></span>
<span id="cb26-799"><a href="#cb26-799" aria-hidden="true" tabindex="-1"></a>            outputs <span class="op">=</span> model(image)</span>
<span id="cb26-800"><a href="#cb26-800" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="bu">hasattr</span>(outputs, <span class="st">'output'</span>):</span>
<span id="cb26-801"><a href="#cb26-801" aria-hidden="true" tabindex="-1"></a>                features <span class="op">=</span> outputs.output</span>
<span id="cb26-802"><a href="#cb26-802" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb26-803"><a href="#cb26-803" aria-hidden="true" tabindex="-1"></a>                features <span class="op">=</span> outputs</span>
<span id="cb26-804"><a href="#cb26-804" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-805"><a href="#cb26-805" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Features are already pooled to (batch, num_classes) by FCNDecoder</span></span>
<span id="cb26-806"><a href="#cb26-806" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Use these as feature representations</span></span>
<span id="cb26-807"><a href="#cb26-807" aria-hidden="true" tabindex="-1"></a>            features <span class="op">=</span> features.squeeze(<span class="dv">0</span>)  <span class="co"># Remove batch dimension</span></span>
<span id="cb26-808"><a href="#cb26-808" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-809"><a href="#cb26-809" aria-hidden="true" tabindex="-1"></a>            class_features.append(features)</span>
<span id="cb26-810"><a href="#cb26-810" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-811"><a href="#cb26-811" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Compute prototype (mean of support features)</span></span>
<span id="cb26-812"><a href="#cb26-812" aria-hidden="true" tabindex="-1"></a>        prototype <span class="op">=</span> torch.stack(class_features).mean(dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb26-813"><a href="#cb26-813" aria-hidden="true" tabindex="-1"></a>        support_features.append(prototype)</span>
<span id="cb26-814"><a href="#cb26-814" aria-hidden="true" tabindex="-1"></a>        support_labels.append(class_idx)</span>
<span id="cb26-815"><a href="#cb26-815" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-816"><a href="#cb26-816" aria-hidden="true" tabindex="-1"></a>support_features <span class="op">=</span> torch.stack(support_features)  <span class="co"># (num_classes, feature_dim)</span></span>
<span id="cb26-817"><a href="#cb26-817" aria-hidden="true" tabindex="-1"></a>support_labels <span class="op">=</span> torch.tensor(support_labels).to(device)</span>
<span id="cb26-818"><a href="#cb26-818" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-819"><a href="#cb26-819" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Extracted prototypes: </span><span class="sc">{</span>support_features<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb26-820"><a href="#cb26-820" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="st">""</span>)</span>
<span id="cb26-821"><a href="#cb26-821" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-822"><a href="#cb26-822" aria-hidden="true" tabindex="-1"></a><span class="co"># Classify test samples by nearest prototype</span></span>
<span id="cb26-823"><a href="#cb26-823" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="st">"Classifying with prototype networks..."</span>)</span>
<span id="cb26-824"><a href="#cb26-824" aria-hidden="true" tabindex="-1"></a>test_features <span class="op">=</span> []</span>
<span id="cb26-825"><a href="#cb26-825" aria-hidden="true" tabindex="-1"></a>test_labels <span class="op">=</span> []</span>
<span id="cb26-826"><a href="#cb26-826" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-827"><a href="#cb26-827" aria-hidden="true" tabindex="-1"></a><span class="co"># Use same representative samples as zero-shot</span></span>
<span id="cb26-828"><a href="#cb26-828" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> class_idx, image <span class="kw">in</span> samples_per_class.items():</span>
<span id="cb26-829"><a href="#cb26-829" aria-hidden="true" tabindex="-1"></a>    sample <span class="op">=</span> {<span class="st">'image'</span>: image, <span class="st">'label'</span>: class_idx}</span>
<span id="cb26-830"><a href="#cb26-830" aria-hidden="true" tabindex="-1"></a>    transformed <span class="op">=</span> transform(sample)</span>
<span id="cb26-831"><a href="#cb26-831" aria-hidden="true" tabindex="-1"></a>    image_tensor <span class="op">=</span> transformed[<span class="st">'image'</span>].unsqueeze(<span class="dv">0</span>).to(device)</span>
<span id="cb26-832"><a href="#cb26-832" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-833"><a href="#cb26-833" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb26-834"><a href="#cb26-834" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Extract features</span></span>
<span id="cb26-835"><a href="#cb26-835" aria-hidden="true" tabindex="-1"></a>        outputs <span class="op">=</span> model(image_tensor)</span>
<span id="cb26-836"><a href="#cb26-836" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">hasattr</span>(outputs, <span class="st">'output'</span>):</span>
<span id="cb26-837"><a href="#cb26-837" aria-hidden="true" tabindex="-1"></a>            features <span class="op">=</span> outputs.output</span>
<span id="cb26-838"><a href="#cb26-838" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb26-839"><a href="#cb26-839" aria-hidden="true" tabindex="-1"></a>            features <span class="op">=</span> outputs</span>
<span id="cb26-840"><a href="#cb26-840" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-841"><a href="#cb26-841" aria-hidden="true" tabindex="-1"></a>        features <span class="op">=</span> features.squeeze(<span class="dv">0</span>)  <span class="co"># Remove batch dimension</span></span>
<span id="cb26-842"><a href="#cb26-842" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-843"><a href="#cb26-843" aria-hidden="true" tabindex="-1"></a>        test_features.append(features)</span>
<span id="cb26-844"><a href="#cb26-844" aria-hidden="true" tabindex="-1"></a>        test_labels.append(class_idx)</span>
<span id="cb26-845"><a href="#cb26-845" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-846"><a href="#cb26-846" aria-hidden="true" tabindex="-1"></a>test_features <span class="op">=</span> torch.stack(test_features)</span>
<span id="cb26-847"><a href="#cb26-847" aria-hidden="true" tabindex="-1"></a>test_labels <span class="op">=</span> torch.tensor(test_labels).to(device)</span>
<span id="cb26-848"><a href="#cb26-848" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-849"><a href="#cb26-849" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute distances to prototypes (cosine similarity)</span></span>
<span id="cb26-850"><a href="#cb26-850" aria-hidden="true" tabindex="-1"></a>test_features_norm <span class="op">=</span> torch.nn.functional.normalize(test_features, dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb26-851"><a href="#cb26-851" aria-hidden="true" tabindex="-1"></a>support_features_norm <span class="op">=</span> torch.nn.functional.normalize(support_features, dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb26-852"><a href="#cb26-852" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-853"><a href="#cb26-853" aria-hidden="true" tabindex="-1"></a>similarities <span class="op">=</span> torch.mm(test_features_norm, support_features_norm.t())  <span class="co"># (test, classes)</span></span>
<span id="cb26-854"><a href="#cb26-854" aria-hidden="true" tabindex="-1"></a>proto_predictions <span class="op">=</span> similarities.argmax(dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb26-855"><a href="#cb26-855" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-856"><a href="#cb26-856" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate accuracy</span></span>
<span id="cb26-857"><a href="#cb26-857" aria-hidden="true" tabindex="-1"></a>proto_correct <span class="op">=</span> proto_predictions.eq(test_labels).<span class="bu">sum</span>().item()</span>
<span id="cb26-858"><a href="#cb26-858" aria-hidden="true" tabindex="-1"></a>proto_accuracy <span class="op">=</span> proto_correct <span class="op">/</span> <span class="bu">len</span>(test_labels)</span>
<span id="cb26-859"><a href="#cb26-859" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-860"><a href="#cb26-860" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Prototype Network Results (</span><span class="sc">{</span>k_shot<span class="sc">}</span><span class="ss">-shot)"</span>)</span>
<span id="cb26-861"><a href="#cb26-861" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="st">"="</span> <span class="op">*</span> <span class="dv">60</span>)</span>
<span id="cb26-862"><a href="#cb26-862" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Accuracy: </span><span class="sc">{</span>proto_accuracy<span class="sc">:.4f}</span><span class="ss"> (</span><span class="sc">{</span>proto_accuracy<span class="op">*</span><span class="dv">100</span><span class="sc">:.2f}</span><span class="ss">%)"</span>)</span>
<span id="cb26-863"><a href="#cb26-863" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Zero-shot (Step 6): </span><span class="sc">{</span>zero_shot_accuracy<span class="sc">:.4f}</span><span class="ss"> (</span><span class="sc">{</span>zero_shot_accuracy<span class="op">*</span><span class="dv">100</span><span class="sc">:.2f}</span><span class="ss">%)"</span>)</span>
<span id="cb26-864"><a href="#cb26-864" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Random Baseline: </span><span class="sc">{</span><span class="fl">1.0</span><span class="op">/</span><span class="bu">len</span>(train_dataset.classes)<span class="sc">:.4f}</span><span class="ss"> (</span><span class="sc">{</span><span class="fl">100.0</span><span class="op">/</span><span class="bu">len</span>(train_dataset.classes)<span class="sc">:.2f}</span><span class="ss">%)"</span>)</span>
<span id="cb26-865"><a href="#cb26-865" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Correct: </span><span class="sc">{</span>proto_correct<span class="sc">}</span><span class="ss">/</span><span class="sc">{</span><span class="bu">len</span>(test_labels)<span class="sc">}</span><span class="ss"> samples"</span>)</span>
<span id="cb26-866"><a href="#cb26-866" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="st">""</span>)</span>
<span id="cb26-867"><a href="#cb26-867" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="st">"Per-Class Prototype Results:"</span>)</span>
<span id="cb26-868"><a href="#cb26-868" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="st">"-"</span> <span class="op">*</span> <span class="dv">60</span>)</span>
<span id="cb26-869"><a href="#cb26-869" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-870"><a href="#cb26-870" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> idx <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(test_labels)):</span>
<span id="cb26-871"><a href="#cb26-871" aria-hidden="true" tabindex="-1"></a>    true_label <span class="op">=</span> test_labels[idx].item()</span>
<span id="cb26-872"><a href="#cb26-872" aria-hidden="true" tabindex="-1"></a>    pred_label <span class="op">=</span> proto_predictions[idx].item()</span>
<span id="cb26-873"><a href="#cb26-873" aria-hidden="true" tabindex="-1"></a>    class_name <span class="op">=</span> train_dataset.classes[true_label]</span>
<span id="cb26-874"><a href="#cb26-874" aria-hidden="true" tabindex="-1"></a>    pred_name <span class="op">=</span> train_dataset.classes[pred_label]</span>
<span id="cb26-875"><a href="#cb26-875" aria-hidden="true" tabindex="-1"></a>    correct_mark <span class="op">=</span> <span class="st">"âœ“"</span> <span class="cf">if</span> true_label <span class="op">==</span> pred_label <span class="cf">else</span> <span class="st">"âœ—"</span></span>
<span id="cb26-876"><a href="#cb26-876" aria-hidden="true" tabindex="-1"></a>    logger.info(<span class="ss">f"  </span><span class="sc">{</span>correct_mark<span class="sc">}</span><span class="ss"> </span><span class="sc">{</span>class_name<span class="sc">:20s}</span><span class="ss"> â†’ </span><span class="sc">{</span>pred_name<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb26-877"><a href="#cb26-877" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-878"><a href="#cb26-878" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-879"><a href="#cb26-879" aria-hidden="true" tabindex="-1"></a>:::{.callout-note}</span>
<span id="cb26-880"><a href="#cb26-880" aria-hidden="true" tabindex="-1"></a><span class="fu">## Understanding Prototype Networks</span></span>
<span id="cb26-881"><a href="#cb26-881" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-882"><a href="#cb26-882" aria-hidden="true" tabindex="-1"></a>**How it works:**</span>
<span id="cb26-883"><a href="#cb26-883" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-884"><a href="#cb26-884" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Pass K examples per class through the model to get output representations (logits)</span>
<span id="cb26-885"><a href="#cb26-885" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Compute prototype (mean logits) for each class</span>
<span id="cb26-886"><a href="#cb26-886" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Classify new samples by finding nearest prototype using cosine similarity</span>
<span id="cb26-887"><a href="#cb26-887" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-888"><a href="#cb26-888" aria-hidden="true" tabindex="-1"></a>**Why it's better than zero-shot:**</span>
<span id="cb26-889"><a href="#cb26-889" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-890"><a href="#cb26-890" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Uses a few labeled examples to establish class centroids in output space</span>
<span id="cb26-891"><a href="#cb26-891" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>No training required - just forward passes and averaging</span>
<span id="cb26-892"><a href="#cb26-892" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Expected performance: 30-50% (vs 11% zero-shot)</span>
<span id="cb26-893"><a href="#cb26-893" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-894"><a href="#cb26-894" aria-hidden="true" tabindex="-1"></a>**Key insight**: Even with a randomly initialized decoder, the output space has enough structure from the Prithvi backbone that averaging a few examples per class creates meaningful prototypes.</span>
<span id="cb26-895"><a href="#cb26-895" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb26-896"><a href="#cb26-896" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-897"><a href="#cb26-897" aria-hidden="true" tabindex="-1"></a><span class="fu">### Step 6b: Linear Probing - Fast Adaptation</span></span>
<span id="cb26-898"><a href="#cb26-898" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-899"><a href="#cb26-899" aria-hidden="true" tabindex="-1"></a>Linear probing freezes the backbone and trains only the decoder head with few examples. This is much faster than full fine-tuning.</span>
<span id="cb26-900"><a href="#cb26-900" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-903"><a href="#cb26-903" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-904"><a href="#cb26-904" aria-hidden="true" tabindex="-1"></a><span class="co"># Create fresh model for linear probing</span></span>
<span id="cb26-905"><a href="#cb26-905" aria-hidden="true" tabindex="-1"></a>linear_probe_model <span class="op">=</span> model_factory.build_model(</span>
<span id="cb26-906"><a href="#cb26-906" aria-hidden="true" tabindex="-1"></a>    task<span class="op">=</span><span class="st">"classification"</span>,</span>
<span id="cb26-907"><a href="#cb26-907" aria-hidden="true" tabindex="-1"></a>    backbone<span class="op">=</span><span class="st">"prithvi_eo_v1_100"</span>,</span>
<span id="cb26-908"><a href="#cb26-908" aria-hidden="true" tabindex="-1"></a>    decoder<span class="op">=</span><span class="st">"FCNDecoder"</span>,</span>
<span id="cb26-909"><a href="#cb26-909" aria-hidden="true" tabindex="-1"></a>    num_classes<span class="op">=</span>num_classes</span>
<span id="cb26-910"><a href="#cb26-910" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb26-911"><a href="#cb26-911" aria-hidden="true" tabindex="-1"></a>linear_probe_model <span class="op">=</span> linear_probe_model.to(device)</span>
<span id="cb26-912"><a href="#cb26-912" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-913"><a href="#cb26-913" aria-hidden="true" tabindex="-1"></a><span class="co"># Freeze backbone completely</span></span>
<span id="cb26-914"><a href="#cb26-914" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="st">"Freezing Prithvi backbone..."</span>)</span>
<span id="cb26-915"><a href="#cb26-915" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> name, param <span class="kw">in</span> linear_probe_model.named_parameters():</span>
<span id="cb26-916"><a href="#cb26-916" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="st">'encoder'</span> <span class="kw">in</span> name <span class="kw">or</span> <span class="st">'backbone'</span> <span class="kw">in</span> name <span class="kw">or</span> <span class="st">'model.model'</span> <span class="kw">in</span> name:</span>
<span id="cb26-917"><a href="#cb26-917" aria-hidden="true" tabindex="-1"></a>        param.requires_grad <span class="op">=</span> <span class="va">False</span></span>
<span id="cb26-918"><a href="#cb26-918" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-919"><a href="#cb26-919" aria-hidden="true" tabindex="-1"></a>trainable <span class="op">=</span> <span class="bu">sum</span>(p.numel() <span class="cf">for</span> p <span class="kw">in</span> linear_probe_model.parameters() <span class="cf">if</span> p.requires_grad)</span>
<span id="cb26-920"><a href="#cb26-920" aria-hidden="true" tabindex="-1"></a>total <span class="op">=</span> <span class="bu">sum</span>(p.numel() <span class="cf">for</span> p <span class="kw">in</span> linear_probe_model.parameters())</span>
<span id="cb26-921"><a href="#cb26-921" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Trainable parameters: </span><span class="sc">{</span>trainable<span class="sc">:,}</span><span class="ss"> / </span><span class="sc">{</span>total<span class="sc">:,}</span><span class="ss"> (</span><span class="sc">{</span><span class="dv">100</span><span class="op">*</span>trainable<span class="op">/</span>total<span class="sc">:.1f}</span><span class="ss">%)"</span>)</span>
<span id="cb26-922"><a href="#cb26-922" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="st">""</span>)</span>
<span id="cb26-923"><a href="#cb26-923" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-924"><a href="#cb26-924" aria-hidden="true" tabindex="-1"></a><span class="co"># Try different k-shot settings</span></span>
<span id="cb26-925"><a href="#cb26-925" aria-hidden="true" tabindex="-1"></a>k_shots <span class="op">=</span> [<span class="dv">1</span>, <span class="dv">5</span>, <span class="dv">10</span>]</span>
<span id="cb26-926"><a href="#cb26-926" aria-hidden="true" tabindex="-1"></a>linear_probe_results <span class="op">=</span> {}</span>
<span id="cb26-927"><a href="#cb26-927" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-928"><a href="#cb26-928" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k <span class="kw">in</span> k_shots:</span>
<span id="cb26-929"><a href="#cb26-929" aria-hidden="true" tabindex="-1"></a>    logger.info(<span class="ss">f"Linear Probing: </span><span class="sc">{</span>k<span class="sc">}</span><span class="ss">-shot"</span>)</span>
<span id="cb26-930"><a href="#cb26-930" aria-hidden="true" tabindex="-1"></a>    logger.info(<span class="st">"="</span> <span class="op">*</span> <span class="dv">60</span>)</span>
<span id="cb26-931"><a href="#cb26-931" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-932"><a href="#cb26-932" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create k-shot dataset</span></span>
<span id="cb26-933"><a href="#cb26-933" aria-hidden="true" tabindex="-1"></a>    few_shot_subset, _ <span class="op">=</span> create_few_shot_dataset(train_dataset, k_shot<span class="op">=</span>k)</span>
<span id="cb26-934"><a href="#cb26-934" aria-hidden="true" tabindex="-1"></a>    few_shot_transformed <span class="op">=</span> TransformedDataset(few_shot_subset, transform)</span>
<span id="cb26-935"><a href="#cb26-935" aria-hidden="true" tabindex="-1"></a>    few_shot_loader <span class="op">=</span> DataLoader(few_shot_transformed, batch_size<span class="op">=</span><span class="bu">min</span>(<span class="dv">32</span>, <span class="bu">len</span>(few_shot_transformed)), shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb26-936"><a href="#cb26-936" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-937"><a href="#cb26-937" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Reset decoder weights</span></span>
<span id="cb26-938"><a href="#cb26-938" aria-hidden="true" tabindex="-1"></a>    linear_probe_model <span class="op">=</span> model_factory.build_model(</span>
<span id="cb26-939"><a href="#cb26-939" aria-hidden="true" tabindex="-1"></a>        task<span class="op">=</span><span class="st">"classification"</span>,</span>
<span id="cb26-940"><a href="#cb26-940" aria-hidden="true" tabindex="-1"></a>        backbone<span class="op">=</span><span class="st">"prithvi_eo_v1_100"</span>,</span>
<span id="cb26-941"><a href="#cb26-941" aria-hidden="true" tabindex="-1"></a>        decoder<span class="op">=</span><span class="st">"FCNDecoder"</span>,</span>
<span id="cb26-942"><a href="#cb26-942" aria-hidden="true" tabindex="-1"></a>        num_classes<span class="op">=</span>num_classes</span>
<span id="cb26-943"><a href="#cb26-943" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb26-944"><a href="#cb26-944" aria-hidden="true" tabindex="-1"></a>    linear_probe_model <span class="op">=</span> linear_probe_model.to(device)</span>
<span id="cb26-945"><a href="#cb26-945" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-946"><a href="#cb26-946" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Freeze backbone</span></span>
<span id="cb26-947"><a href="#cb26-947" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> name, param <span class="kw">in</span> linear_probe_model.named_parameters():</span>
<span id="cb26-948"><a href="#cb26-948" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="st">'encoder'</span> <span class="kw">in</span> name <span class="kw">or</span> <span class="st">'backbone'</span> <span class="kw">in</span> name <span class="kw">or</span> <span class="st">'model.model'</span> <span class="kw">in</span> name:</span>
<span id="cb26-949"><a href="#cb26-949" aria-hidden="true" tabindex="-1"></a>            param.requires_grad <span class="op">=</span> <span class="va">False</span></span>
<span id="cb26-950"><a href="#cb26-950" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-951"><a href="#cb26-951" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Train decoder only</span></span>
<span id="cb26-952"><a href="#cb26-952" aria-hidden="true" tabindex="-1"></a>    probe_optimizer <span class="op">=</span> torch.optim.Adam(</span>
<span id="cb26-953"><a href="#cb26-953" aria-hidden="true" tabindex="-1"></a>        [p <span class="cf">for</span> p <span class="kw">in</span> linear_probe_model.parameters() <span class="cf">if</span> p.requires_grad],</span>
<span id="cb26-954"><a href="#cb26-954" aria-hidden="true" tabindex="-1"></a>        lr<span class="op">=</span><span class="fl">1e-3</span>  <span class="co"># Higher LR since only training head</span></span>
<span id="cb26-955"><a href="#cb26-955" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb26-956"><a href="#cb26-956" aria-hidden="true" tabindex="-1"></a>    probe_criterion <span class="op">=</span> nn.CrossEntropyLoss()</span>
<span id="cb26-957"><a href="#cb26-957" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-958"><a href="#cb26-958" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Train for more epochs on small dataset</span></span>
<span id="cb26-959"><a href="#cb26-959" aria-hidden="true" tabindex="-1"></a>    epochs <span class="op">=</span> <span class="dv">50</span></span>
<span id="cb26-960"><a href="#cb26-960" aria-hidden="true" tabindex="-1"></a>    linear_probe_model.train()</span>
<span id="cb26-961"><a href="#cb26-961" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-962"><a href="#cb26-962" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb26-963"><a href="#cb26-963" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> images, labels <span class="kw">in</span> few_shot_loader:</span>
<span id="cb26-964"><a href="#cb26-964" aria-hidden="true" tabindex="-1"></a>            images <span class="op">=</span> images.to(device)</span>
<span id="cb26-965"><a href="#cb26-965" aria-hidden="true" tabindex="-1"></a>            labels <span class="op">=</span> labels.to(device)</span>
<span id="cb26-966"><a href="#cb26-966" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-967"><a href="#cb26-967" aria-hidden="true" tabindex="-1"></a>            probe_optimizer.zero_grad()</span>
<span id="cb26-968"><a href="#cb26-968" aria-hidden="true" tabindex="-1"></a>            outputs <span class="op">=</span> linear_probe_model(images)</span>
<span id="cb26-969"><a href="#cb26-969" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="bu">hasattr</span>(outputs, <span class="st">'output'</span>):</span>
<span id="cb26-970"><a href="#cb26-970" aria-hidden="true" tabindex="-1"></a>                outputs <span class="op">=</span> outputs.output</span>
<span id="cb26-971"><a href="#cb26-971" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-972"><a href="#cb26-972" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> probe_criterion(outputs, labels)</span>
<span id="cb26-973"><a href="#cb26-973" aria-hidden="true" tabindex="-1"></a>            loss.backward()</span>
<span id="cb26-974"><a href="#cb26-974" aria-hidden="true" tabindex="-1"></a>            probe_optimizer.step()</span>
<span id="cb26-975"><a href="#cb26-975" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-976"><a href="#cb26-976" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Evaluate on same test samples</span></span>
<span id="cb26-977"><a href="#cb26-977" aria-hidden="true" tabindex="-1"></a>    linear_probe_model.<span class="bu">eval</span>()</span>
<span id="cb26-978"><a href="#cb26-978" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb26-979"><a href="#cb26-979" aria-hidden="true" tabindex="-1"></a>        outputs <span class="op">=</span> linear_probe_model(zero_shot_images)</span>
<span id="cb26-980"><a href="#cb26-980" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">hasattr</span>(outputs, <span class="st">'output'</span>):</span>
<span id="cb26-981"><a href="#cb26-981" aria-hidden="true" tabindex="-1"></a>            outputs <span class="op">=</span> outputs.output</span>
<span id="cb26-982"><a href="#cb26-982" aria-hidden="true" tabindex="-1"></a>        _, linear_predictions <span class="op">=</span> outputs.<span class="bu">max</span>(<span class="dv">1</span>)</span>
<span id="cb26-983"><a href="#cb26-983" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-984"><a href="#cb26-984" aria-hidden="true" tabindex="-1"></a>    linear_correct <span class="op">=</span> linear_predictions.eq(zero_shot_labels).<span class="bu">sum</span>().item()</span>
<span id="cb26-985"><a href="#cb26-985" aria-hidden="true" tabindex="-1"></a>    linear_accuracy <span class="op">=</span> linear_correct <span class="op">/</span> <span class="bu">len</span>(zero_shot_labels)</span>
<span id="cb26-986"><a href="#cb26-986" aria-hidden="true" tabindex="-1"></a>    linear_probe_results[k] <span class="op">=</span> linear_accuracy</span>
<span id="cb26-987"><a href="#cb26-987" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-988"><a href="#cb26-988" aria-hidden="true" tabindex="-1"></a>    logger.info(<span class="ss">f"</span><span class="sc">{</span>k<span class="sc">}</span><span class="ss">-shot Accuracy: </span><span class="sc">{</span>linear_accuracy<span class="sc">:.4f}</span><span class="ss"> (</span><span class="sc">{</span>linear_accuracy<span class="op">*</span><span class="dv">100</span><span class="sc">:.2f}</span><span class="ss">%)"</span>)</span>
<span id="cb26-989"><a href="#cb26-989" aria-hidden="true" tabindex="-1"></a>    logger.info(<span class="ss">f"Correct: </span><span class="sc">{</span>linear_correct<span class="sc">}</span><span class="ss">/</span><span class="sc">{</span><span class="bu">len</span>(zero_shot_labels)<span class="sc">}</span><span class="ss"> samples"</span>)</span>
<span id="cb26-990"><a href="#cb26-990" aria-hidden="true" tabindex="-1"></a>    logger.info(<span class="st">""</span>)</span>
<span id="cb26-991"><a href="#cb26-991" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-992"><a href="#cb26-992" aria-hidden="true" tabindex="-1"></a><span class="co"># Summary comparison</span></span>
<span id="cb26-993"><a href="#cb26-993" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="st">"Data Efficiency Comparison"</span>)</span>
<span id="cb26-994"><a href="#cb26-994" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="st">"="</span> <span class="op">*</span> <span class="dv">60</span>)</span>
<span id="cb26-995"><a href="#cb26-995" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Zero-shot (0 examples):     </span><span class="sc">{</span>zero_shot_accuracy<span class="sc">:.4f}</span><span class="ss"> (</span><span class="sc">{</span>zero_shot_accuracy<span class="op">*</span><span class="dv">100</span><span class="sc">:.2f}</span><span class="ss">%)"</span>)</span>
<span id="cb26-996"><a href="#cb26-996" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Prototypes (</span><span class="sc">{</span>k_shot<span class="sc">}</span><span class="ss">-shot): </span><span class="sc">{</span>proto_accuracy<span class="sc">:.4f}</span><span class="ss"> (</span><span class="sc">{</span>proto_accuracy<span class="op">*</span><span class="dv">100</span><span class="sc">:.2f}</span><span class="ss">%)"</span>)</span>
<span id="cb26-997"><a href="#cb26-997" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k, acc <span class="kw">in</span> linear_probe_results.items():</span>
<span id="cb26-998"><a href="#cb26-998" aria-hidden="true" tabindex="-1"></a>    logger.info(<span class="ss">f"Linear Probe (</span><span class="sc">{</span>k<span class="sc">}</span><span class="ss">-shot):    </span><span class="sc">{</span>acc<span class="sc">:.4f}</span><span class="ss"> (</span><span class="sc">{</span>acc<span class="op">*</span><span class="dv">100</span><span class="sc">:.2f}</span><span class="ss">%)"</span>)</span>
<span id="cb26-999"><a href="#cb26-999" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Random Baseline:            </span><span class="sc">{</span><span class="fl">1.0</span><span class="op">/</span><span class="bu">len</span>(train_dataset.classes)<span class="sc">:.4f}</span><span class="ss"> (</span><span class="sc">{</span><span class="fl">100.0</span><span class="op">/</span><span class="bu">len</span>(train_dataset.classes)<span class="sc">:.2f}</span><span class="ss">%)"</span>)</span>
<span id="cb26-1000"><a href="#cb26-1000" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-1001"><a href="#cb26-1001" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1002"><a href="#cb26-1002" aria-hidden="true" tabindex="-1"></a>:::{.callout-note}</span>
<span id="cb26-1003"><a href="#cb26-1003" aria-hidden="true" tabindex="-1"></a><span class="fu">## Understanding Linear Probing</span></span>
<span id="cb26-1004"><a href="#cb26-1004" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1005"><a href="#cb26-1005" aria-hidden="true" tabindex="-1"></a>**How it works:**</span>
<span id="cb26-1006"><a href="#cb26-1006" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1007"><a href="#cb26-1007" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Freeze pretrained backbone (no updates to 100M parameters)</span>
<span id="cb26-1008"><a href="#cb26-1008" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Train only decoder head (~10K parameters)</span>
<span id="cb26-1009"><a href="#cb26-1009" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Use few examples per class</span>
<span id="cb26-1010"><a href="#cb26-1010" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1011"><a href="#cb26-1011" aria-hidden="true" tabindex="-1"></a>**Why it's efficient:**</span>
<span id="cb26-1012"><a href="#cb26-1012" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1013"><a href="#cb26-1013" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Much faster than full fine-tuning (seconds vs minutes)</span>
<span id="cb26-1014"><a href="#cb26-1014" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Less prone to overfitting with few examples</span>
<span id="cb26-1015"><a href="#cb26-1015" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Expected performance: 1-shot (30%), 5-shot (60%), 10-shot (75%)</span>
<span id="cb26-1016"><a href="#cb26-1016" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1017"><a href="#cb26-1017" aria-hidden="true" tabindex="-1"></a>**Key insight**: Foundation model features are so good that you can achieve strong performance by just learning a simple mapping (linear layer) from features to classes.</span>
<span id="cb26-1018"><a href="#cb26-1018" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb26-1019"><a href="#cb26-1019" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1020"><a href="#cb26-1020" aria-hidden="true" tabindex="-1"></a><span class="fu">## Part 5: Full Fine-Tuning - Maximum Performance</span></span>
<span id="cb26-1021"><a href="#cb26-1021" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1022"><a href="#cb26-1022" aria-hidden="true" tabindex="-1"></a>Now we'll (briefly!) train the model and compare performance to the zero-shot baseline.</span>
<span id="cb26-1023"><a href="#cb26-1023" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1024"><a href="#cb26-1024" aria-hidden="true" tabindex="-1"></a><span class="fu">### Step 8: Define Loss Function</span></span>
<span id="cb26-1025"><a href="#cb26-1025" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1026"><a href="#cb26-1026" aria-hidden="true" tabindex="-1"></a>The loss function is used to train the model. It is a measure of how good the model is at predicting the correct class. We use the <span class="in">`CrossEntropyLoss`</span> loss function for classification tasks.</span>
<span id="cb26-1027"><a href="#cb26-1027" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1030"><a href="#cb26-1030" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-1031"><a href="#cb26-1031" aria-hidden="true" tabindex="-1"></a><span class="co">#| tangle: geogfm/training/simple_trainer.py</span></span>
<span id="cb26-1032"><a href="#cb26-1032" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1033"><a href="#cb26-1033" aria-hidden="true" tabindex="-1"></a>criterion <span class="op">=</span> nn.CrossEntropyLoss()</span>
<span id="cb26-1034"><a href="#cb26-1034" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-1035"><a href="#cb26-1035" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1036"><a href="#cb26-1036" aria-hidden="true" tabindex="-1"></a><span class="fu">### Step 7: Define Optimizer</span></span>
<span id="cb26-1037"><a href="#cb26-1037" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1038"><a href="#cb26-1038" aria-hidden="true" tabindex="-1"></a>The optimizer is used to update the model's parameters. We use the <span class="in">`Adam`</span> optimizer for classification tasks. It is a <span class="co">[</span><span class="ot">stochastic gradient descent</span><span class="co">](https://en.wikipedia.org/wiki/Stochastic_gradient_descent)</span> optimizer that is a popular optimizer for deep learning.</span>
<span id="cb26-1039"><a href="#cb26-1039" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1042"><a href="#cb26-1042" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-1043"><a href="#cb26-1043" aria-hidden="true" tabindex="-1"></a><span class="co">#| tangle: geogfm/training/simple_trainer.py</span></span>
<span id="cb26-1044"><a href="#cb26-1044" aria-hidden="true" tabindex="-1"></a><span class="co">#| mode: append</span></span>
<span id="cb26-1045"><a href="#cb26-1045" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1046"><a href="#cb26-1046" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> torch.optim.Adam(model.parameters(), lr<span class="op">=</span><span class="fl">1e-4</span>)</span>
<span id="cb26-1047"><a href="#cb26-1047" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-1048"><a href="#cb26-1048" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1049"><a href="#cb26-1049" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1050"><a href="#cb26-1050" aria-hidden="true" tabindex="-1"></a><span class="fu">### Step 6: Define Training Loop</span></span>
<span id="cb26-1051"><a href="#cb26-1051" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1052"><a href="#cb26-1052" aria-hidden="true" tabindex="-1"></a>Let's break down what happens during training and validation of a deep learning model:</span>
<span id="cb26-1053"><a href="#cb26-1053" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1054"><a href="#cb26-1054" aria-hidden="true" tabindex="-1"></a>**Training Loop: Step-by-Step**</span>
<span id="cb26-1055"><a href="#cb26-1055" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1056"><a href="#cb26-1056" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**Set model to training mode**: This enables layers like dropout and batch normalization to behave appropriately during training.</span>
<span id="cb26-1057"><a href="#cb26-1057" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**Iterate over training batches**: For each batch in the training data:</span>
<span id="cb26-1058"><a href="#cb26-1058" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>**Move data to the device** (CPU or GPU).</span>
<span id="cb26-1059"><a href="#cb26-1059" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>**Zero (reset) the gradients** from the previous step.</span>
<span id="cb26-1060"><a href="#cb26-1060" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>**Forward pass**: Input images are passed through the model to produce predictions.</span>
<span id="cb26-1061"><a href="#cb26-1061" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>**Compute the loss**: The loss function compares predictions to ground-truth labels.</span>
<span id="cb26-1062"><a href="#cb26-1062" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>**Backward pass**: Compute gradients of the loss with respect to each parameter.</span>
<span id="cb26-1063"><a href="#cb26-1063" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>**Optimizer step**: Update parameters by taking a step in the direction that reduces the loss.</span>
<span id="cb26-1064"><a href="#cb26-1064" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>**Track statistics**: Optionally record loss and accuracy for reporting.</span>
<span id="cb26-1065"><a href="#cb26-1065" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1066"><a href="#cb26-1066" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1069"><a href="#cb26-1069" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-1070"><a href="#cb26-1070" aria-hidden="true" tabindex="-1"></a><span class="co">#| tangle: geogfm/training/simple_trainer.py</span></span>
<span id="cb26-1071"><a href="#cb26-1071" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb26-1072"><a href="#cb26-1072" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb26-1073"><a href="#cb26-1073" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1074"><a href="#cb26-1074" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_one_epoch(model, train_loader, criterion, optimizer, device):</span>
<span id="cb26-1075"><a href="#cb26-1075" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb26-1076"><a href="#cb26-1076" aria-hidden="true" tabindex="-1"></a><span class="co">    Train for one epoch.</span></span>
<span id="cb26-1077"><a href="#cb26-1077" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1078"><a href="#cb26-1078" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters</span></span>
<span id="cb26-1079"><a href="#cb26-1079" aria-hidden="true" tabindex="-1"></a><span class="co">    ----------</span></span>
<span id="cb26-1080"><a href="#cb26-1080" aria-hidden="true" tabindex="-1"></a><span class="co">    model : nn.Module</span></span>
<span id="cb26-1081"><a href="#cb26-1081" aria-hidden="true" tabindex="-1"></a><span class="co">        The model to train</span></span>
<span id="cb26-1082"><a href="#cb26-1082" aria-hidden="true" tabindex="-1"></a><span class="co">    train_loader : DataLoader</span></span>
<span id="cb26-1083"><a href="#cb26-1083" aria-hidden="true" tabindex="-1"></a><span class="co">        Training data loader</span></span>
<span id="cb26-1084"><a href="#cb26-1084" aria-hidden="true" tabindex="-1"></a><span class="co">    criterion : nn.Module</span></span>
<span id="cb26-1085"><a href="#cb26-1085" aria-hidden="true" tabindex="-1"></a><span class="co">        Loss function</span></span>
<span id="cb26-1086"><a href="#cb26-1086" aria-hidden="true" tabindex="-1"></a><span class="co">    optimizer : torch.optim.Optimizer</span></span>
<span id="cb26-1087"><a href="#cb26-1087" aria-hidden="true" tabindex="-1"></a><span class="co">        Optimizer for parameter updates</span></span>
<span id="cb26-1088"><a href="#cb26-1088" aria-hidden="true" tabindex="-1"></a><span class="co">    device : torch.device</span></span>
<span id="cb26-1089"><a href="#cb26-1089" aria-hidden="true" tabindex="-1"></a><span class="co">        Device to run on</span></span>
<span id="cb26-1090"><a href="#cb26-1090" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1091"><a href="#cb26-1091" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns</span></span>
<span id="cb26-1092"><a href="#cb26-1092" aria-hidden="true" tabindex="-1"></a><span class="co">    -------</span></span>
<span id="cb26-1093"><a href="#cb26-1093" aria-hidden="true" tabindex="-1"></a><span class="co">    tuple</span></span>
<span id="cb26-1094"><a href="#cb26-1094" aria-hidden="true" tabindex="-1"></a><span class="co">        (average_loss, accuracy)</span></span>
<span id="cb26-1095"><a href="#cb26-1095" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb26-1096"><a href="#cb26-1096" aria-hidden="true" tabindex="-1"></a>    model.train() <span class="co"># Set model to training mode</span></span>
<span id="cb26-1097"><a href="#cb26-1097" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1098"><a href="#cb26-1098" aria-hidden="true" tabindex="-1"></a>    running_loss <span class="op">=</span> <span class="fl">0.0</span> <span class="co"># Running loss</span></span>
<span id="cb26-1099"><a href="#cb26-1099" aria-hidden="true" tabindex="-1"></a>    correct <span class="op">=</span> <span class="dv">0</span> <span class="co"># Correct predictions</span></span>
<span id="cb26-1100"><a href="#cb26-1100" aria-hidden="true" tabindex="-1"></a>    total <span class="op">=</span> <span class="dv">0</span> <span class="co"># Total predictions</span></span>
<span id="cb26-1101"><a href="#cb26-1101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1102"><a href="#cb26-1102" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> images, labels <span class="kw">in</span> train_loader:</span>
<span id="cb26-1103"><a href="#cb26-1103" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Move data to device</span></span>
<span id="cb26-1104"><a href="#cb26-1104" aria-hidden="true" tabindex="-1"></a>        images <span class="op">=</span> images.to(device) <span class="co"># Move data to device</span></span>
<span id="cb26-1105"><a href="#cb26-1105" aria-hidden="true" tabindex="-1"></a>        labels <span class="op">=</span> labels.to(device) <span class="co"># Move data to device</span></span>
<span id="cb26-1106"><a href="#cb26-1106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1107"><a href="#cb26-1107" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Zero gradients</span></span>
<span id="cb26-1108"><a href="#cb26-1108" aria-hidden="true" tabindex="-1"></a>        optimizer.zero_grad()</span>
<span id="cb26-1109"><a href="#cb26-1109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1110"><a href="#cb26-1110" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Forward pass</span></span>
<span id="cb26-1111"><a href="#cb26-1111" aria-hidden="true" tabindex="-1"></a>        outputs <span class="op">=</span> model(images)</span>
<span id="cb26-1112"><a href="#cb26-1112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1113"><a href="#cb26-1113" aria-hidden="true" tabindex="-1"></a>        <span class="co"># TerraTorch models return ModelOutput object</span></span>
<span id="cb26-1114"><a href="#cb26-1114" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Extract the tensor</span></span>
<span id="cb26-1115"><a href="#cb26-1115" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">hasattr</span>(outputs, <span class="st">'output'</span>):</span>
<span id="cb26-1116"><a href="#cb26-1116" aria-hidden="true" tabindex="-1"></a>            outputs <span class="op">=</span> outputs.output <span class="co"># Extract tensor from ModelOutput</span></span>
<span id="cb26-1117"><a href="#cb26-1117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1118"><a href="#cb26-1118" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Compute loss</span></span>
<span id="cb26-1119"><a href="#cb26-1119" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> criterion(outputs, labels) </span>
<span id="cb26-1120"><a href="#cb26-1120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1121"><a href="#cb26-1121" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Backward pass</span></span>
<span id="cb26-1122"><a href="#cb26-1122" aria-hidden="true" tabindex="-1"></a>        loss.backward()</span>
<span id="cb26-1123"><a href="#cb26-1123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1124"><a href="#cb26-1124" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Update parameters</span></span>
<span id="cb26-1125"><a href="#cb26-1125" aria-hidden="true" tabindex="-1"></a>        optimizer.step()</span>
<span id="cb26-1126"><a href="#cb26-1126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1127"><a href="#cb26-1127" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Track metrics</span></span>
<span id="cb26-1128"><a href="#cb26-1128" aria-hidden="true" tabindex="-1"></a>        running_loss <span class="op">+=</span> loss.item() <span class="co"># Add loss to running loss</span></span>
<span id="cb26-1129"><a href="#cb26-1129" aria-hidden="true" tabindex="-1"></a>        _, predicted <span class="op">=</span> outputs.<span class="bu">max</span>(<span class="dv">1</span>) <span class="co"># Get predicted class</span></span>
<span id="cb26-1130"><a href="#cb26-1130" aria-hidden="true" tabindex="-1"></a>        total <span class="op">+=</span> labels.size(<span class="dv">0</span>) <span class="co"># Add number of labels to total</span></span>
<span id="cb26-1131"><a href="#cb26-1131" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Add number of correct predictions to total</span></span>
<span id="cb26-1132"><a href="#cb26-1132" aria-hidden="true" tabindex="-1"></a>        correct <span class="op">+=</span> predicted.eq(labels).<span class="bu">sum</span>().item()</span>
<span id="cb26-1133"><a href="#cb26-1133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1134"><a href="#cb26-1134" aria-hidden="true" tabindex="-1"></a>    epoch_loss <span class="op">=</span> running_loss <span class="op">/</span> <span class="bu">len</span>(train_loader) <span class="co"># Calculate average loss</span></span>
<span id="cb26-1135"><a href="#cb26-1135" aria-hidden="true" tabindex="-1"></a>    epoch_acc <span class="op">=</span> correct <span class="op">/</span> total <span class="co"># Calculate average accuracy</span></span>
<span id="cb26-1136"><a href="#cb26-1136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1137"><a href="#cb26-1137" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> epoch_loss, epoch_acc</span>
<span id="cb26-1138"><a href="#cb26-1138" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-1139"><a href="#cb26-1139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1140"><a href="#cb26-1140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1141"><a href="#cb26-1141" aria-hidden="true" tabindex="-1"></a>**Validation Loop: Step-by-Step**</span>
<span id="cb26-1142"><a href="#cb26-1142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1143"><a href="#cb26-1143" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**Set model to evaluation mode**: This disables/dropouts and sets batch normalization to use running statistics.</span>
<span id="cb26-1144"><a href="#cb26-1144" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**Disable gradients**: Turn off gradient computation to reduce memory and computation cost.</span>
<span id="cb26-1145"><a href="#cb26-1145" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>**Iterate over validation batches**: For each batch in the validation data:</span>
<span id="cb26-1146"><a href="#cb26-1146" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>**Move data to the device**.</span>
<span id="cb26-1147"><a href="#cb26-1147" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>**Forward pass**: Pass images through the model to get predictions.</span>
<span id="cb26-1148"><a href="#cb26-1148" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>**Compute the loss**: Evaluate how well predictions match ground-truth labels.</span>
<span id="cb26-1149"><a href="#cb26-1149" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>**Track statistics**: Record loss and accuracy, just as in training.</span>
<span id="cb26-1150"><a href="#cb26-1150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1153"><a href="#cb26-1153" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-1154"><a href="#cb26-1154" aria-hidden="true" tabindex="-1"></a><span class="co">#| tangle: geogfm/training/simple_trainer.py</span></span>
<span id="cb26-1155"><a href="#cb26-1155" aria-hidden="true" tabindex="-1"></a><span class="co">#| mode: append</span></span>
<span id="cb26-1156"><a href="#cb26-1156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1157"><a href="#cb26-1157" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> validate(model, val_loader, criterion, device):</span>
<span id="cb26-1158"><a href="#cb26-1158" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb26-1159"><a href="#cb26-1159" aria-hidden="true" tabindex="-1"></a><span class="co">    Validate the model.</span></span>
<span id="cb26-1160"><a href="#cb26-1160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1161"><a href="#cb26-1161" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters</span></span>
<span id="cb26-1162"><a href="#cb26-1162" aria-hidden="true" tabindex="-1"></a><span class="co">    ----------</span></span>
<span id="cb26-1163"><a href="#cb26-1163" aria-hidden="true" tabindex="-1"></a><span class="co">    model : nn.Module</span></span>
<span id="cb26-1164"><a href="#cb26-1164" aria-hidden="true" tabindex="-1"></a><span class="co">        The model to validate</span></span>
<span id="cb26-1165"><a href="#cb26-1165" aria-hidden="true" tabindex="-1"></a><span class="co">    val_loader : DataLoader</span></span>
<span id="cb26-1166"><a href="#cb26-1166" aria-hidden="true" tabindex="-1"></a><span class="co">        Validation data loader</span></span>
<span id="cb26-1167"><a href="#cb26-1167" aria-hidden="true" tabindex="-1"></a><span class="co">    criterion : nn.Module</span></span>
<span id="cb26-1168"><a href="#cb26-1168" aria-hidden="true" tabindex="-1"></a><span class="co">        Loss function</span></span>
<span id="cb26-1169"><a href="#cb26-1169" aria-hidden="true" tabindex="-1"></a><span class="co">    device : torch.device</span></span>
<span id="cb26-1170"><a href="#cb26-1170" aria-hidden="true" tabindex="-1"></a><span class="co">        Device to run on</span></span>
<span id="cb26-1171"><a href="#cb26-1171" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1172"><a href="#cb26-1172" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns</span></span>
<span id="cb26-1173"><a href="#cb26-1173" aria-hidden="true" tabindex="-1"></a><span class="co">    -------</span></span>
<span id="cb26-1174"><a href="#cb26-1174" aria-hidden="true" tabindex="-1"></a><span class="co">    tuple</span></span>
<span id="cb26-1175"><a href="#cb26-1175" aria-hidden="true" tabindex="-1"></a><span class="co">        (average_loss, accuracy)</span></span>
<span id="cb26-1176"><a href="#cb26-1176" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb26-1177"><a href="#cb26-1177" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">eval</span>() <span class="co"># Set model to evaluation mode</span></span>
<span id="cb26-1178"><a href="#cb26-1178" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1179"><a href="#cb26-1179" aria-hidden="true" tabindex="-1"></a>    running_loss <span class="op">=</span> <span class="fl">0.0</span> <span class="co"># Running loss</span></span>
<span id="cb26-1180"><a href="#cb26-1180" aria-hidden="true" tabindex="-1"></a>    correct <span class="op">=</span> <span class="dv">0</span> <span class="co"># Correct predictions</span></span>
<span id="cb26-1181"><a href="#cb26-1181" aria-hidden="true" tabindex="-1"></a>    total <span class="op">=</span> <span class="dv">0</span> <span class="co"># Total predictions</span></span>
<span id="cb26-1182"><a href="#cb26-1182" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1183"><a href="#cb26-1183" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb26-1184"><a href="#cb26-1184" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> images, labels <span class="kw">in</span> val_loader:</span>
<span id="cb26-1185"><a href="#cb26-1185" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Move data to device</span></span>
<span id="cb26-1186"><a href="#cb26-1186" aria-hidden="true" tabindex="-1"></a>            images <span class="op">=</span> images.to(device) <span class="co"># Move data to device</span></span>
<span id="cb26-1187"><a href="#cb26-1187" aria-hidden="true" tabindex="-1"></a>            labels <span class="op">=</span> labels.to(device) <span class="co"># Move data to device</span></span>
<span id="cb26-1188"><a href="#cb26-1188" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1189"><a href="#cb26-1189" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Forward pass</span></span>
<span id="cb26-1190"><a href="#cb26-1190" aria-hidden="true" tabindex="-1"></a>            outputs <span class="op">=</span> model(images)</span>
<span id="cb26-1191"><a href="#cb26-1191" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1192"><a href="#cb26-1192" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Extract tensor from ModelOutput</span></span>
<span id="cb26-1193"><a href="#cb26-1193" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="bu">hasattr</span>(outputs, <span class="st">'output'</span>):</span>
<span id="cb26-1194"><a href="#cb26-1194" aria-hidden="true" tabindex="-1"></a>                outputs <span class="op">=</span> outputs.output <span class="co"># Extract tensor from ModelOutput</span></span>
<span id="cb26-1195"><a href="#cb26-1195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1196"><a href="#cb26-1196" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Compute loss</span></span>
<span id="cb26-1197"><a href="#cb26-1197" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> criterion(outputs, labels) <span class="co"># Compute loss</span></span>
<span id="cb26-1198"><a href="#cb26-1198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1199"><a href="#cb26-1199" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Track metrics</span></span>
<span id="cb26-1200"><a href="#cb26-1200" aria-hidden="true" tabindex="-1"></a>            running_loss <span class="op">+=</span> loss.item() <span class="co"># Add loss to running loss</span></span>
<span id="cb26-1201"><a href="#cb26-1201" aria-hidden="true" tabindex="-1"></a>            _, predicted <span class="op">=</span> outputs.<span class="bu">max</span>(<span class="dv">1</span>) <span class="co"># Get predicted class</span></span>
<span id="cb26-1202"><a href="#cb26-1202" aria-hidden="true" tabindex="-1"></a>            total <span class="op">+=</span> labels.size(<span class="dv">0</span>) <span class="co"># Add number of labels to total</span></span>
<span id="cb26-1203"><a href="#cb26-1203" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Add number of correct predictions to total</span></span>
<span id="cb26-1204"><a href="#cb26-1204" aria-hidden="true" tabindex="-1"></a>            correct <span class="op">+=</span> predicted.eq(labels).<span class="bu">sum</span>().item()</span>
<span id="cb26-1205"><a href="#cb26-1205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1206"><a href="#cb26-1206" aria-hidden="true" tabindex="-1"></a>    epoch_loss <span class="op">=</span> running_loss <span class="op">/</span> <span class="bu">len</span>(val_loader) <span class="co"># Calculate average loss</span></span>
<span id="cb26-1207"><a href="#cb26-1207" aria-hidden="true" tabindex="-1"></a>    epoch_acc <span class="op">=</span> correct <span class="op">/</span> total <span class="co"># Calculate average accuracy</span></span>
<span id="cb26-1208"><a href="#cb26-1208" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1209"><a href="#cb26-1209" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> epoch_loss, epoch_acc</span>
<span id="cb26-1210"><a href="#cb26-1210" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-1211"><a href="#cb26-1211" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1212"><a href="#cb26-1212" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1213"><a href="#cb26-1213" aria-hidden="true" tabindex="-1"></a>**Key Differences between Training and Validation Loops**:</span>
<span id="cb26-1214"><a href="#cb26-1214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1215"><a href="#cb26-1215" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Parameter updates**: Only the training loop updates parameters via backpropagation and optimizer steps; the validation loop does not.</span>
<span id="cb26-1216"><a href="#cb26-1216" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Model mode**: The training loop uses <span class="in">`model.train()`</span>; the validation loop uses <span class="in">`model.eval()`</span>.</span>
<span id="cb26-1217"><a href="#cb26-1217" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Gradient calculation**: Gradients are computed (and accumulated) in training, but turned off in validation (using <span class="in">`torch.no_grad()`</span>).</span>
<span id="cb26-1218"><a href="#cb26-1218" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Purpose**: Training optimizes the model's weights, while validation evaluates the model's current performance without influencing parameters.</span>
<span id="cb26-1219"><a href="#cb26-1219" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1220"><a href="#cb26-1220" aria-hidden="true" tabindex="-1"></a>By writing out these loops explicitly, we gain transparency: it's much easier to spot bugs, add logging, customize behavior, and truly understand every step of model training.</span>
<span id="cb26-1221"><a href="#cb26-1221" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1222"><a href="#cb26-1222" aria-hidden="true" tabindex="-1"></a><span class="fu">### Step 7: Develop a Training Loop the Model</span></span>
<span id="cb26-1223"><a href="#cb26-1223" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1224"><a href="#cb26-1224" aria-hidden="true" tabindex="-1"></a>Let's put it all together in the <span class="in">`train_model`</span> function. This function:</span>
<span id="cb26-1225"><a href="#cb26-1225" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1226"><a href="#cb26-1226" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Implements both the training and validation loops. </span>
<span id="cb26-1227"><a href="#cb26-1227" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Sets up the training and validation data loaders, and the optimizer. </span>
<span id="cb26-1228"><a href="#cb26-1228" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Records the training and validation loss and accuracy for each epoch. </span>
<span id="cb26-1229"><a href="#cb26-1229" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Prints the progress every 5 epochs. </span>
<span id="cb26-1230"><a href="#cb26-1230" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Returns the training history (loss and accuracy for each epoch).</span>
<span id="cb26-1231"><a href="#cb26-1231" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1234"><a href="#cb26-1234" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-1235"><a href="#cb26-1235" aria-hidden="true" tabindex="-1"></a><span class="co">#| tangle: geogfm/training/simple_trainer.py</span></span>
<span id="cb26-1236"><a href="#cb26-1236" aria-hidden="true" tabindex="-1"></a><span class="co">#| mode: append</span></span>
<span id="cb26-1237"><a href="#cb26-1237" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1238"><a href="#cb26-1238" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_model(</span>
<span id="cb26-1239"><a href="#cb26-1239" aria-hidden="true" tabindex="-1"></a>    model, <span class="co"># Model to train</span></span>
<span id="cb26-1240"><a href="#cb26-1240" aria-hidden="true" tabindex="-1"></a>    train_loader, </span>
<span id="cb26-1241"><a href="#cb26-1241" aria-hidden="true" tabindex="-1"></a>    val_loader, <span class="co"># Validation data</span></span>
<span id="cb26-1242"><a href="#cb26-1242" aria-hidden="true" tabindex="-1"></a>    device<span class="op">=</span><span class="va">None</span>, <span class="co"># Device to use for training </span></span>
<span id="cb26-1243"><a href="#cb26-1243" aria-hidden="true" tabindex="-1"></a>    epochs<span class="op">=</span><span class="dv">15</span>, <span class="co"># Number of epochs</span></span>
<span id="cb26-1244"><a href="#cb26-1244" aria-hidden="true" tabindex="-1"></a>    lr<span class="op">=</span><span class="fl">1e-4</span>, <span class="co"># Learning rate</span></span>
<span id="cb26-1245"><a href="#cb26-1245" aria-hidden="true" tabindex="-1"></a>    criterion<span class="op">=</span><span class="va">None</span>, <span class="co"># Loss function</span></span>
<span id="cb26-1246"><a href="#cb26-1246" aria-hidden="true" tabindex="-1"></a>    optimizer<span class="op">=</span><span class="va">None</span>, <span class="co"># Optimizer</span></span>
<span id="cb26-1247"><a href="#cb26-1247" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb26-1248"><a href="#cb26-1248" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb26-1249"><a href="#cb26-1249" aria-hidden="true" tabindex="-1"></a><span class="co">    Full training loop.</span></span>
<span id="cb26-1250"><a href="#cb26-1250" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1251"><a href="#cb26-1251" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters</span></span>
<span id="cb26-1252"><a href="#cb26-1252" aria-hidden="true" tabindex="-1"></a><span class="co">    ----------</span></span>
<span id="cb26-1253"><a href="#cb26-1253" aria-hidden="true" tabindex="-1"></a><span class="co">    model : nn.Module</span></span>
<span id="cb26-1254"><a href="#cb26-1254" aria-hidden="true" tabindex="-1"></a><span class="co">        Model to train</span></span>
<span id="cb26-1255"><a href="#cb26-1255" aria-hidden="true" tabindex="-1"></a><span class="co">    train_loader : DataLoader</span></span>
<span id="cb26-1256"><a href="#cb26-1256" aria-hidden="true" tabindex="-1"></a><span class="co">        Training data</span></span>
<span id="cb26-1257"><a href="#cb26-1257" aria-hidden="true" tabindex="-1"></a><span class="co">    val_loader : DataLoader</span></span>
<span id="cb26-1258"><a href="#cb26-1258" aria-hidden="true" tabindex="-1"></a><span class="co">        Validation data</span></span>
<span id="cb26-1259"><a href="#cb26-1259" aria-hidden="true" tabindex="-1"></a><span class="co">    epochs : int</span></span>
<span id="cb26-1260"><a href="#cb26-1260" aria-hidden="true" tabindex="-1"></a><span class="co">        Number of epochs, default is 15</span></span>
<span id="cb26-1261"><a href="#cb26-1261" aria-hidden="true" tabindex="-1"></a><span class="co">    lr : float</span></span>
<span id="cb26-1262"><a href="#cb26-1262" aria-hidden="true" tabindex="-1"></a><span class="co">        Learning rate, default is 1e-4</span></span>
<span id="cb26-1263"><a href="#cb26-1263" aria-hidden="true" tabindex="-1"></a><span class="co">    device : torch.device</span></span>
<span id="cb26-1264"><a href="#cb26-1264" aria-hidden="true" tabindex="-1"></a><span class="co">        Device to use</span></span>
<span id="cb26-1265"><a href="#cb26-1265" aria-hidden="true" tabindex="-1"></a><span class="co">    criterion : nn.Module</span></span>
<span id="cb26-1266"><a href="#cb26-1266" aria-hidden="true" tabindex="-1"></a><span class="co">        Loss function, default is CrossEntropyLoss</span></span>
<span id="cb26-1267"><a href="#cb26-1267" aria-hidden="true" tabindex="-1"></a><span class="co">    optimizer : torch.optim.Optimizer</span></span>
<span id="cb26-1268"><a href="#cb26-1268" aria-hidden="true" tabindex="-1"></a><span class="co">        Optimizer, default is Adam</span></span>
<span id="cb26-1269"><a href="#cb26-1269" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1270"><a href="#cb26-1270" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns</span></span>
<span id="cb26-1271"><a href="#cb26-1271" aria-hidden="true" tabindex="-1"></a><span class="co">    -------</span></span>
<span id="cb26-1272"><a href="#cb26-1272" aria-hidden="true" tabindex="-1"></a><span class="co">    dict</span></span>
<span id="cb26-1273"><a href="#cb26-1273" aria-hidden="true" tabindex="-1"></a><span class="co">        Training history with losses and accuracies</span></span>
<span id="cb26-1274"><a href="#cb26-1274" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb26-1275"><a href="#cb26-1275" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Setup training</span></span>
<span id="cb26-1276"><a href="#cb26-1276" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> criterion <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb26-1277"><a href="#cb26-1277" aria-hidden="true" tabindex="-1"></a>        logger.info(<span class="st">"Using default loss function: CrossEntropyLoss"</span>)</span>
<span id="cb26-1278"><a href="#cb26-1278" aria-hidden="true" tabindex="-1"></a>        criterion <span class="op">=</span> nn.CrossEntropyLoss()</span>
<span id="cb26-1279"><a href="#cb26-1279" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> optimizer <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb26-1280"><a href="#cb26-1280" aria-hidden="true" tabindex="-1"></a>        logger.info(<span class="st">"Using default optimizer: Adam"</span>)</span>
<span id="cb26-1281"><a href="#cb26-1281" aria-hidden="true" tabindex="-1"></a>        optimizer <span class="op">=</span> torch.optim.Adam(model.parameters(), lr<span class="op">=</span>lr)</span>
<span id="cb26-1282"><a href="#cb26-1282" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> device <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb26-1283"><a href="#cb26-1283" aria-hidden="true" tabindex="-1"></a>        logger.info(<span class="st">"Using default device: cpu"</span>)</span>
<span id="cb26-1284"><a href="#cb26-1284" aria-hidden="true" tabindex="-1"></a>        device <span class="op">=</span> <span class="st">'cpu'</span></span>
<span id="cb26-1285"><a href="#cb26-1285" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1286"><a href="#cb26-1286" aria-hidden="true" tabindex="-1"></a>    history <span class="op">=</span> {</span>
<span id="cb26-1287"><a href="#cb26-1287" aria-hidden="true" tabindex="-1"></a>        <span class="st">'train_loss'</span>: [],  <span class="co"># Training loss</span></span>
<span id="cb26-1288"><a href="#cb26-1288" aria-hidden="true" tabindex="-1"></a>        <span class="st">'train_acc'</span>: [],  <span class="co"># Training accuracy</span></span>
<span id="cb26-1289"><a href="#cb26-1289" aria-hidden="true" tabindex="-1"></a>        <span class="st">'val_loss'</span>: [],  <span class="co"># Validation loss</span></span>
<span id="cb26-1290"><a href="#cb26-1290" aria-hidden="true" tabindex="-1"></a>        <span class="st">'val_acc'</span>: []  <span class="co"># Validation accuracy</span></span>
<span id="cb26-1291"><a href="#cb26-1291" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb26-1292"><a href="#cb26-1292" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1293"><a href="#cb26-1293" aria-hidden="true" tabindex="-1"></a>    logger.info(<span class="ss">f"Training for </span><span class="sc">{</span>epochs<span class="sc">}</span><span class="ss"> epochs..."</span>)</span>
<span id="cb26-1294"><a href="#cb26-1294" aria-hidden="true" tabindex="-1"></a>    logger.info(<span class="ss">f"Device: </span><span class="sc">{</span>device<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb26-1295"><a href="#cb26-1295" aria-hidden="true" tabindex="-1"></a>    logger.info(<span class="ss">f"Learning rate: </span><span class="sc">{</span>lr<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb26-1296"><a href="#cb26-1296" aria-hidden="true" tabindex="-1"></a>    logger.info(<span class="ss">f""</span>)</span>
<span id="cb26-1297"><a href="#cb26-1297" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1298"><a href="#cb26-1298" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb26-1299"><a href="#cb26-1299" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Train</span></span>
<span id="cb26-1300"><a href="#cb26-1300" aria-hidden="true" tabindex="-1"></a>        train_loss, train_acc <span class="op">=</span> train_one_epoch(</span>
<span id="cb26-1301"><a href="#cb26-1301" aria-hidden="true" tabindex="-1"></a>            model, train_loader, criterion, optimizer, device</span>
<span id="cb26-1302"><a href="#cb26-1302" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb26-1303"><a href="#cb26-1303" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1304"><a href="#cb26-1304" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Validate</span></span>
<span id="cb26-1305"><a href="#cb26-1305" aria-hidden="true" tabindex="-1"></a>        val_loss, val_acc <span class="op">=</span> validate(</span>
<span id="cb26-1306"><a href="#cb26-1306" aria-hidden="true" tabindex="-1"></a>            model, val_loader, criterion, device</span>
<span id="cb26-1307"><a href="#cb26-1307" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb26-1308"><a href="#cb26-1308" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1309"><a href="#cb26-1309" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Record history</span></span>
<span id="cb26-1310"><a href="#cb26-1310" aria-hidden="true" tabindex="-1"></a>        history[<span class="st">'train_loss'</span>].append(train_loss)</span>
<span id="cb26-1311"><a href="#cb26-1311" aria-hidden="true" tabindex="-1"></a>        history[<span class="st">'train_acc'</span>].append(train_acc)</span>
<span id="cb26-1312"><a href="#cb26-1312" aria-hidden="true" tabindex="-1"></a>        history[<span class="st">'val_loss'</span>].append(val_loss)</span>
<span id="cb26-1313"><a href="#cb26-1313" aria-hidden="true" tabindex="-1"></a>        history[<span class="st">'val_acc'</span>].append(val_acc)</span>
<span id="cb26-1314"><a href="#cb26-1314" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1315"><a href="#cb26-1315" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Print progress every 5 epochs</span></span>
<span id="cb26-1316"><a href="#cb26-1316" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> (epoch <span class="op">+</span> <span class="dv">1</span>) <span class="op">%</span> <span class="dv">5</span> <span class="op">==</span> <span class="dv">0</span> <span class="kw">or</span> epoch <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb26-1317"><a href="#cb26-1317" aria-hidden="true" tabindex="-1"></a>            logger.info(<span class="ss">f"Epoch </span><span class="sc">{</span>epoch<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>epochs<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb26-1318"><a href="#cb26-1318" aria-hidden="true" tabindex="-1"></a>            logger.info(<span class="ss">f"  Train Loss: </span><span class="sc">{</span>train_loss<span class="sc">:.4f}</span><span class="ss">, Train Acc: </span><span class="sc">{</span>train_acc<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb26-1319"><a href="#cb26-1319" aria-hidden="true" tabindex="-1"></a>            logger.info(<span class="ss">f"  Val Loss: </span><span class="sc">{</span>val_loss<span class="sc">:.4f}</span><span class="ss">, Val Acc: </span><span class="sc">{</span>val_acc<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb26-1320"><a href="#cb26-1320" aria-hidden="true" tabindex="-1"></a>            logger.info(<span class="ss">f""</span>)</span>
<span id="cb26-1321"><a href="#cb26-1321" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1322"><a href="#cb26-1322" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> history</span>
<span id="cb26-1323"><a href="#cb26-1323" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-1324"><a href="#cb26-1324" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1325"><a href="#cb26-1325" aria-hidden="true" tabindex="-1"></a><span class="fu">### Step 8: Train the Model</span></span>
<span id="cb26-1326"><a href="#cb26-1326" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1327"><a href="#cb26-1327" aria-hidden="true" tabindex="-1"></a><span class="in">    Before we train the model, let's set up some key training parameters. This is just for demonstration purposes. In practice, you would want to use a larger number of epochs and a smaller learning rate.</span></span>
<span id="cb26-1328"><a href="#cb26-1328" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1329"><a href="#cb26-1329" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`EPOCHS`</span>: The number of complete passes through the training dataset. For demonstration, we'll use 15 epochs. Increasing this can lead to better results, but takes longer.</span>
<span id="cb26-1330"><a href="#cb26-1330" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`LEARNING_RATE`</span>: This controls how much the model weights are updated during training. A smaller value (like <span class="in">`1e-4`</span>) means smaller, more stable updatesâ€”generally safer for fine-tuning.</span>
<span id="cb26-1331"><a href="#cb26-1331" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>We'll use these values in the training loop to show how the model gradually learns and improves over time.</span>
<span id="cb26-1332"><a href="#cb26-1332" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1333"><a href="#cb26-1333" aria-hidden="true" tabindex="-1"></a>Each epoch is a complete pass through the training dataset, and the model is updated based on the loss and accuracy. One EPOCH will take longer than one batch, because it will process all the training data.</span>
<span id="cb26-1334"><a href="#cb26-1334" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1337"><a href="#cb26-1337" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-1338"><a href="#cb26-1338" aria-hidden="true" tabindex="-1"></a><span class="co"># Training configuration</span></span>
<span id="cb26-1339"><a href="#cb26-1339" aria-hidden="true" tabindex="-1"></a>EPOCHS <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb26-1340"><a href="#cb26-1340" aria-hidden="true" tabindex="-1"></a>LEARNING_RATE <span class="op">=</span> <span class="fl">1e-4</span></span>
<span id="cb26-1341"><a href="#cb26-1341" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1342"><a href="#cb26-1342" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the model</span></span>
<span id="cb26-1343"><a href="#cb26-1343" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> train_model(</span>
<span id="cb26-1344"><a href="#cb26-1344" aria-hidden="true" tabindex="-1"></a>    model<span class="op">=</span>model,</span>
<span id="cb26-1345"><a href="#cb26-1345" aria-hidden="true" tabindex="-1"></a>    train_loader<span class="op">=</span>train_loader,</span>
<span id="cb26-1346"><a href="#cb26-1346" aria-hidden="true" tabindex="-1"></a>    val_loader<span class="op">=</span>val_loader,</span>
<span id="cb26-1347"><a href="#cb26-1347" aria-hidden="true" tabindex="-1"></a>    epochs<span class="op">=</span>EPOCHS,</span>
<span id="cb26-1348"><a href="#cb26-1348" aria-hidden="true" tabindex="-1"></a>    lr<span class="op">=</span>LEARNING_RATE,</span>
<span id="cb26-1349"><a href="#cb26-1349" aria-hidden="true" tabindex="-1"></a>    device<span class="op">=</span>device, </span>
<span id="cb26-1350"><a href="#cb26-1350" aria-hidden="true" tabindex="-1"></a>    criterion<span class="op">=</span>criterion, <span class="co"># Our CrossEntropyLoss loss function</span></span>
<span id="cb26-1351"><a href="#cb26-1351" aria-hidden="true" tabindex="-1"></a>    optimizer<span class="op">=</span>optimizer <span class="co"># Our Adam optimizer</span></span>
<span id="cb26-1352"><a href="#cb26-1352" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb26-1353"><a href="#cb26-1353" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1354"><a href="#cb26-1354" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="st">"Training complete!"</span>)</span>
<span id="cb26-1355"><a href="#cb26-1355" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-1356"><a href="#cb26-1356" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1357"><a href="#cb26-1357" aria-hidden="true" tabindex="-1"></a>:::{.callout-tip}</span>
<span id="cb26-1358"><a href="#cb26-1358" aria-hidden="true" tabindex="-1"></a><span class="fu">## Training Tips</span></span>
<span id="cb26-1359"><a href="#cb26-1359" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1360"><a href="#cb26-1360" aria-hidden="true" tabindex="-1"></a>**For better accuracy (production):**</span>
<span id="cb26-1361"><a href="#cb26-1361" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1362"><a href="#cb26-1362" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Increase epochs to 50-100</span>
<span id="cb26-1363"><a href="#cb26-1363" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Add learning rate scheduling</span>
<span id="cb26-1364"><a href="#cb26-1364" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Use data augmentation (random flips, rotations)</span>
<span id="cb26-1365"><a href="#cb26-1365" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Fine-tune the entire model (unfreeze backbone)</span>
<span id="cb26-1366"><a href="#cb26-1366" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1367"><a href="#cb26-1367" aria-hidden="true" tabindex="-1"></a>**For faster training:**</span>
<span id="cb26-1368"><a href="#cb26-1368" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1369"><a href="#cb26-1369" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Reduce batch size if GPU memory limited</span>
<span id="cb26-1370"><a href="#cb26-1370" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Use mixed precision (torch.cuda.amp)</span>
<span id="cb26-1371"><a href="#cb26-1371" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Freeze backbone layers (only train decoder)</span>
<span id="cb26-1372"><a href="#cb26-1372" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb26-1373"><a href="#cb26-1373" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1374"><a href="#cb26-1374" aria-hidden="true" tabindex="-1"></a><span class="fu">### Step 9: Visualize Training Progress</span></span>
<span id="cb26-1375"><a href="#cb26-1375" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1378"><a href="#cb26-1378" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-1379"><a href="#cb26-1379" aria-hidden="true" tabindex="-1"></a>fig, (ax1, ax2) <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">4</span>))</span>
<span id="cb26-1380"><a href="#cb26-1380" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1381"><a href="#cb26-1381" aria-hidden="true" tabindex="-1"></a>epochs_range <span class="op">=</span> <span class="bu">range</span>(<span class="dv">1</span>, EPOCHS <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb26-1382"><a href="#cb26-1382" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1383"><a href="#cb26-1383" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot loss</span></span>
<span id="cb26-1384"><a href="#cb26-1384" aria-hidden="true" tabindex="-1"></a>ax1.plot(epochs_range, history[<span class="st">'train_loss'</span>], label<span class="op">=</span><span class="st">'Train'</span>, marker<span class="op">=</span><span class="st">'o'</span>)</span>
<span id="cb26-1385"><a href="#cb26-1385" aria-hidden="true" tabindex="-1"></a>ax1.plot(epochs_range, history[<span class="st">'val_loss'</span>], label<span class="op">=</span><span class="st">'Validation'</span>, marker<span class="op">=</span><span class="st">'s'</span>)</span>
<span id="cb26-1386"><a href="#cb26-1386" aria-hidden="true" tabindex="-1"></a>ax1.set_xlabel(<span class="st">'Epoch'</span>)</span>
<span id="cb26-1387"><a href="#cb26-1387" aria-hidden="true" tabindex="-1"></a>ax1.set_ylabel(<span class="st">'Loss'</span>)</span>
<span id="cb26-1388"><a href="#cb26-1388" aria-hidden="true" tabindex="-1"></a>ax1.set_title(<span class="st">'Training and Validation Loss'</span>)</span>
<span id="cb26-1389"><a href="#cb26-1389" aria-hidden="true" tabindex="-1"></a>ax1.legend()</span>
<span id="cb26-1390"><a href="#cb26-1390" aria-hidden="true" tabindex="-1"></a>ax1.grid(alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb26-1391"><a href="#cb26-1391" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1392"><a href="#cb26-1392" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot accuracy</span></span>
<span id="cb26-1393"><a href="#cb26-1393" aria-hidden="true" tabindex="-1"></a>ax2.plot(epochs_range, history[<span class="st">'train_acc'</span>], label<span class="op">=</span><span class="st">'Train'</span>, marker<span class="op">=</span><span class="st">'o'</span>)</span>
<span id="cb26-1394"><a href="#cb26-1394" aria-hidden="true" tabindex="-1"></a>ax2.plot(epochs_range, history[<span class="st">'val_acc'</span>], label<span class="op">=</span><span class="st">'Validation'</span>, marker<span class="op">=</span><span class="st">'s'</span>)</span>
<span id="cb26-1395"><a href="#cb26-1395" aria-hidden="true" tabindex="-1"></a>ax2.set_xlabel(<span class="st">'Epoch'</span>)</span>
<span id="cb26-1396"><a href="#cb26-1396" aria-hidden="true" tabindex="-1"></a>ax2.set_ylabel(<span class="st">'Accuracy'</span>)</span>
<span id="cb26-1397"><a href="#cb26-1397" aria-hidden="true" tabindex="-1"></a>ax2.set_title(<span class="st">'Training and Validation Accuracy'</span>)</span>
<span id="cb26-1398"><a href="#cb26-1398" aria-hidden="true" tabindex="-1"></a>ax2.legend()</span>
<span id="cb26-1399"><a href="#cb26-1399" aria-hidden="true" tabindex="-1"></a>ax2.grid(alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb26-1400"><a href="#cb26-1400" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1401"><a href="#cb26-1401" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb26-1402"><a href="#cb26-1402" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb26-1403"><a href="#cb26-1403" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1404"><a href="#cb26-1404" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Final Training Accuracy: </span><span class="sc">{</span>history[<span class="st">'train_acc'</span>][<span class="op">-</span><span class="dv">1</span>]<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb26-1405"><a href="#cb26-1405" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Final Validation Accuracy: </span><span class="sc">{</span>history[<span class="st">'val_acc'</span>][<span class="op">-</span><span class="dv">1</span>]<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb26-1406"><a href="#cb26-1406" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-1407"><a href="#cb26-1407" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1408"><a href="#cb26-1408" aria-hidden="true" tabindex="-1"></a><span class="fu">### Step 10: Evaluate on Test Set</span></span>
<span id="cb26-1409"><a href="#cb26-1409" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1412"><a href="#cb26-1412" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-1413"><a href="#cb26-1413" aria-hidden="true" tabindex="-1"></a><span class="co">#| tangle: geogfm/training/simple_trainer.py</span></span>
<span id="cb26-1414"><a href="#cb26-1414" aria-hidden="true" tabindex="-1"></a><span class="co">#| mode: append</span></span>
<span id="cb26-1415"><a href="#cb26-1415" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1416"><a href="#cb26-1416" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> evaluate_model(model, test_loader, device):</span>
<span id="cb26-1417"><a href="#cb26-1417" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb26-1418"><a href="#cb26-1418" aria-hidden="true" tabindex="-1"></a><span class="co">    Evaluate model on test set.</span></span>
<span id="cb26-1419"><a href="#cb26-1419" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1420"><a href="#cb26-1420" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters</span></span>
<span id="cb26-1421"><a href="#cb26-1421" aria-hidden="true" tabindex="-1"></a><span class="co">    ----------</span></span>
<span id="cb26-1422"><a href="#cb26-1422" aria-hidden="true" tabindex="-1"></a><span class="co">    model : nn.Module</span></span>
<span id="cb26-1423"><a href="#cb26-1423" aria-hidden="true" tabindex="-1"></a><span class="co">        Trained model</span></span>
<span id="cb26-1424"><a href="#cb26-1424" aria-hidden="true" tabindex="-1"></a><span class="co">    test_loader : DataLoader</span></span>
<span id="cb26-1425"><a href="#cb26-1425" aria-hidden="true" tabindex="-1"></a><span class="co">        Test data</span></span>
<span id="cb26-1426"><a href="#cb26-1426" aria-hidden="true" tabindex="-1"></a><span class="co">    device : torch.device</span></span>
<span id="cb26-1427"><a href="#cb26-1427" aria-hidden="true" tabindex="-1"></a><span class="co">        Device to use</span></span>
<span id="cb26-1428"><a href="#cb26-1428" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1429"><a href="#cb26-1429" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns</span></span>
<span id="cb26-1430"><a href="#cb26-1430" aria-hidden="true" tabindex="-1"></a><span class="co">    -------</span></span>
<span id="cb26-1431"><a href="#cb26-1431" aria-hidden="true" tabindex="-1"></a><span class="co">    dict</span></span>
<span id="cb26-1432"><a href="#cb26-1432" aria-hidden="true" tabindex="-1"></a><span class="co">        Test metrics including accuracy and per-class accuracy</span></span>
<span id="cb26-1433"><a href="#cb26-1433" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb26-1434"><a href="#cb26-1434" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">eval</span>()</span>
<span id="cb26-1435"><a href="#cb26-1435" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1436"><a href="#cb26-1436" aria-hidden="true" tabindex="-1"></a>    correct <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb26-1437"><a href="#cb26-1437" aria-hidden="true" tabindex="-1"></a>    total <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb26-1438"><a href="#cb26-1438" aria-hidden="true" tabindex="-1"></a>    class_correct <span class="op">=</span> {}</span>
<span id="cb26-1439"><a href="#cb26-1439" aria-hidden="true" tabindex="-1"></a>    class_total <span class="op">=</span> {}</span>
<span id="cb26-1440"><a href="#cb26-1440" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1441"><a href="#cb26-1441" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb26-1442"><a href="#cb26-1442" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> images, labels <span class="kw">in</span> test_loader:</span>
<span id="cb26-1443"><a href="#cb26-1443" aria-hidden="true" tabindex="-1"></a>            images <span class="op">=</span> images.to(device)</span>
<span id="cb26-1444"><a href="#cb26-1444" aria-hidden="true" tabindex="-1"></a>            labels <span class="op">=</span> labels.to(device)</span>
<span id="cb26-1445"><a href="#cb26-1445" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1446"><a href="#cb26-1446" aria-hidden="true" tabindex="-1"></a>            outputs <span class="op">=</span> model(images)</span>
<span id="cb26-1447"><a href="#cb26-1447" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="bu">hasattr</span>(outputs, <span class="st">'output'</span>):</span>
<span id="cb26-1448"><a href="#cb26-1448" aria-hidden="true" tabindex="-1"></a>                outputs <span class="op">=</span> outputs.output</span>
<span id="cb26-1449"><a href="#cb26-1449" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1450"><a href="#cb26-1450" aria-hidden="true" tabindex="-1"></a>            _, predicted <span class="op">=</span> outputs.<span class="bu">max</span>(<span class="dv">1</span>)</span>
<span id="cb26-1451"><a href="#cb26-1451" aria-hidden="true" tabindex="-1"></a>            total <span class="op">+=</span> labels.size(<span class="dv">0</span>)</span>
<span id="cb26-1452"><a href="#cb26-1452" aria-hidden="true" tabindex="-1"></a>            correct <span class="op">+=</span> predicted.eq(labels).<span class="bu">sum</span>().item()</span>
<span id="cb26-1453"><a href="#cb26-1453" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1454"><a href="#cb26-1454" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Per-class accuracy</span></span>
<span id="cb26-1455"><a href="#cb26-1455" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> label, pred <span class="kw">in</span> <span class="bu">zip</span>(labels, predicted):</span>
<span id="cb26-1456"><a href="#cb26-1456" aria-hidden="true" tabindex="-1"></a>                label_item <span class="op">=</span> label.item()</span>
<span id="cb26-1457"><a href="#cb26-1457" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> label_item <span class="kw">not</span> <span class="kw">in</span> class_correct:</span>
<span id="cb26-1458"><a href="#cb26-1458" aria-hidden="true" tabindex="-1"></a>                    class_correct[label_item] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb26-1459"><a href="#cb26-1459" aria-hidden="true" tabindex="-1"></a>                    class_total[label_item] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb26-1460"><a href="#cb26-1460" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1461"><a href="#cb26-1461" aria-hidden="true" tabindex="-1"></a>                class_total[label_item] <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb26-1462"><a href="#cb26-1462" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> label <span class="op">==</span> pred:</span>
<span id="cb26-1463"><a href="#cb26-1463" aria-hidden="true" tabindex="-1"></a>                    class_correct[label_item] <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb26-1464"><a href="#cb26-1464" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1465"><a href="#cb26-1465" aria-hidden="true" tabindex="-1"></a>    overall_acc <span class="op">=</span> correct <span class="op">/</span> total</span>
<span id="cb26-1466"><a href="#cb26-1466" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1467"><a href="#cb26-1467" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compute per-class accuracies</span></span>
<span id="cb26-1468"><a href="#cb26-1468" aria-hidden="true" tabindex="-1"></a>    per_class_acc <span class="op">=</span> {}</span>
<span id="cb26-1469"><a href="#cb26-1469" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> label_idx <span class="kw">in</span> class_correct.keys():</span>
<span id="cb26-1470"><a href="#cb26-1470" aria-hidden="true" tabindex="-1"></a>        per_class_acc[label_idx] <span class="op">=</span> class_correct[label_idx] <span class="op">/</span> class_total[label_idx]</span>
<span id="cb26-1471"><a href="#cb26-1471" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1472"><a href="#cb26-1472" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {</span>
<span id="cb26-1473"><a href="#cb26-1473" aria-hidden="true" tabindex="-1"></a>        <span class="st">'overall_accuracy'</span>: overall_acc,</span>
<span id="cb26-1474"><a href="#cb26-1474" aria-hidden="true" tabindex="-1"></a>        <span class="st">'per_class_accuracy'</span>: per_class_acc,</span>
<span id="cb26-1475"><a href="#cb26-1475" aria-hidden="true" tabindex="-1"></a>        <span class="st">'total_samples'</span>: total</span>
<span id="cb26-1476"><a href="#cb26-1476" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb26-1477"><a href="#cb26-1477" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-1478"><a href="#cb26-1478" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1481"><a href="#cb26-1481" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-1482"><a href="#cb26-1482" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate on test set</span></span>
<span id="cb26-1483"><a href="#cb26-1483" aria-hidden="true" tabindex="-1"></a>test_results <span class="op">=</span> evaluate_model(model, test_loader, device)</span>
<span id="cb26-1484"><a href="#cb26-1484" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1485"><a href="#cb26-1485" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Test Set Evaluation"</span>)</span>
<span id="cb26-1486"><a href="#cb26-1486" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"="</span> <span class="op">*</span> <span class="dv">50</span>)</span>
<span id="cb26-1487"><a href="#cb26-1487" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Overall Accuracy: </span><span class="sc">{</span>test_results[<span class="st">'overall_accuracy'</span>]<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb26-1488"><a href="#cb26-1488" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Total Test Samples: </span><span class="sc">{</span>test_results[<span class="st">'total_samples'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb26-1489"><a href="#cb26-1489" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"Per-Class Accuracy:"</span>)</span>
<span id="cb26-1490"><a href="#cb26-1490" aria-hidden="true" tabindex="-1"></a>logger.info(<span class="ss">f"-"</span> <span class="op">*</span> <span class="dv">50</span>)</span>
<span id="cb26-1491"><a href="#cb26-1491" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1492"><a href="#cb26-1492" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> label_idx, acc <span class="kw">in</span> <span class="bu">sorted</span>(test_results[<span class="st">'per_class_accuracy'</span>].items()):</span>
<span id="cb26-1493"><a href="#cb26-1493" aria-hidden="true" tabindex="-1"></a>    class_name <span class="op">=</span> train_dataset.classes[label_idx]</span>
<span id="cb26-1494"><a href="#cb26-1494" aria-hidden="true" tabindex="-1"></a>    logger.info(<span class="ss">f"  </span><span class="sc">{</span>class_name<span class="sc">:20s}</span><span class="ss">: </span><span class="sc">{</span>acc<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb26-1495"><a href="#cb26-1495" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-1496"><a href="#cb26-1496" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1497"><a href="#cb26-1497" aria-hidden="true" tabindex="-1"></a>:::{.callout-note}</span>
<span id="cb26-1498"><a href="#cb26-1498" aria-hidden="true" tabindex="-1"></a><span class="fu">## Expected Performance</span></span>
<span id="cb26-1499"><a href="#cb26-1499" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1500"><a href="#cb26-1500" aria-hidden="true" tabindex="-1"></a>With only a limited number of epochs of training, you should see:</span>
<span id="cb26-1501"><a href="#cb26-1501" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1502"><a href="#cb26-1502" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Overall accuracy: 80-95%**</span>
<span id="cb26-1503"><a href="#cb26-1503" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Some improvement in accuracy on distinct classes (Forest, Water)</span>
<span id="cb26-1504"><a href="#cb26-1504" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Some improvement in accuracy on similar classes (Annual vs Permanent Crop)</span>
<span id="cb26-1505"><a href="#cb26-1505" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1506"><a href="#cb26-1506" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb26-1507"><a href="#cb26-1507" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1508"><a href="#cb26-1508" aria-hidden="true" tabindex="-1"></a><span class="fu">### Step 11: Visualize Predictions</span></span>
<span id="cb26-1509"><a href="#cb26-1509" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1510"><a href="#cb26-1510" aria-hidden="true" tabindex="-1"></a>Let's see what the model is predicting.</span>
<span id="cb26-1511"><a href="#cb26-1511" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1514"><a href="#cb26-1514" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-1515"><a href="#cb26-1515" aria-hidden="true" tabindex="-1"></a><span class="co">#| tangle: geogfm/training/simple_trainer.py</span></span>
<span id="cb26-1516"><a href="#cb26-1516" aria-hidden="true" tabindex="-1"></a><span class="co">#| mode: append</span></span>
<span id="cb26-1517"><a href="#cb26-1517" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1518"><a href="#cb26-1518" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> visualize_predictions(model, dataset, class_names, device, num_samples<span class="op">=</span><span class="dv">9</span>):</span>
<span id="cb26-1519"><a href="#cb26-1519" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb26-1520"><a href="#cb26-1520" aria-hidden="true" tabindex="-1"></a><span class="co">    Visualize model predictions on random samples.</span></span>
<span id="cb26-1521"><a href="#cb26-1521" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1522"><a href="#cb26-1522" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters</span></span>
<span id="cb26-1523"><a href="#cb26-1523" aria-hidden="true" tabindex="-1"></a><span class="co">    ----------</span></span>
<span id="cb26-1524"><a href="#cb26-1524" aria-hidden="true" tabindex="-1"></a><span class="co">    model : nn.Module</span></span>
<span id="cb26-1525"><a href="#cb26-1525" aria-hidden="true" tabindex="-1"></a><span class="co">        Trained model</span></span>
<span id="cb26-1526"><a href="#cb26-1526" aria-hidden="true" tabindex="-1"></a><span class="co">    dataset : Dataset</span></span>
<span id="cb26-1527"><a href="#cb26-1527" aria-hidden="true" tabindex="-1"></a><span class="co">        Dataset to sample from</span></span>
<span id="cb26-1528"><a href="#cb26-1528" aria-hidden="true" tabindex="-1"></a><span class="co">    class_names : list</span></span>
<span id="cb26-1529"><a href="#cb26-1529" aria-hidden="true" tabindex="-1"></a><span class="co">        List of class names</span></span>
<span id="cb26-1530"><a href="#cb26-1530" aria-hidden="true" tabindex="-1"></a><span class="co">    device : torch.device</span></span>
<span id="cb26-1531"><a href="#cb26-1531" aria-hidden="true" tabindex="-1"></a><span class="co">        Device to use</span></span>
<span id="cb26-1532"><a href="#cb26-1532" aria-hidden="true" tabindex="-1"></a><span class="co">    num_samples : int</span></span>
<span id="cb26-1533"><a href="#cb26-1533" aria-hidden="true" tabindex="-1"></a><span class="co">        Number of samples to visualize</span></span>
<span id="cb26-1534"><a href="#cb26-1534" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb26-1535"><a href="#cb26-1535" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb26-1536"><a href="#cb26-1536" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb26-1537"><a href="#cb26-1537" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1538"><a href="#cb26-1538" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">eval</span>()</span>
<span id="cb26-1539"><a href="#cb26-1539" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1540"><a href="#cb26-1540" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get random samples</span></span>
<span id="cb26-1541"><a href="#cb26-1541" aria-hidden="true" tabindex="-1"></a>    indices <span class="op">=</span> np.random.choice(<span class="bu">len</span>(dataset), num_samples, replace<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb26-1542"><a href="#cb26-1542" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1543"><a href="#cb26-1543" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create subplot grid</span></span>
<span id="cb26-1544"><a href="#cb26-1544" aria-hidden="true" tabindex="-1"></a>    rows <span class="op">=</span> <span class="bu">int</span>(np.sqrt(num_samples))</span>
<span id="cb26-1545"><a href="#cb26-1545" aria-hidden="true" tabindex="-1"></a>    cols <span class="op">=</span> <span class="bu">int</span>(np.ceil(num_samples <span class="op">/</span> rows))</span>
<span id="cb26-1546"><a href="#cb26-1546" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1547"><a href="#cb26-1547" aria-hidden="true" tabindex="-1"></a>    fig, axes <span class="op">=</span> plt.subplots(rows, cols, figsize<span class="op">=</span>(<span class="dv">3</span><span class="op">*</span>cols, <span class="dv">3</span><span class="op">*</span>rows))</span>
<span id="cb26-1548"><a href="#cb26-1548" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> num_samples <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb26-1549"><a href="#cb26-1549" aria-hidden="true" tabindex="-1"></a>        axes <span class="op">=</span> [axes]</span>
<span id="cb26-1550"><a href="#cb26-1550" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb26-1551"><a href="#cb26-1551" aria-hidden="true" tabindex="-1"></a>        axes <span class="op">=</span> axes.ravel()</span>
<span id="cb26-1552"><a href="#cb26-1552" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1553"><a href="#cb26-1553" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb26-1554"><a href="#cb26-1554" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> idx, sample_idx <span class="kw">in</span> <span class="bu">enumerate</span>(indices):</span>
<span id="cb26-1555"><a href="#cb26-1555" aria-hidden="true" tabindex="-1"></a>            image, true_label <span class="op">=</span> dataset[sample_idx]</span>
<span id="cb26-1556"><a href="#cb26-1556" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1557"><a href="#cb26-1557" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Get prediction</span></span>
<span id="cb26-1558"><a href="#cb26-1558" aria-hidden="true" tabindex="-1"></a>            image_batch <span class="op">=</span> image.unsqueeze(<span class="dv">0</span>).to(device)</span>
<span id="cb26-1559"><a href="#cb26-1559" aria-hidden="true" tabindex="-1"></a>            output <span class="op">=</span> model(image_batch)</span>
<span id="cb26-1560"><a href="#cb26-1560" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="bu">hasattr</span>(output, <span class="st">'output'</span>):</span>
<span id="cb26-1561"><a href="#cb26-1561" aria-hidden="true" tabindex="-1"></a>                output <span class="op">=</span> output.output</span>
<span id="cb26-1562"><a href="#cb26-1562" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1563"><a href="#cb26-1563" aria-hidden="true" tabindex="-1"></a>            _, predicted <span class="op">=</span> output.<span class="bu">max</span>(<span class="dv">1</span>)</span>
<span id="cb26-1564"><a href="#cb26-1564" aria-hidden="true" tabindex="-1"></a>            pred_label <span class="op">=</span> predicted.item()</span>
<span id="cb26-1565"><a href="#cb26-1565" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1566"><a href="#cb26-1566" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Create RGB visualization from first 3 bands</span></span>
<span id="cb26-1567"><a href="#cb26-1567" aria-hidden="true" tabindex="-1"></a>            rgb <span class="op">=</span> image[[<span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">0</span>], :, :].numpy()  <span class="co"># Assuming bands 2,1,0 are R,G,B-like</span></span>
<span id="cb26-1568"><a href="#cb26-1568" aria-hidden="true" tabindex="-1"></a>            rgb <span class="op">=</span> np.transpose(rgb, (<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">0</span>))</span>
<span id="cb26-1569"><a href="#cb26-1569" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1570"><a href="#cb26-1570" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Normalize for display</span></span>
<span id="cb26-1571"><a href="#cb26-1571" aria-hidden="true" tabindex="-1"></a>            rgb_min, rgb_max <span class="op">=</span> rgb.<span class="bu">min</span>(), rgb.<span class="bu">max</span>()</span>
<span id="cb26-1572"><a href="#cb26-1572" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> rgb_max <span class="op">&gt;</span> rgb_min:</span>
<span id="cb26-1573"><a href="#cb26-1573" aria-hidden="true" tabindex="-1"></a>                rgb_norm <span class="op">=</span> (rgb <span class="op">-</span> rgb_min) <span class="op">/</span> (rgb_max <span class="op">-</span> rgb_min)</span>
<span id="cb26-1574"><a href="#cb26-1574" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb26-1575"><a href="#cb26-1575" aria-hidden="true" tabindex="-1"></a>                rgb_norm <span class="op">=</span> rgb</span>
<span id="cb26-1576"><a href="#cb26-1576" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1577"><a href="#cb26-1577" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Plot</span></span>
<span id="cb26-1578"><a href="#cb26-1578" aria-hidden="true" tabindex="-1"></a>            axes[idx].imshow(rgb_norm)</span>
<span id="cb26-1579"><a href="#cb26-1579" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1580"><a href="#cb26-1580" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Color code: green if correct, red if wrong</span></span>
<span id="cb26-1581"><a href="#cb26-1581" aria-hidden="true" tabindex="-1"></a>            color <span class="op">=</span> <span class="st">'green'</span> <span class="cf">if</span> pred_label <span class="op">==</span> true_label <span class="cf">else</span> <span class="st">'red'</span></span>
<span id="cb26-1582"><a href="#cb26-1582" aria-hidden="true" tabindex="-1"></a>            axes[idx].set_title(</span>
<span id="cb26-1583"><a href="#cb26-1583" aria-hidden="true" tabindex="-1"></a>                <span class="ss">f"True: </span><span class="sc">{</span>class_names[true_label]<span class="sc">}</span><span class="ch">\n</span><span class="ss">"</span></span>
<span id="cb26-1584"><a href="#cb26-1584" aria-hidden="true" tabindex="-1"></a>                <span class="ss">f"Pred: </span><span class="sc">{</span>class_names[pred_label]<span class="sc">}</span><span class="ss">"</span>,</span>
<span id="cb26-1585"><a href="#cb26-1585" aria-hidden="true" tabindex="-1"></a>                color<span class="op">=</span>color,</span>
<span id="cb26-1586"><a href="#cb26-1586" aria-hidden="true" tabindex="-1"></a>                fontsize<span class="op">=</span><span class="dv">9</span></span>
<span id="cb26-1587"><a href="#cb26-1587" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb26-1588"><a href="#cb26-1588" aria-hidden="true" tabindex="-1"></a>            axes[idx].axis(<span class="st">'off'</span>)</span>
<span id="cb26-1589"><a href="#cb26-1589" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1590"><a href="#cb26-1590" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb26-1591"><a href="#cb26-1591" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb26-1592"><a href="#cb26-1592" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-1593"><a href="#cb26-1593" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1596"><a href="#cb26-1596" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb26-1597"><a href="#cb26-1597" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize predictions</span></span>
<span id="cb26-1598"><a href="#cb26-1598" aria-hidden="true" tabindex="-1"></a>visualize_predictions(</span>
<span id="cb26-1599"><a href="#cb26-1599" aria-hidden="true" tabindex="-1"></a>    model<span class="op">=</span>model,</span>
<span id="cb26-1600"><a href="#cb26-1600" aria-hidden="true" tabindex="-1"></a>    dataset<span class="op">=</span>test_dataset_transformed,</span>
<span id="cb26-1601"><a href="#cb26-1601" aria-hidden="true" tabindex="-1"></a>    class_names<span class="op">=</span>train_dataset.classes,</span>
<span id="cb26-1602"><a href="#cb26-1602" aria-hidden="true" tabindex="-1"></a>    device<span class="op">=</span>device,</span>
<span id="cb26-1603"><a href="#cb26-1603" aria-hidden="true" tabindex="-1"></a>    num_samples<span class="op">=</span><span class="dv">9</span></span>
<span id="cb26-1604"><a href="#cb26-1604" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb26-1605"><a href="#cb26-1605" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb26-1606"><a href="#cb26-1606" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1607"><a href="#cb26-1607" aria-hidden="true" tabindex="-1"></a><span class="fu">## Key Takeaways</span></span>
<span id="cb26-1608"><a href="#cb26-1608" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1609"><a href="#cb26-1609" aria-hidden="true" tabindex="-1"></a><span class="fu">### What You Learned</span></span>
<span id="cb26-1610"><a href="#cb26-1610" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1611"><a href="#cb26-1611" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**Library-Native Workflows**</span>
<span id="cb26-1612"><a href="#cb26-1612" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1613"><a href="#cb26-1613" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>TorchGeo for standardized datasets</span>
<span id="cb26-1614"><a href="#cb26-1614" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>TerraTorch for foundation models</span>
<span id="cb26-1615"><a href="#cb26-1615" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>No custom data loading needed</span>
<span id="cb26-1616"><a href="#cb26-1616" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1617"><a href="#cb26-1617" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**Progressive Transfer Learning Approaches**</span>
<span id="cb26-1618"><a href="#cb26-1618" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1619"><a href="#cb26-1619" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>**Zero-shot (0 examples)**: ~11% - Random decoder, backbone features only</span>
<span id="cb26-1620"><a href="#cb26-1620" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>**Prototype Networks (5 examples/class)**: ~30-50% - No training, just output space averaging</span>
<span id="cb26-1621"><a href="#cb26-1621" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>**Linear Probing (1-10 examples/class)**: ~30-75% - Train decoder only, backbone frozen</span>
<span id="cb26-1622"><a href="#cb26-1622" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>**Full Fine-tuning (thousands of examples)**: ~80-95% - Train entire model</span>
<span id="cb26-1623"><a href="#cb26-1623" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1624"><a href="#cb26-1624" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>**Data Efficiency of Foundation Models**</span>
<span id="cb26-1625"><a href="#cb26-1625" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1626"><a href="#cb26-1626" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Pretrained features enable learning from minimal data</span>
<span id="cb26-1627"><a href="#cb26-1627" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>5-10 examples per class can achieve 60-75% accuracy</span>
<span id="cb26-1628"><a href="#cb26-1628" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Huge reduction in labeling effort vs training from scratch</span>
<span id="cb26-1629"><a href="#cb26-1629" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Foundation models make few-shot learning practical</span>
<span id="cb26-1630"><a href="#cb26-1630" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1631"><a href="#cb26-1631" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>**Explicit Training Loops**</span>
<span id="cb26-1632"><a href="#cb26-1632" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1633"><a href="#cb26-1633" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Full visibility into training process</span>
<span id="cb26-1634"><a href="#cb26-1634" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Easy to debug and modify</span>
<span id="cb26-1635"><a href="#cb26-1635" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Understand every step</span>
<span id="cb26-1636"><a href="#cb26-1636" aria-hidden="true" tabindex="-1"></a><span class="ss">   - </span>Compare training regimes side-by-side</span>
<span id="cb26-1637"><a href="#cb26-1637" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1638"><a href="#cb26-1638" aria-hidden="true" tabindex="-1"></a><span class="fu">### Next Steps</span></span>
<span id="cb26-1639"><a href="#cb26-1639" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1640"><a href="#cb26-1640" aria-hidden="true" tabindex="-1"></a>**Week 3b will introduce:**</span>
<span id="cb26-1641"><a href="#cb26-1641" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1642"><a href="#cb26-1642" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>PyTorch Lightning for automation</span>
<span id="cb26-1643"><a href="#cb26-1643" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>TerraTorch Tasks interface</span>
<span id="cb26-1644"><a href="#cb26-1644" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Experiment tracking and logging</span>
<span id="cb26-1645"><a href="#cb26-1645" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Multi-GPU training</span>
<span id="cb26-1646"><a href="#cb26-1646" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Production deployment patterns</span>
<span id="cb26-1647"><a href="#cb26-1647" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1648"><a href="#cb26-1648" aria-hidden="true" tabindex="-1"></a>**For now, practice with:**</span>
<span id="cb26-1649"><a href="#cb26-1649" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1650"><a href="#cb26-1650" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Different TorchGeo datasets (BigEarthNet, Sen12MS, etc.)</span>
<span id="cb26-1651"><a href="#cb26-1651" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Different backbones (SatMAE, ScaleMAE, Clay)</span>
<span id="cb26-1652"><a href="#cb26-1652" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Different k-shot settings (try 3-shot, 20-shot, 50-shot)</span>
<span id="cb26-1653"><a href="#cb26-1653" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Compare prototype networks vs linear probing</span>
<span id="cb26-1654"><a href="#cb26-1654" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Longer training runs for full fine-tuning (50-100 epochs)</span>
<span id="cb26-1655"><a href="#cb26-1655" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1656"><a href="#cb26-1656" aria-hidden="true" tabindex="-1"></a><span class="fu">## Resources</span></span>
<span id="cb26-1657"><a href="#cb26-1657" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1658"><a href="#cb26-1658" aria-hidden="true" tabindex="-1"></a><span class="fu">### Documentation</span></span>
<span id="cb26-1659"><a href="#cb26-1659" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1660"><a href="#cb26-1660" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="co">[</span><span class="ot">TorchGeo Docs</span><span class="co">](https://torchgeo.readthedocs.io/)</span></span>
<span id="cb26-1661"><a href="#cb26-1661" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="co">[</span><span class="ot">TerraTorch GitHub</span><span class="co">](https://github.com/IBM/terratorch)</span></span>
<span id="cb26-1662"><a href="#cb26-1662" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="co">[</span><span class="ot">Prithvi Models</span><span class="co">](https://huggingface.co/ibm-nasa-geospatial)</span></span>
<span id="cb26-1663"><a href="#cb26-1663" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1664"><a href="#cb26-1664" aria-hidden="true" tabindex="-1"></a><span class="fu">### Datasets</span></span>
<span id="cb26-1665"><a href="#cb26-1665" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1666"><a href="#cb26-1666" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="co">[</span><span class="ot">EuroSAT Paper</span><span class="co">](https://ieeexplore.ieee.org/document/8736785)</span></span>
<span id="cb26-1667"><a href="#cb26-1667" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="co">[</span><span class="ot">TorchGeo Datasets</span><span class="co">](https://torchgeo.readthedocs.io/en/stable/api/datasets.html)</span></span>
<span id="cb26-1668"><a href="#cb26-1668" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1669"><a href="#cb26-1669" aria-hidden="true" tabindex="-1"></a><span class="fu">### Models</span></span>
<span id="cb26-1670"><a href="#cb26-1670" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1671"><a href="#cb26-1671" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="co">[</span><span class="ot">TerraTorch Model Zoo</span><span class="co">](https://github.com/IBM/terratorch/blob/main/MODEL_ZOO.md)</span></span>
<span id="cb26-1672"><a href="#cb26-1672" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="co">[</span><span class="ot">Prithvi Paper</span><span class="co">](https://arxiv.org/abs/2310.18660)</span></span>
<span id="cb26-1673"><a href="#cb26-1673" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1674"><a href="#cb26-1674" aria-hidden="true" tabindex="-1"></a>:::{.callout-tip}</span>
<span id="cb26-1675"><a href="#cb26-1675" aria-hidden="true" tabindex="-1"></a><span class="fu">## Extension Ideas</span></span>
<span id="cb26-1676"><a href="#cb26-1676" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1677"><a href="#cb26-1677" aria-hidden="true" tabindex="-1"></a>**Try these modifications:**</span>
<span id="cb26-1678"><a href="#cb26-1678" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1679"><a href="#cb26-1679" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**Few-Shot Variations**: Compare different K values (1, 3, 5, 10, 20, 50)</span>
<span id="cb26-1680"><a href="#cb26-1680" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**Distance Metrics**: Try Euclidean distance instead of cosine similarity for prototypes</span>
<span id="cb26-1681"><a href="#cb26-1681" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>**Feature Visualization**: Use t-SNE or UMAP to visualize Prithvi feature clusters</span>
<span id="cb26-1682"><a href="#cb26-1682" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>**Data Augmentation**: Add random flips, rotations for few-shot training</span>
<span id="cb26-1683"><a href="#cb26-1683" aria-hidden="true" tabindex="-1"></a><span class="ss">5. </span>**Learning Rate Scheduling**: Use ReduceLROnPlateau or CosineAnnealingLR</span>
<span id="cb26-1684"><a href="#cb26-1684" aria-hidden="true" tabindex="-1"></a><span class="ss">6. </span>**Ensemble**: Combine prototype networks + linear probing predictions</span>
<span id="cb26-1685"><a href="#cb26-1685" aria-hidden="true" tabindex="-1"></a><span class="ss">7. </span>**Cross-Dataset Transfer**: Train on EuroSAT, test on BigEarthNet</span>
<span id="cb26-1686"><a href="#cb26-1686" aria-hidden="true" tabindex="-1"></a><span class="ss">8. </span>**Export**: Save model weights and load for inference</span>
<span id="cb26-1687"><a href="#cb26-1687" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1688"><a href="#cb26-1688" aria-hidden="true" tabindex="-1"></a>All of these build on the foundation you learned today.</span>
<span id="cb26-1689"><a href="#cb26-1689" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb26-1690"><a href="#cb26-1690" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1691"><a href="#cb26-1691" aria-hidden="true" tabindex="-1"></a>:::{.callout-warning}</span>
<span id="cb26-1692"><a href="#cb26-1692" aria-hidden="true" tabindex="-1"></a><span class="fu">## Troubleshooting</span></span>
<span id="cb26-1693"><a href="#cb26-1693" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1694"><a href="#cb26-1694" aria-hidden="true" tabindex="-1"></a>**Common Issues:**</span>
<span id="cb26-1695"><a href="#cb26-1695" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1696"><a href="#cb26-1696" aria-hidden="true" tabindex="-1"></a>**"RuntimeError: CUDA out of memory"**</span>
<span id="cb26-1697"><a href="#cb26-1697" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1698"><a href="#cb26-1698" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Reduce batch size</span>
<span id="cb26-1699"><a href="#cb26-1699" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Use smaller model</span>
<span id="cb26-1700"><a href="#cb26-1700" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Use gradient checkpointing</span>
<span id="cb26-1701"><a href="#cb26-1701" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1702"><a href="#cb26-1702" aria-hidden="true" tabindex="-1"></a>**"ImportError: No module named 'terratorch'"**</span>
<span id="cb26-1703"><a href="#cb26-1703" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1704"><a href="#cb26-1704" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Install: <span class="in">`pip install terratorch`</span></span>
<span id="cb26-1705"><a href="#cb26-1705" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Verify: <span class="in">`python -c "import terratorch; print(terratorch.__version__)"`</span></span>
<span id="cb26-1706"><a href="#cb26-1706" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1707"><a href="#cb26-1707" aria-hidden="true" tabindex="-1"></a>**"Download failed"**</span>
<span id="cb26-1708"><a href="#cb26-1708" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1709"><a href="#cb26-1709" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Check internet connection</span>
<span id="cb26-1710"><a href="#cb26-1710" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Manually download EuroSAT from source</span>
<span id="cb26-1711"><a href="#cb26-1711" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Set download=False and point to existing data</span>
<span id="cb26-1712"><a href="#cb26-1712" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1713"><a href="#cb26-1713" aria-hidden="true" tabindex="-1"></a>**"Model output shape mismatch"**</span>
<span id="cb26-1714"><a href="#cb26-1714" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1715"><a href="#cb26-1715" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Verify band selection (6 bands for Prithvi)</span>
<span id="cb26-1716"><a href="#cb26-1716" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Check num_classes matches dataset</span>
<span id="cb26-1717"><a href="#cb26-1717" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Ensure transforms applied correctly</span>
<span id="cb26-1718"><a href="#cb26-1718" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1719"><a href="#cb26-1719" aria-hidden="true" tabindex="-1"></a>**Low accuracy (&lt;50%)**</span>
<span id="cb26-1720"><a href="#cb26-1720" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-1721"><a href="#cb26-1721" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Verify labels are correct</span>
<span id="cb26-1722"><a href="#cb26-1722" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Check data normalization</span>
<span id="cb26-1723"><a href="#cb26-1723" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Increase training epochs</span>
<span id="cb26-1724"><a href="#cb26-1724" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Try different learning rate</span>
<span id="cb26-1725"><a href="#cb26-1725" aria-hidden="true" tabindex="-1"></a>:::</span>
</code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../images/geog-logo.png" class="img-fluid figure-img" width="250"></p>
<figcaption>Department of Geography logo</figcaption>
</figure>
</div>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
<p>This website is built with <a href="https://github.com/kcaylor/GEOG-288KC-geospatial-foundation-models"><i class="fa-brands fa-github" title="the github octocat logo" aria-label="github"></i></a> and <a href="https://quarto.org/">Quarto</a></p>
</div>
  </div>
</footer>




</body></html>